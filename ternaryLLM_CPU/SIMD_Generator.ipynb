{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e0f104-9a6c-40a6-a37c-a386d5e1c942",
   "metadata": {},
   "source": [
    "# Generate INT8 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a468327-f75a-42a7-aa61-e1fcb55c53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G16_AVX2_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 16; j++) {\n",
      "            int* groupData = &metadata[j * 34]; \n",
      "            __m256 res0 = _mm256_setzero_ps();\n",
      "            __m256 res1 = _mm256_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 32) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256 pos0 = _mm256_i32gather_ps(X, indices_p0, 4);\n",
      "                __m256 pos1 = _mm256_i32gather_ps(X, indices_p1, 4);\n",
      "                __m256 neg0 = _mm256_i32gather_ps(X, indices_n0, 4);\n",
      "                __m256 neg1 = _mm256_i32gather_ps(X, indices_n1, 4);\n",
      "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
      "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
      "            }\n",
      "            float* Ybase = result + j * 16;\n",
      "            _mm256_store_ps(Ybase + 0, res0);\n",
      "            _mm256_store_ps(Ybase + 8, res1);\n",
      "            for (int g = 0; g < 16; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\n",
      "                    Ybase[g] += X[row_index[k]];\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\n",
      "                    Ybase[g] -= X[row_index[k]];\n",
      "            }\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin\n",
    "N_UNROLL = 16\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m256 res\"+str(sn)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8 + 8 * N_SIMD)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256 pos\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\") \n",
    "for sn in range(N_SIMD):  \n",
    "    print(\"                __m256 neg\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm256_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL): \n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] -= X[row_index[k]];\")\n",
    "else:\n",
    "        print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "        print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\")\n",
    "        print(\"                    Ybase[g] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\")\n",
    "        print(\"                    Ybase[g] -= X[row_index[k]];\")\n",
    "        print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a25de019-fdfa-4e17-a44c-09e34aec80da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_INT8_colMajor_TCSC_Uniform_64xG4_AVX512_OpenMP(const int8_t* X, const int32_t NonZeroPerCol, const int16_t* row_index, int8_t* result, const int M_ROW, const int N_COL, const int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 4; j++) {\n",
      "        for (int i = 0; i < M_ROW; i +=64) {\n",
      "            __m512i res00 = _mm512_setzero_si512();\n",
      "            __m512i res10 = _mm512_setzero_si512();\n",
      "            __m512i res20 = _mm512_setzero_si512();\n",
      "            __m512i res30 = _mm512_setzero_si512();\n",
      "            for (int k = j * 4 * NonZeroPerCol; k < (j + 1) * 4 * NonZeroPerCol; k += 8) {\n",
      "                __m512i pos00 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 0] * M_ROW + i + 0));\n",
      "                __m512i pos10 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 1] * M_ROW + i + 0));\n",
      "                __m512i pos20 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 2] * M_ROW + i + 0));\n",
      "                __m512i pos30 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 3] * M_ROW + i + 0));\n",
      "                __m512i neg00 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 4] * M_ROW + i + 0));\n",
      "                __m512i neg10 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 5] * M_ROW + i + 0));\n",
      "                __m512i neg20 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 6] * M_ROW + i + 0));\n",
      "                __m512i neg30 = _mm512_load_si512(reinterpret_cast<const __m512i*>(X + row_index[k + 7] * M_ROW + i + 0));\n",
      "                res00 = _mm512_add_epi8(res00, _mm512_sub_epi8(pos00, neg00));\n",
      "                res10 = _mm512_add_epi8(res10, _mm512_sub_epi8(pos10, neg10));\n",
      "                res20 = _mm512_add_epi8(res20, _mm512_sub_epi8(pos20, neg20));\n",
      "                res30 = _mm512_add_epi8(res30, _mm512_sub_epi8(pos30, neg30));\n",
      "            }\n",
      "            _mm512_store_si512(reinterpret_cast<__m512i*>(result + (j * 4 + 0) * M_ROW  + i + 0), res00);\n",
      "            _mm512_store_si512(reinterpret_cast<__m512i*>(result + (j * 4 + 1) * M_ROW  + i + 0), res10);\n",
      "            _mm512_store_si512(reinterpret_cast<__m512i*>(result + (j * 4 + 2) * M_ROW  + i + 0), res20);\n",
      "            _mm512_store_si512(reinterpret_cast<__m512i*>(result + (j * 4 + 3) * M_ROW  + i + 0), res30);\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate INT8 GEMM Code: Uniform and General, AVX2 and AVX-512\n",
    "M_UNROLL = 64\n",
    "N_UNROLL = 4\n",
    "X_DATA_BYTES = 1\n",
    "\n",
    "UNIFORM=True\n",
    "AVX512=True\n",
    "UNROLL_REMAIN = False\n",
    "\n",
    "if(UNIFORM):\n",
    "    TCSC_FORMAT = \"Uniform\"\n",
    "    INPUT_META = \"const int32_t NonZeroPerCol\"\n",
    "    K_START = \"j * \"+str(N_UNROLL)+\" * NonZeroPerCol\"\n",
    "    K_END = \"(j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol\"\n",
    "else:\n",
    "    TCSC_FORMAT = \"Merged_GroupMin\"\n",
    "    INPUT_META = \"const int32_t* metadata\"\n",
    "    K_START = \"groupData[0]\"\n",
    "    K_END = \"groupData[1]\"\n",
    "\n",
    "if(AVX512):\n",
    "    SIMD_SIZE = 64\n",
    "    AVX_NAME = \"AVX512\"\n",
    "    AVX = \"__m512i\"\n",
    "    SET_R = \"_mm512_setzero_si512\"\n",
    "    LOAD_W = \"_mm512_load_si512(reinterpret_cast<const __m512i*>\"\n",
    "    LOAD_X = \"_mm512_load_si512(reinterpret_cast<const __m512i*>\"\n",
    "    SUB_X = \"_mm512_sub_epi8\"\n",
    "    ADD_X = \"_mm512_add_epi8\"\n",
    "    STORE_Y = \"_mm512_store_si512(reinterpret_cast<__m512i*>\"\n",
    "else:\n",
    "    SIMD_SIZE = 32\n",
    "    AVX_NAME = \"AVX2\"\n",
    "    AVX = \"__m256i\"\n",
    "    SET_R = \"_mm256_setzero_si256\"\n",
    "    LOAD_W = \"_mm256_load_si256(reinterpret_cast<const __m256i*>\"\n",
    "    LOAD_X = \"_mm256_load_si256(reinterpret_cast<const __m256i*>\"\n",
    "    SUB_X = \"_mm256_sub_epi8\"\n",
    "    ADD_X = \"_mm256_add_epi8\"\n",
    "    STORE_Y = \"_mm256_store_si256(reinterpret_cast<__m256i*>\"\n",
    "    \n",
    "M_SIMD = int(M_UNROLL/SIMD_SIZE)\n",
    "\n",
    "function_name = \"void GEMM_CPU_INT8_colMajor_TCSC_\"+TCSC_FORMAT+\"_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_\"+AVX_NAME+\"_OpenMP\"\n",
    "function_name +=\"(const int8_t* X, \"+INPUT_META+\", const int16_t* row_index, int8_t* result, const int M_ROW, const int N_COL, const int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\") \n",
    "if(not UNIFORM):\n",
    "    print(\"        const int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL):\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"            \"+AVX+\" res\"+str(sn)+str(sm)+\" = \"+SET_R+\"();\")    \n",
    "print(\"            for (int k = \"+K_START+\"; k < \"+K_END+\"; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL): \n",
    "    for sm in range(M_SIMD):  \n",
    "        print(\"                \"+AVX+\" pos\"+str(sn)+str(sm)+\" = \"+LOAD_X+\"(X + row_index[k + \"+str(sn)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")   \n",
    "for sn in range(N_UNROLL): \n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"                \"+AVX+\" neg\"+str(sn)+str(sm)+\" = \"+LOAD_X+\"(X + row_index[k + \"+str(sn+N_UNROLL)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")\n",
    "for sn in range(N_UNROLL): \n",
    "    for sm in range(M_SIMD):\n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = \"+ADD_X+\"(res\"+idx+\", \"+SUB_X+\"(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "\n",
    "if(not UNIFORM):\n",
    "    for sn in range(N_UNROLL):\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++) {\")\n",
    "        for sm in range(M_SIMD):\n",
    "            print(\"                    res\"+str(sn)+str(sm)+\" = \"+ADD_X+\"(res\"+str(sn)+str(sm)+\", \"+LOAD_X+\"(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\")));\")\n",
    "        print(\"                }\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++) {\")\n",
    "        for sm in range(M_SIMD):\n",
    "            print(\"                    res\"+str(sn)+str(sm)+\" = \"+SUB_X+\"(res\"+str(sn)+str(sm)+\", \"+LOAD_X+\"(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\")));\")\n",
    "        print(\"                }\")\n",
    "\n",
    "for sn in range(N_UNROLL): \n",
    "    for sm in range(M_SIMD):     \n",
    "       print(\"            \"+STORE_Y+\"(result + (j * \"+str(N_UNROLL)+\" + \"+str(sn)+\") * M_ROW  + i + \"+str(sm*SIMD_SIZE)+\"), res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a9c07-aa7d-4aac-af4b-e4e140c4c00b",
   "metadata": {},
   "source": [
    "# Generate SiLU + Pointwise Mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69cfa89-fc92-4305-bb90-ddf108b3fe4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        T a0 = X[i + 0];\n",
      "        T a1 = X[i + 1];\n",
      "        T a2 = X[i + 2];\n",
      "        T a3 = X[i + 3];\n",
      "        T a4 = X[i + 4];\n",
      "        T a5 = X[i + 5];\n",
      "        T a6 = X[i + 6];\n",
      "        T a7 = X[i + 7];\n",
      "        T a8 = X[i + 8];\n",
      "        T a9 = X[i + 9];\n",
      "        T a10 = X[i + 10];\n",
      "        T a11 = X[i + 11];\n",
      "        T a12 = X[i + 12];\n",
      "        T a13 = X[i + 13];\n",
      "        T a14 = X[i + 14];\n",
      "        T a15 = X[i + 15];\n",
      "        T b0 = XB[i + 0];\n",
      "        T b1 = XB[i + 1];\n",
      "        T b2 = XB[i + 2];\n",
      "        T b3 = XB[i + 3];\n",
      "        T b4 = XB[i + 4];\n",
      "        T b5 = XB[i + 5];\n",
      "        T b6 = XB[i + 6];\n",
      "        T b7 = XB[i + 7];\n",
      "        T b8 = XB[i + 8];\n",
      "        T b9 = XB[i + 9];\n",
      "        T b10 = XB[i + 10];\n",
      "        T b11 = XB[i + 11];\n",
      "        T b12 = XB[i + 12];\n",
      "        T b13 = XB[i + 13];\n",
      "        T b14 = XB[i + 14];\n",
      "        T b15 = XB[i + 15];\n",
      "        T d0 = 1 + std::exp( - a0);\n",
      "        T d1 = 1 + std::exp( - a1);\n",
      "        T d2 = 1 + std::exp( - a2);\n",
      "        T d3 = 1 + std::exp( - a3);\n",
      "        T d4 = 1 + std::exp( - a4);\n",
      "        T d5 = 1 + std::exp( - a5);\n",
      "        T d6 = 1 + std::exp( - a6);\n",
      "        T d7 = 1 + std::exp( - a7);\n",
      "        T d8 = 1 + std::exp( - a8);\n",
      "        T d9 = 1 + std::exp( - a9);\n",
      "        T d10 = 1 + std::exp( - a10);\n",
      "        T d11 = 1 + std::exp( - a11);\n",
      "        T d12 = 1 + std::exp( - a12);\n",
      "        T d13 = 1 + std::exp( - a13);\n",
      "        T d14 = 1 + std::exp( - a14);\n",
      "        T d15 = 1 + std::exp( - a15);\n",
      "        a0 = a0 * b0 /  d0;\n",
      "        a1 = a1 * b1 /  d1;\n",
      "        a2 = a2 * b2 /  d2;\n",
      "        a3 = a3 * b3 /  d3;\n",
      "        a4 = a4 * b4 /  d4;\n",
      "        a5 = a5 * b5 /  d5;\n",
      "        a6 = a6 * b6 /  d6;\n",
      "        a7 = a7 * b7 /  d7;\n",
      "        a8 = a8 * b8 /  d8;\n",
      "        a9 = a9 * b9 /  d9;\n",
      "        a10 = a10 * b10 /  d10;\n",
      "        a11 = a11 * b11 /  d11;\n",
      "        a12 = a12 * b12 /  d12;\n",
      "        a13 = a13 * b13 /  d13;\n",
      "        a14 = a14 * b14 /  d14;\n",
      "        a15 = a15 * b15 /  d15;\n",
      "        X[i + 0] = a0;\n",
      "        X[i + 1] = a1;\n",
      "        X[i + 2] = a2;\n",
      "        X[i + 3] = a3;\n",
      "        X[i + 4] = a4;\n",
      "        X[i + 5] = a5;\n",
      "        X[i + 6] = a6;\n",
      "        X[i + 7] = a7;\n",
      "        X[i + 8] = a8;\n",
      "        X[i + 9] = a9;\n",
      "        X[i + 10] = a10;\n",
      "        X[i + 11] = a11;\n",
      "        X[i + 12] = a12;\n",
      "        X[i + 13] = a13;\n",
      "        X[i + 14] = a14;\n",
      "        X[i + 15] = a15;\n"
     ]
    }
   ],
   "source": [
    "# SiLU\n",
    "UNROLL_SIZE = 16\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T a\"+str(un)+\" = X[i + \"+str(un)+\"];\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T b\"+str(un)+\" = XB[i + \"+str(un)+\"];\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T d\"+str(un)+\" = 1 + std::exp( - a\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        a\"+str(un)+\" = a\"+str(un)+\" * b\"+str(un)+\" /  d\"+str(un)+\";\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        X[i + \"+str(un)+\"] = a\"+str(un)+\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f8dfe3-4fb0-47f2-856e-28e87d5a0eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        T a0 = X[i + j + 0];\n",
      "        T a1 = X[i + j + 1];\n",
      "        T a2 = X[i + j + 2];\n",
      "        T a3 = X[i + j + 3];\n",
      "        T a4 = X[i + j + 4];\n",
      "        T a5 = X[i + j + 5];\n",
      "        T a6 = X[i + j + 6];\n",
      "        T a7 = X[i + j + 7];\n",
      "        T a8 = X[i + j + 8];\n",
      "        T a9 = X[i + j + 9];\n",
      "        T a10 = X[i + j + 10];\n",
      "        T a11 = X[i + j + 11];\n",
      "        T a12 = X[i + j + 12];\n",
      "        T a13 = X[i + j + 13];\n",
      "        T a14 = X[i + j + 14];\n",
      "        T a15 = X[i + j + 15];\n",
      "        T b0 = XB[i + j + 0];\n",
      "        T b1 = XB[i + j + 1];\n",
      "        T b2 = XB[i + j + 2];\n",
      "        T b3 = XB[i + j + 3];\n",
      "        T b4 = XB[i + j + 4];\n",
      "        T b5 = XB[i + j + 5];\n",
      "        T b6 = XB[i + j + 6];\n",
      "        T b7 = XB[i + j + 7];\n",
      "        T b8 = XB[i + j + 8];\n",
      "        T b9 = XB[i + j + 9];\n",
      "        T b10 = XB[i + j + 10];\n",
      "        T b11 = XB[i + j + 11];\n",
      "        T b12 = XB[i + j + 12];\n",
      "        T b13 = XB[i + j + 13];\n",
      "        T b14 = XB[i + j + 14];\n",
      "        T b15 = XB[i + j + 15];\n",
      "        T d0 = std::exp( - a0);\n",
      "        T d1 = std::exp( - a1);\n",
      "        T d2 = std::exp( - a2);\n",
      "        T d3 = std::exp( - a3);\n",
      "        T d4 = std::exp( - a4);\n",
      "        T d5 = std::exp( - a5);\n",
      "        T d6 = std::exp( - a6);\n",
      "        T d7 = std::exp( - a7);\n",
      "        T d8 = std::exp( - a8);\n",
      "        T d9 = std::exp( - a9);\n",
      "        T d10 = std::exp( - a10);\n",
      "        T d11 = std::exp( - a11);\n",
      "        T d12 = std::exp( - a12);\n",
      "        T d13 = std::exp( - a13);\n",
      "        T d14 = std::exp( - a14);\n",
      "        T d15 = std::exp( - a15);\n",
      "        d0 = d0 + 1;\n",
      "        d1 = d1 + 1;\n",
      "        d2 = d2 + 1;\n",
      "        d3 = d3 + 1;\n",
      "        d4 = d4 + 1;\n",
      "        d5 = d5 + 1;\n",
      "        d6 = d6 + 1;\n",
      "        d7 = d7 + 1;\n",
      "        d8 = d8 + 1;\n",
      "        d9 = d9 + 1;\n",
      "        d10 = d10 + 1;\n",
      "        d11 = d11 + 1;\n",
      "        d12 = d12 + 1;\n",
      "        d13 = d13 + 1;\n",
      "        d14 = d14 + 1;\n",
      "        d15 = d15 + 1;\n",
      "        a0 = a0 * b0 /  d0;\n",
      "        a1 = a1 * b1 /  d1;\n",
      "        a2 = a2 * b2 /  d2;\n",
      "        a3 = a3 * b3 /  d3;\n",
      "        a4 = a4 * b4 /  d4;\n",
      "        a5 = a5 * b5 /  d5;\n",
      "        a6 = a6 * b6 /  d6;\n",
      "        a7 = a7 * b7 /  d7;\n",
      "        a8 = a8 * b8 /  d8;\n",
      "        a9 = a9 * b9 /  d9;\n",
      "        a10 = a10 * b10 /  d10;\n",
      "        a11 = a11 * b11 /  d11;\n",
      "        a12 = a12 * b12 /  d12;\n",
      "        a13 = a13 * b13 /  d13;\n",
      "        a14 = a14 * b14 /  d14;\n",
      "        a15 = a15 * b15 /  d15;\n",
      "        X[i + j + 0] = a0;\n",
      "        X[i + j + 1] = a1;\n",
      "        X[i + j + 2] = a2;\n",
      "        X[i + j + 3] = a3;\n",
      "        X[i + j + 4] = a4;\n",
      "        X[i + j + 5] = a5;\n",
      "        X[i + j + 6] = a6;\n",
      "        X[i + j + 7] = a7;\n",
      "        X[i + j + 8] = a8;\n",
      "        X[i + j + 9] = a9;\n",
      "        X[i + j + 10] = a10;\n",
      "        X[i + j + 11] = a11;\n",
      "        X[i + j + 12] = a12;\n",
      "        X[i + j + 13] = a13;\n",
      "        X[i + j + 14] = a14;\n",
      "        X[i + j + 15] = a15;\n"
     ]
    }
   ],
   "source": [
    "UNROLL_SIZE = 16\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T a\"+str(un)+\" = X[i + j + \"+str(un)+\"];\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T b\"+str(un)+\" = XB[i + j + \"+str(un)+\"];\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        T d\"+str(un)+\" = std::exp( - a\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = d\"+str(un)+\" + 1;\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        a\"+str(un)+\" = a\"+str(un)+\" * b\"+str(un)+\" /  d\"+str(un)+\";\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        X[i + j + \"+str(un)+\"] = a\"+str(un)+\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4e029b-a21e-42c1-b909-30e5fadadfdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __m256 a0 = _mm256_load_ps(&X[i + 0]);\n",
      "        __m256 a1 = _mm256_load_ps(&X[i + 8]);\n",
      "        __m256 a2 = _mm256_load_ps(&X[i + 16]);\n",
      "        __m256 a3 = _mm256_load_ps(&X[i + 24]);\n",
      "        __m256 a4 = _mm256_load_ps(&X[i + 32]);\n",
      "        __m256 a5 = _mm256_load_ps(&X[i + 40]);\n",
      "        __m256 a6 = _mm256_load_ps(&X[i + 48]);\n",
      "        __m256 a7 = _mm256_load_ps(&X[i + 56]);\n",
      "        __m256 b0 = _mm256_load_ps(&XB[i + 0]);\n",
      "        __m256 b1 = _mm256_load_ps(&XB[i + 8]);\n",
      "        __m256 b2 = _mm256_load_ps(&XB[i + 16]);\n",
      "        __m256 b3 = _mm256_load_ps(&XB[i + 24]);\n",
      "        __m256 b4 = _mm256_load_ps(&XB[i + 32]);\n",
      "        __m256 b5 = _mm256_load_ps(&XB[i + 40]);\n",
      "        __m256 b6 = _mm256_load_ps(&XB[i + 48]);\n",
      "        __m256 b7 = _mm256_load_ps(&XB[i + 56]);\n",
      "        __m256 d0 = _mm256_sub_ps(zeros, a0);\n",
      "        __m256 d1 = _mm256_sub_ps(zeros, a1);\n",
      "        __m256 d2 = _mm256_sub_ps(zeros, a2);\n",
      "        __m256 d3 = _mm256_sub_ps(zeros, a3);\n",
      "        __m256 d4 = _mm256_sub_ps(zeros, a4);\n",
      "        __m256 d5 = _mm256_sub_ps(zeros, a5);\n",
      "        __m256 d6 = _mm256_sub_ps(zeros, a6);\n",
      "        __m256 d7 = _mm256_sub_ps(zeros, a7);\n",
      "        a0 = _mm256_mul_ps(a0, b0);\n",
      "        a1 = _mm256_mul_ps(a1, b1);\n",
      "        a2 = _mm256_mul_ps(a2, b2);\n",
      "        a3 = _mm256_mul_ps(a3, b3);\n",
      "        a4 = _mm256_mul_ps(a4, b4);\n",
      "        a5 = _mm256_mul_ps(a5, b5);\n",
      "        a6 = _mm256_mul_ps(a6, b6);\n",
      "        a7 = _mm256_mul_ps(a7, b7);\n",
      "        d0 = _mm256_exp_ps( d0);\n",
      "        d1 = _mm256_exp_ps( d1);\n",
      "        d2 = _mm256_exp_ps( d2);\n",
      "        d3 = _mm256_exp_ps( d3);\n",
      "        d4 = _mm256_exp_ps( d4);\n",
      "        d5 = _mm256_exp_ps( d5);\n",
      "        d6 = _mm256_exp_ps( d6);\n",
      "        d7 = _mm256_exp_ps( d7);\n",
      "        d0 = _mm256_add_ps(d0, ones);\n",
      "        d1 = _mm256_add_ps(d1, ones);\n",
      "        d2 = _mm256_add_ps(d2, ones);\n",
      "        d3 = _mm256_add_ps(d3, ones);\n",
      "        d4 = _mm256_add_ps(d4, ones);\n",
      "        d5 = _mm256_add_ps(d5, ones);\n",
      "        d6 = _mm256_add_ps(d6, ones);\n",
      "        d7 = _mm256_add_ps(d7, ones);\n",
      "        d0 = _mm256_rcp_ps(d0);\n",
      "        d1 = _mm256_rcp_ps(d1);\n",
      "        d2 = _mm256_rcp_ps(d2);\n",
      "        d3 = _mm256_rcp_ps(d3);\n",
      "        d4 = _mm256_rcp_ps(d4);\n",
      "        d5 = _mm256_rcp_ps(d5);\n",
      "        d6 = _mm256_rcp_ps(d6);\n",
      "        d7 = _mm256_rcp_ps(d7);\n",
      "        d0 = _mm256_mul_ps(a0, d0);\n",
      "        d1 = _mm256_mul_ps(a1, d1);\n",
      "        d2 = _mm256_mul_ps(a2, d2);\n",
      "        d3 = _mm256_mul_ps(a3, d3);\n",
      "        d4 = _mm256_mul_ps(a4, d4);\n",
      "        d5 = _mm256_mul_ps(a5, d5);\n",
      "        d6 = _mm256_mul_ps(a6, d6);\n",
      "        d7 = _mm256_mul_ps(a7, d7);\n",
      "        _mm256_store_ps(&X[i + 0], d0);\n",
      "        _mm256_store_ps(&X[i + 8], d1);\n",
      "        _mm256_store_ps(&X[i + 16], d2);\n",
      "        _mm256_store_ps(&X[i + 24], d3);\n",
      "        _mm256_store_ps(&X[i + 32], d4);\n",
      "        _mm256_store_ps(&X[i + 40], d5);\n",
      "        _mm256_store_ps(&X[i + 48], d6);\n",
      "        _mm256_store_ps(&X[i + 56], d7);\n"
     ]
    }
   ],
   "source": [
    "SIMD_SIZE = 8\n",
    "UNROLL_SIZE = 8\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m256 a\"+str(un)+\" = _mm256_load_ps(&X[i + \"+str(un * SIMD_SIZE)+\"]);\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m256 b\"+str(un)+\" = _mm256_load_ps(&XB[i + \"+str(un * SIMD_SIZE)+\"]);\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m256 d\"+str(un)+\" = _mm256_sub_ps(zeros, a\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        a\"+str(un)+\" = _mm256_mul_ps(a\"+str(un)+\", b\"+str(un)+\");\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm256_exp_ps( d\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm256_add_ps(d\"+str(un)+\", ones);\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm256_rcp_ps(d\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm256_mul_ps(a\"+str(un)+\", d\"+str(un)+\");\")  \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        _mm256_store_ps(&X[i + \"+str(un * SIMD_SIZE)+\"], d\"+str(un)+\");\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ec8daf-ac93-4299-b626-5e5161f0710c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __m512 a0 = _mm512_load_ps(&X[i + 0]);\n",
      "        __m512 a1 = _mm512_load_ps(&X[i + 16]);\n",
      "        __m512 a2 = _mm512_load_ps(&X[i + 32]);\n",
      "        __m512 a3 = _mm512_load_ps(&X[i + 48]);\n",
      "        __m512 a4 = _mm512_load_ps(&X[i + 64]);\n",
      "        __m512 a5 = _mm512_load_ps(&X[i + 80]);\n",
      "        __m512 a6 = _mm512_load_ps(&X[i + 96]);\n",
      "        __m512 a7 = _mm512_load_ps(&X[i + 112]);\n",
      "        __m512 b0 = _mm512_load_ps(&XB[i + 0]);\n",
      "        __m512 b1 = _mm512_load_ps(&XB[i + 16]);\n",
      "        __m512 b2 = _mm512_load_ps(&XB[i + 32]);\n",
      "        __m512 b3 = _mm512_load_ps(&XB[i + 48]);\n",
      "        __m512 b4 = _mm512_load_ps(&XB[i + 64]);\n",
      "        __m512 b5 = _mm512_load_ps(&XB[i + 80]);\n",
      "        __m512 b6 = _mm512_load_ps(&XB[i + 96]);\n",
      "        __m512 b7 = _mm512_load_ps(&XB[i + 112]);\n",
      "        __m512 d0 = _mm512_sub_ps(zeros, a0);\n",
      "        __m512 d1 = _mm512_sub_ps(zeros, a1);\n",
      "        __m512 d2 = _mm512_sub_ps(zeros, a2);\n",
      "        __m512 d3 = _mm512_sub_ps(zeros, a3);\n",
      "        __m512 d4 = _mm512_sub_ps(zeros, a4);\n",
      "        __m512 d5 = _mm512_sub_ps(zeros, a5);\n",
      "        __m512 d6 = _mm512_sub_ps(zeros, a6);\n",
      "        __m512 d7 = _mm512_sub_ps(zeros, a7);\n",
      "        a0 = _mm512_mul_ps(a0, b0);\n",
      "        a1 = _mm512_mul_ps(a1, b1);\n",
      "        a2 = _mm512_mul_ps(a2, b2);\n",
      "        a3 = _mm512_mul_ps(a3, b3);\n",
      "        a4 = _mm512_mul_ps(a4, b4);\n",
      "        a5 = _mm512_mul_ps(a5, b5);\n",
      "        a6 = _mm512_mul_ps(a6, b6);\n",
      "        a7 = _mm512_mul_ps(a7, b7);\n",
      "        d0 = _mm512_exp_ps( d0);\n",
      "        d1 = _mm512_exp_ps( d1);\n",
      "        d2 = _mm512_exp_ps( d2);\n",
      "        d3 = _mm512_exp_ps( d3);\n",
      "        d4 = _mm512_exp_ps( d4);\n",
      "        d5 = _mm512_exp_ps( d5);\n",
      "        d6 = _mm512_exp_ps( d6);\n",
      "        d7 = _mm512_exp_ps( d7);\n",
      "        d0 = _mm512_add_ps(d0, ones);\n",
      "        d1 = _mm512_add_ps(d1, ones);\n",
      "        d2 = _mm512_add_ps(d2, ones);\n",
      "        d3 = _mm512_add_ps(d3, ones);\n",
      "        d4 = _mm512_add_ps(d4, ones);\n",
      "        d5 = _mm512_add_ps(d5, ones);\n",
      "        d6 = _mm512_add_ps(d6, ones);\n",
      "        d7 = _mm512_add_ps(d7, ones);\n",
      "        d0 = _mm512_rcp_ps(d0);\n",
      "        d1 = _mm512_rcp_ps(d1);\n",
      "        d2 = _mm512_rcp_ps(d2);\n",
      "        d3 = _mm512_rcp_ps(d3);\n",
      "        d4 = _mm512_rcp_ps(d4);\n",
      "        d5 = _mm512_rcp_ps(d5);\n",
      "        d6 = _mm512_rcp_ps(d6);\n",
      "        d7 = _mm512_rcp_ps(d7);\n",
      "        d0 = _mm512_mul_ps(a0, d0);\n",
      "        d1 = _mm512_mul_ps(a1, d1);\n",
      "        d2 = _mm512_mul_ps(a2, d2);\n",
      "        d3 = _mm512_mul_ps(a3, d3);\n",
      "        d4 = _mm512_mul_ps(a4, d4);\n",
      "        d5 = _mm512_mul_ps(a5, d5);\n",
      "        d6 = _mm512_mul_ps(a6, d6);\n",
      "        d7 = _mm512_mul_ps(a7, d7);\n",
      "        _mm512_store_ps(&X[i + 0], d0);\n",
      "        _mm512_store_ps(&X[i + 16], d1);\n",
      "        _mm512_store_ps(&X[i + 32], d2);\n",
      "        _mm512_store_ps(&X[i + 48], d3);\n",
      "        _mm512_store_ps(&X[i + 64], d4);\n",
      "        _mm512_store_ps(&X[i + 80], d5);\n",
      "        _mm512_store_ps(&X[i + 96], d6);\n",
      "        _mm512_store_ps(&X[i + 112], d7);\n"
     ]
    }
   ],
   "source": [
    "SIMD_SIZE = 16\n",
    "UNROLL_SIZE = 8\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m512 a\"+str(un)+\" = _mm512_load_ps(&X[i + \"+str(un * SIMD_SIZE)+\"]);\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m512 b\"+str(un)+\" = _mm512_load_ps(&XB[i + \"+str(un * SIMD_SIZE)+\"]);\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        __m512 d\"+str(un)+\" = _mm512_sub_ps(zeros, a\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        a\"+str(un)+\" = _mm512_mul_ps(a\"+str(un)+\", b\"+str(un)+\");\")    \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm512_exp_ps( d\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm512_add_ps(d\"+str(un)+\", ones);\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm512_rcp_ps(d\"+str(un)+\");\")\n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        d\"+str(un)+\" = _mm512_mul_ps(a\"+str(un)+\", d\"+str(un)+\");\")  \n",
    "for un in range(UNROLL_SIZE):\n",
    "    print(\"        _mm512_store_ps(&X[i + \"+str(un * SIMD_SIZE)+\"], d\"+str(un)+\");\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9646d-101c-419a-8b77-9929015f8b78",
   "metadata": {},
   "source": [
    "# SIMD Code Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b00f63-810f-46e3-b4f4-143470ae9429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_2xG64_AVX2_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 64; j++) {\n",
      "        for (int i = 0; i < M_ROW; i +=2) {\n",
      "            float* Xbase = X + i * K;\n",
      "            int* groupData = &metadata[j * 130]; \n",
      "            __m256 res00 = _mm256_setzero_ps();\n",
      "            __m256 res01 = _mm256_setzero_ps();\n",
      "            __m256 res10 = _mm256_setzero_ps();\n",
      "            __m256 res11 = _mm256_setzero_ps();\n",
      "            __m256 res20 = _mm256_setzero_ps();\n",
      "            __m256 res21 = _mm256_setzero_ps();\n",
      "            __m256 res30 = _mm256_setzero_ps();\n",
      "            __m256 res31 = _mm256_setzero_ps();\n",
      "            __m256 res40 = _mm256_setzero_ps();\n",
      "            __m256 res41 = _mm256_setzero_ps();\n",
      "            __m256 res50 = _mm256_setzero_ps();\n",
      "            __m256 res51 = _mm256_setzero_ps();\n",
      "            __m256 res60 = _mm256_setzero_ps();\n",
      "            __m256 res61 = _mm256_setzero_ps();\n",
      "            __m256 res70 = _mm256_setzero_ps();\n",
      "            __m256 res71 = _mm256_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 128) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_p2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_p3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256i indices_p4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 32));\n",
      "                __m256i indices_p5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 40));\n",
      "                __m256i indices_p6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 48));\n",
      "                __m256i indices_p7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 56));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 64));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 72));\n",
      "                __m256i indices_n2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 80));\n",
      "                __m256i indices_n3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 88));\n",
      "                __m256i indices_n4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 96));\n",
      "                __m256i indices_n5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 104));\n",
      "                __m256i indices_n6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 112));\n",
      "                __m256i indices_n7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 120));\n",
      "                __m256 pos00 = _mm256_i32gather_ps(Xbase + K * 0, indices_p0, 4);\n",
      "                __m256 pos10 = _mm256_i32gather_ps(Xbase + K * 0, indices_p1, 4);\n",
      "                __m256 pos20 = _mm256_i32gather_ps(Xbase + K * 0, indices_p2, 4);\n",
      "                __m256 pos30 = _mm256_i32gather_ps(Xbase + K * 0, indices_p3, 4);\n",
      "                __m256 pos40 = _mm256_i32gather_ps(Xbase + K * 0, indices_p4, 4);\n",
      "                __m256 pos50 = _mm256_i32gather_ps(Xbase + K * 0, indices_p5, 4);\n",
      "                __m256 pos60 = _mm256_i32gather_ps(Xbase + K * 0, indices_p6, 4);\n",
      "                __m256 pos70 = _mm256_i32gather_ps(Xbase + K * 0, indices_p7, 4);\n",
      "                __m256 pos01 = _mm256_i32gather_ps(Xbase + K * 1, indices_p0, 4);\n",
      "                __m256 pos11 = _mm256_i32gather_ps(Xbase + K * 1, indices_p1, 4);\n",
      "                __m256 pos21 = _mm256_i32gather_ps(Xbase + K * 1, indices_p2, 4);\n",
      "                __m256 pos31 = _mm256_i32gather_ps(Xbase + K * 1, indices_p3, 4);\n",
      "                __m256 pos41 = _mm256_i32gather_ps(Xbase + K * 1, indices_p4, 4);\n",
      "                __m256 pos51 = _mm256_i32gather_ps(Xbase + K * 1, indices_p5, 4);\n",
      "                __m256 pos61 = _mm256_i32gather_ps(Xbase + K * 1, indices_p6, 4);\n",
      "                __m256 pos71 = _mm256_i32gather_ps(Xbase + K * 1, indices_p7, 4);\n",
      "                __m256 neg00 = _mm256_i32gather_ps(Xbase + K * 0, indices_n0, 4);\n",
      "                __m256 neg10 = _mm256_i32gather_ps(Xbase + K * 0, indices_n1, 4);\n",
      "                __m256 neg20 = _mm256_i32gather_ps(Xbase + K * 0, indices_n2, 4);\n",
      "                __m256 neg30 = _mm256_i32gather_ps(Xbase + K * 0, indices_n3, 4);\n",
      "                __m256 neg40 = _mm256_i32gather_ps(Xbase + K * 0, indices_n4, 4);\n",
      "                __m256 neg50 = _mm256_i32gather_ps(Xbase + K * 0, indices_n5, 4);\n",
      "                __m256 neg60 = _mm256_i32gather_ps(Xbase + K * 0, indices_n6, 4);\n",
      "                __m256 neg70 = _mm256_i32gather_ps(Xbase + K * 0, indices_n7, 4);\n",
      "                __m256 neg01 = _mm256_i32gather_ps(Xbase + K * 1, indices_n0, 4);\n",
      "                __m256 neg11 = _mm256_i32gather_ps(Xbase + K * 1, indices_n1, 4);\n",
      "                __m256 neg21 = _mm256_i32gather_ps(Xbase + K * 1, indices_n2, 4);\n",
      "                __m256 neg31 = _mm256_i32gather_ps(Xbase + K * 1, indices_n3, 4);\n",
      "                __m256 neg41 = _mm256_i32gather_ps(Xbase + K * 1, indices_n4, 4);\n",
      "                __m256 neg51 = _mm256_i32gather_ps(Xbase + K * 1, indices_n5, 4);\n",
      "                __m256 neg61 = _mm256_i32gather_ps(Xbase + K * 1, indices_n6, 4);\n",
      "                __m256 neg71 = _mm256_i32gather_ps(Xbase + K * 1, indices_n7, 4);\n",
      "                res00 = _mm256_add_ps(res00, _mm256_sub_ps(pos00, neg00));\n",
      "                res10 = _mm256_add_ps(res10, _mm256_sub_ps(pos10, neg10));\n",
      "                res20 = _mm256_add_ps(res20, _mm256_sub_ps(pos20, neg20));\n",
      "                res30 = _mm256_add_ps(res30, _mm256_sub_ps(pos30, neg30));\n",
      "                res40 = _mm256_add_ps(res40, _mm256_sub_ps(pos40, neg40));\n",
      "                res50 = _mm256_add_ps(res50, _mm256_sub_ps(pos50, neg50));\n",
      "                res60 = _mm256_add_ps(res60, _mm256_sub_ps(pos60, neg60));\n",
      "                res70 = _mm256_add_ps(res70, _mm256_sub_ps(pos70, neg70));\n",
      "                res01 = _mm256_add_ps(res01, _mm256_sub_ps(pos01, neg01));\n",
      "                res11 = _mm256_add_ps(res11, _mm256_sub_ps(pos11, neg11));\n",
      "                res21 = _mm256_add_ps(res21, _mm256_sub_ps(pos21, neg21));\n",
      "                res31 = _mm256_add_ps(res31, _mm256_sub_ps(pos31, neg31));\n",
      "                res41 = _mm256_add_ps(res41, _mm256_sub_ps(pos41, neg41));\n",
      "                res51 = _mm256_add_ps(res51, _mm256_sub_ps(pos51, neg51));\n",
      "                res61 = _mm256_add_ps(res61, _mm256_sub_ps(pos61, neg61));\n",
      "                res71 = _mm256_add_ps(res71, _mm256_sub_ps(pos71, neg71));\n",
      "            }\n",
      "            float* Ybase = result + i * N_COL + j * 64;\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 0, res00);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 8, res10);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 16, res20);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 24, res30);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 32, res40);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 40, res50);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 48, res60);\n",
      "            _mm256_store_ps(Ybase + N_COL * 0 + 56, res70);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 0, res01);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 8, res11);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 16, res21);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 24, res31);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 32, res41);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 40, res51);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 48, res61);\n",
      "            _mm256_store_ps(Ybase + N_COL * 1 + 56, res71);\n",
      "            for (int g = 0; g < 64; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++) {\n",
      "                    Ybase[N_COL * 0 + g] += Xbase[K * 0 + row_index[k]];\n",
      "                    Ybase[N_COL * 1 + g] += Xbase[K * 1 + row_index[k]];\n",
      "                }\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++) {\n",
      "                    Ybase[N_COL * 0 + g] -= Xbase[K * 0 + row_index[k]];\n",
      "                    Ybase[N_COL * 1 + g] -= Xbase[K * 1 + row_index[k]];\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin\n",
    "M_UNROLL = 2\n",
    "N_UNROLL = 64\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "print(\"            float* Xbase = X + i * K;\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"            __m256 res\"+str(sn)+str(sm)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8 + 8*N_SIMD)+\"));\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        print(\"                __m256 pos\"+str(sn)+str(sm)+\" = _mm256_i32gather_ps(Xbase + K * \"+str(sm)+\", indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        print(\"                __m256 neg\"+str(sn)+str(sm)+\" = _mm256_i32gather_ps(Xbase + K * \"+str(sm)+\", indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + i * N_COL + j * \"+str(N_UNROLL)+\";\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "       print(\"            _mm256_store_ps(Ybase + N_COL * \"+str(sm)+\" + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "\n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL):\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++) {\")\n",
    "        for sm in range(M_UNROLL):\n",
    "            print(\"                    Ybase[N_COL * \"+str(sm)+\" + \"+str(sn)+\"] += Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "        print(\"                }\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++) {\")\n",
    "        for sm in range(M_UNROLL):\n",
    "            print(\"                    Ybase[N_COL * \"+str(sm)+\" + \"+str(sn)+\"] -= Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "        print(\"                }\")\n",
    "else:\n",
    "    print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "    print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++) {\")\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"                    Ybase[N_COL * \"+str(sm)+\" + g] += Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "    print(\"                }\")\n",
    "    print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++) {\")\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"                    Ybase[N_COL * \"+str(sm)+\" + g] -= Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "    print(\"                }\")\n",
    "    print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcffb7-0786-4b60-9086-cc43077e8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "void GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_1xG8_AVX2_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int M_ROW, int N_COL, int K) {\n",
    "    for (int i = 0; i < M_ROW; i ++) {\n",
    "    #pragma omp parallel for\n",
    "        for (int j = 0; j < N_COL / 8; j++) {\n",
    "            /* Pointer to where a column starts and ends\n",
    "            int align_start  = metadata[j * 10 + 0];\n",
    "            int align_end    = metadata[j * 10 + 1];\n",
    "            int +remain_end0 = metadata[j * 10 + 2];\n",
    "            int -remain_end0 = metadata[j * 10 + 3];\n",
    "            int +remain_end1 = metadata[j * 10 + 4];\n",
    "            int -remain_end1 = metadata[j * 10 + 5];\n",
    "            ...\n",
    "            */\n",
    "            // Group # = j, metadata per group = 18\n",
    "            int* groupData = &metadata[j * 18];        \n",
    "            __m256 res0 = _mm256_setzero_ps();\n",
    "            float* Xbase = X + i * K;\n",
    "            float* Ybase = result + i * N_COL + j * 8;\n",
    "            for (int k = groupData[0]; k < groupData[1]; k += 16) {\n",
    "                __m256i indices_p = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
    "                __m256i indices_n = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
    "                //__m128i indices_p = _mm128_load_si128(reinterpret_cast<const __m128i*>(row_index + k + 0));\n",
    "                //__m128i indices_n = _mm128_load_si128(reinterpret_cast<const __m128i*>(row_index + k + 8));\n",
    "                __m256 pos0 = _mm256_i32gather_ps(Xbase, indices_p, 4);\n",
    "                __m256 neg0 = _mm256_i32gather_ps(Xbase, indices_n, 4);\n",
    "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
    "            }\n",
    "            _mm256_store_ps(Ybase, res0);\n",
    "\n",
    "            #pragma unroll(8)\n",
    "            for (int g = 0; g < 8; g++) {\n",
    "                float pos00 = 0;\n",
    "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g+2]; k++) {\n",
    "                    pos00 += Xbase[row_index[k]];\n",
    "                }\n",
    "                Ybase[g]+=pos00;\n",
    "                float neg00 = 0;\n",
    "                for (int k = groupData[2 * g+2]; k < groupData[2 * g+3]; k++) {\n",
    "                    neg00 += Xbase[row_index[k]];\n",
    "                }\n",
    "                Ybase[g] -= neg00;\n",
    "            }          \n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5801dc5e-41d6-45af-9893-3960d887d87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G16_AVX2_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 16; j++) {\n",
      "            int* groupData = &metadata[j * 34]; \n",
      "            __m256 res0 = _mm256_setzero_ps();\n",
      "            __m256 res1 = _mm256_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 32) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256 pos0 = _mm256_i32gather_ps(X, indices_p0, 4);\n",
      "                __m256 pos1 = _mm256_i32gather_ps(X, indices_p1, 4);\n",
      "                __m256 neg0 = _mm256_i32gather_ps(X, indices_n0, 4);\n",
      "                __m256 neg1 = _mm256_i32gather_ps(X, indices_n1, 4);\n",
      "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
      "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
      "            }\n",
      "            float* Ybase = result + j * 16;\n",
      "            _mm256_store_ps(Ybase + 0, res0);\n",
      "            _mm256_store_ps(Ybase + 8, res1);\n",
      "            for (int g = 0; g < 16; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\n",
      "                    Ybase[g] += X[row_index[k]];\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\n",
      "                    Ybase[g] -= X[row_index[k]];\n",
      "            }\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin\n",
    "N_UNROLL = 16\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m256 res\"+str(sn)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8 + 8 * N_SIMD)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256 pos\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\") \n",
    "for sn in range(N_SIMD):  \n",
    "    print(\"                __m256 neg\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm256_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL): \n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] -= X[row_index[k]];\")\n",
    "else:\n",
    "        print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "        print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\")\n",
    "        print(\"                    Ybase[g] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\")\n",
    "        print(\"                    Ybase[g] -= X[row_index[k]];\")\n",
    "        print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02868a3e-2963-4a7a-ad13-7dd41f071ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G64_AVX2_OpenMP(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 64; j++) {\n",
      "            __m256 res0 = _mm256_setzero_ps();\n",
      "            __m256 res1 = _mm256_setzero_ps();\n",
      "            __m256 res2 = _mm256_setzero_ps();\n",
      "            __m256 res3 = _mm256_setzero_ps();\n",
      "            __m256 res4 = _mm256_setzero_ps();\n",
      "            __m256 res5 = _mm256_setzero_ps();\n",
      "            __m256 res6 = _mm256_setzero_ps();\n",
      "            __m256 res7 = _mm256_setzero_ps();\n",
      "            for (int k = j * 64 * NonZeroPerCol; k < (j + 1) * 64 * NonZeroPerCol; k += 128) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_p2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_p3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256i indices_p4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 32));\n",
      "                __m256i indices_p5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 40));\n",
      "                __m256i indices_p6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 48));\n",
      "                __m256i indices_p7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 56));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 64));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 72));\n",
      "                __m256i indices_n2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 80));\n",
      "                __m256i indices_n3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 88));\n",
      "                __m256i indices_n4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 96));\n",
      "                __m256i indices_n5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 104));\n",
      "                __m256i indices_n6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 112));\n",
      "                __m256i indices_n7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 120));\n",
      "                __m256 pos0 = _mm256_i32gather_ps(X, indices_p0, 4);\n",
      "                __m256 pos1 = _mm256_i32gather_ps(X, indices_p1, 4);\n",
      "                __m256 pos2 = _mm256_i32gather_ps(X, indices_p2, 4);\n",
      "                __m256 pos3 = _mm256_i32gather_ps(X, indices_p3, 4);\n",
      "                __m256 pos4 = _mm256_i32gather_ps(X, indices_p4, 4);\n",
      "                __m256 pos5 = _mm256_i32gather_ps(X, indices_p5, 4);\n",
      "                __m256 pos6 = _mm256_i32gather_ps(X, indices_p6, 4);\n",
      "                __m256 pos7 = _mm256_i32gather_ps(X, indices_p7, 4);\n",
      "                __m256 neg0 = _mm256_i32gather_ps(X, indices_n0, 4);\n",
      "                __m256 neg1 = _mm256_i32gather_ps(X, indices_n1, 4);\n",
      "                __m256 neg2 = _mm256_i32gather_ps(X, indices_n2, 4);\n",
      "                __m256 neg3 = _mm256_i32gather_ps(X, indices_n3, 4);\n",
      "                __m256 neg4 = _mm256_i32gather_ps(X, indices_n4, 4);\n",
      "                __m256 neg5 = _mm256_i32gather_ps(X, indices_n5, 4);\n",
      "                __m256 neg6 = _mm256_i32gather_ps(X, indices_n6, 4);\n",
      "                __m256 neg7 = _mm256_i32gather_ps(X, indices_n7, 4);\n",
      "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
      "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
      "                res2 = _mm256_add_ps(res2, _mm256_sub_ps(pos2, neg2));\n",
      "                res3 = _mm256_add_ps(res3, _mm256_sub_ps(pos3, neg3));\n",
      "                res4 = _mm256_add_ps(res4, _mm256_sub_ps(pos4, neg4));\n",
      "                res5 = _mm256_add_ps(res5, _mm256_sub_ps(pos5, neg5));\n",
      "                res6 = _mm256_add_ps(res6, _mm256_sub_ps(pos6, neg6));\n",
      "                res7 = _mm256_add_ps(res7, _mm256_sub_ps(pos7, neg7));\n",
      "            }\n",
      "            float* Ybase = result + j * 64;\n",
      "            _mm256_store_ps(Ybase + 0, res0);\n",
      "            _mm256_store_ps(Ybase + 8, res1);\n",
      "            _mm256_store_ps(Ybase + 16, res2);\n",
      "            _mm256_store_ps(Ybase + 24, res3);\n",
      "            _mm256_store_ps(Ybase + 32, res4);\n",
      "            _mm256_store_ps(Ybase + 40, res5);\n",
      "            _mm256_store_ps(Ybase + 48, res6);\n",
      "            _mm256_store_ps(Ybase + 56, res7);\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Uniform\n",
    "N_UNROLL = 64\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m256 res\"+str(sn)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * 8 + 8 * N_SIMD)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256 pos\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\") \n",
    "for sn in range(N_SIMD):  \n",
    "    print(\"                __m256 neg\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm256_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1286d45-9996-4a38-8577-6c5d3cca141b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin_64xG4_AVX2_OpenMP(float* X, int32_t* metadata, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 4; j++) {\n",
      "        int* groupData = &metadata[j * 10]; \n",
      "        for (int i = 0; i < M_ROW; i +=64) {\n",
      "            __m256 res00 = _mm256_setzero_ps();\n",
      "            __m256 res01 = _mm256_setzero_ps();\n",
      "            __m256 res02 = _mm256_setzero_ps();\n",
      "            __m256 res03 = _mm256_setzero_ps();\n",
      "            __m256 res04 = _mm256_setzero_ps();\n",
      "            __m256 res05 = _mm256_setzero_ps();\n",
      "            __m256 res06 = _mm256_setzero_ps();\n",
      "            __m256 res07 = _mm256_setzero_ps();\n",
      "            __m256 res10 = _mm256_setzero_ps();\n",
      "            __m256 res11 = _mm256_setzero_ps();\n",
      "            __m256 res12 = _mm256_setzero_ps();\n",
      "            __m256 res13 = _mm256_setzero_ps();\n",
      "            __m256 res14 = _mm256_setzero_ps();\n",
      "            __m256 res15 = _mm256_setzero_ps();\n",
      "            __m256 res16 = _mm256_setzero_ps();\n",
      "            __m256 res17 = _mm256_setzero_ps();\n",
      "            __m256 res20 = _mm256_setzero_ps();\n",
      "            __m256 res21 = _mm256_setzero_ps();\n",
      "            __m256 res22 = _mm256_setzero_ps();\n",
      "            __m256 res23 = _mm256_setzero_ps();\n",
      "            __m256 res24 = _mm256_setzero_ps();\n",
      "            __m256 res25 = _mm256_setzero_ps();\n",
      "            __m256 res26 = _mm256_setzero_ps();\n",
      "            __m256 res27 = _mm256_setzero_ps();\n",
      "            __m256 res30 = _mm256_setzero_ps();\n",
      "            __m256 res31 = _mm256_setzero_ps();\n",
      "            __m256 res32 = _mm256_setzero_ps();\n",
      "            __m256 res33 = _mm256_setzero_ps();\n",
      "            __m256 res34 = _mm256_setzero_ps();\n",
      "            __m256 res35 = _mm256_setzero_ps();\n",
      "            __m256 res36 = _mm256_setzero_ps();\n",
      "            __m256 res37 = _mm256_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 8) {\n",
      "                __m256 pos00 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 0);\n",
      "                __m256 neg00 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 0);\n",
      "                __m256 pos10 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 0);\n",
      "                __m256 neg10 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 0);\n",
      "                __m256 pos20 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 0);\n",
      "                __m256 neg20 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 0);\n",
      "                __m256 pos30 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 0);\n",
      "                __m256 neg30 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 0);\n",
      "                __m256 pos01 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 8);\n",
      "                __m256 neg01 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 8);\n",
      "                __m256 pos11 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 8);\n",
      "                __m256 neg11 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 8);\n",
      "                __m256 pos21 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 8);\n",
      "                __m256 neg21 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 8);\n",
      "                __m256 pos31 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 8);\n",
      "                __m256 neg31 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 8);\n",
      "                __m256 pos02 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 16);\n",
      "                __m256 neg02 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 16);\n",
      "                __m256 pos12 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 16);\n",
      "                __m256 neg12 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 16);\n",
      "                __m256 pos22 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 16);\n",
      "                __m256 neg22 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 16);\n",
      "                __m256 pos32 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 16);\n",
      "                __m256 neg32 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 16);\n",
      "                __m256 pos03 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 24);\n",
      "                __m256 neg03 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 24);\n",
      "                __m256 pos13 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 24);\n",
      "                __m256 neg13 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 24);\n",
      "                __m256 pos23 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 24);\n",
      "                __m256 neg23 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 24);\n",
      "                __m256 pos33 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 24);\n",
      "                __m256 neg33 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 24);\n",
      "                __m256 pos04 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 32);\n",
      "                __m256 neg04 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 32);\n",
      "                __m256 pos14 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 32);\n",
      "                __m256 neg14 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 32);\n",
      "                __m256 pos24 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 32);\n",
      "                __m256 neg24 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 32);\n",
      "                __m256 pos34 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 32);\n",
      "                __m256 neg34 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 32);\n",
      "                __m256 pos05 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 40);\n",
      "                __m256 neg05 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 40);\n",
      "                __m256 pos15 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 40);\n",
      "                __m256 neg15 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 40);\n",
      "                __m256 pos25 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 40);\n",
      "                __m256 neg25 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 40);\n",
      "                __m256 pos35 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 40);\n",
      "                __m256 neg35 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 40);\n",
      "                __m256 pos06 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 48);\n",
      "                __m256 neg06 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 48);\n",
      "                __m256 pos16 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 48);\n",
      "                __m256 neg16 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 48);\n",
      "                __m256 pos26 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 48);\n",
      "                __m256 neg26 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 48);\n",
      "                __m256 pos36 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 48);\n",
      "                __m256 neg36 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 48);\n",
      "                __m256 pos07 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 56);\n",
      "                __m256 neg07 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 56);\n",
      "                __m256 pos17 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 56);\n",
      "                __m256 neg17 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 56);\n",
      "                __m256 pos27 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 56);\n",
      "                __m256 neg27 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 56);\n",
      "                __m256 pos37 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 56);\n",
      "                __m256 neg37 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 56);\n",
      "                res00 = _mm256_add_ps(res00, _mm256_sub_ps(pos00, neg00));\n",
      "                res10 = _mm256_add_ps(res10, _mm256_sub_ps(pos10, neg10));\n",
      "                res20 = _mm256_add_ps(res20, _mm256_sub_ps(pos20, neg20));\n",
      "                res30 = _mm256_add_ps(res30, _mm256_sub_ps(pos30, neg30));\n",
      "                res01 = _mm256_add_ps(res01, _mm256_sub_ps(pos01, neg01));\n",
      "                res11 = _mm256_add_ps(res11, _mm256_sub_ps(pos11, neg11));\n",
      "                res21 = _mm256_add_ps(res21, _mm256_sub_ps(pos21, neg21));\n",
      "                res31 = _mm256_add_ps(res31, _mm256_sub_ps(pos31, neg31));\n",
      "                res02 = _mm256_add_ps(res02, _mm256_sub_ps(pos02, neg02));\n",
      "                res12 = _mm256_add_ps(res12, _mm256_sub_ps(pos12, neg12));\n",
      "                res22 = _mm256_add_ps(res22, _mm256_sub_ps(pos22, neg22));\n",
      "                res32 = _mm256_add_ps(res32, _mm256_sub_ps(pos32, neg32));\n",
      "                res03 = _mm256_add_ps(res03, _mm256_sub_ps(pos03, neg03));\n",
      "                res13 = _mm256_add_ps(res13, _mm256_sub_ps(pos13, neg13));\n",
      "                res23 = _mm256_add_ps(res23, _mm256_sub_ps(pos23, neg23));\n",
      "                res33 = _mm256_add_ps(res33, _mm256_sub_ps(pos33, neg33));\n",
      "                res04 = _mm256_add_ps(res04, _mm256_sub_ps(pos04, neg04));\n",
      "                res14 = _mm256_add_ps(res14, _mm256_sub_ps(pos14, neg14));\n",
      "                res24 = _mm256_add_ps(res24, _mm256_sub_ps(pos24, neg24));\n",
      "                res34 = _mm256_add_ps(res34, _mm256_sub_ps(pos34, neg34));\n",
      "                res05 = _mm256_add_ps(res05, _mm256_sub_ps(pos05, neg05));\n",
      "                res15 = _mm256_add_ps(res15, _mm256_sub_ps(pos15, neg15));\n",
      "                res25 = _mm256_add_ps(res25, _mm256_sub_ps(pos25, neg25));\n",
      "                res35 = _mm256_add_ps(res35, _mm256_sub_ps(pos35, neg35));\n",
      "                res06 = _mm256_add_ps(res06, _mm256_sub_ps(pos06, neg06));\n",
      "                res16 = _mm256_add_ps(res16, _mm256_sub_ps(pos16, neg16));\n",
      "                res26 = _mm256_add_ps(res26, _mm256_sub_ps(pos26, neg26));\n",
      "                res36 = _mm256_add_ps(res36, _mm256_sub_ps(pos36, neg36));\n",
      "                res07 = _mm256_add_ps(res07, _mm256_sub_ps(pos07, neg07));\n",
      "                res17 = _mm256_add_ps(res17, _mm256_sub_ps(pos17, neg17));\n",
      "                res27 = _mm256_add_ps(res27, _mm256_sub_ps(pos27, neg27));\n",
      "                res37 = _mm256_add_ps(res37, _mm256_sub_ps(pos37, neg37));\n",
      "            }\n",
      "                for (int k = groupData[1]; k < groupData[2]; k++) {\n",
      "                    res00 = _mm256_add_ps(res00, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res01 = _mm256_add_ps(res01, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res02 = _mm256_add_ps(res02, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res03 = _mm256_add_ps(res03, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res04 = _mm256_add_ps(res04, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res05 = _mm256_add_ps(res05, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res06 = _mm256_add_ps(res06, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res07 = _mm256_add_ps(res07, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[2]; k < groupData[3]; k++) {\n",
      "                    res00 = _mm256_sub_ps(res00, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res01 = _mm256_sub_ps(res01, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res02 = _mm256_sub_ps(res02, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res03 = _mm256_sub_ps(res03, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res04 = _mm256_sub_ps(res04, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res05 = _mm256_sub_ps(res05, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res06 = _mm256_sub_ps(res06, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res07 = _mm256_sub_ps(res07, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[3]; k < groupData[4]; k++) {\n",
      "                    res10 = _mm256_add_ps(res10, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res11 = _mm256_add_ps(res11, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res12 = _mm256_add_ps(res12, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res13 = _mm256_add_ps(res13, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res14 = _mm256_add_ps(res14, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res15 = _mm256_add_ps(res15, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res16 = _mm256_add_ps(res16, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res17 = _mm256_add_ps(res17, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[4]; k < groupData[5]; k++) {\n",
      "                    res10 = _mm256_sub_ps(res10, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res11 = _mm256_sub_ps(res11, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res12 = _mm256_sub_ps(res12, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res13 = _mm256_sub_ps(res13, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res14 = _mm256_sub_ps(res14, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res15 = _mm256_sub_ps(res15, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res16 = _mm256_sub_ps(res16, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res17 = _mm256_sub_ps(res17, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[5]; k < groupData[6]; k++) {\n",
      "                    res20 = _mm256_add_ps(res20, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res21 = _mm256_add_ps(res21, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res22 = _mm256_add_ps(res22, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res23 = _mm256_add_ps(res23, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res24 = _mm256_add_ps(res24, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res25 = _mm256_add_ps(res25, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res26 = _mm256_add_ps(res26, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res27 = _mm256_add_ps(res27, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[6]; k < groupData[7]; k++) {\n",
      "                    res20 = _mm256_sub_ps(res20, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res21 = _mm256_sub_ps(res21, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res22 = _mm256_sub_ps(res22, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res23 = _mm256_sub_ps(res23, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res24 = _mm256_sub_ps(res24, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res25 = _mm256_sub_ps(res25, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res26 = _mm256_sub_ps(res26, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res27 = _mm256_sub_ps(res27, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[7]; k < groupData[8]; k++) {\n",
      "                    res30 = _mm256_add_ps(res30, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res31 = _mm256_add_ps(res31, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res32 = _mm256_add_ps(res32, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res33 = _mm256_add_ps(res33, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res34 = _mm256_add_ps(res34, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res35 = _mm256_add_ps(res35, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res36 = _mm256_add_ps(res36, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res37 = _mm256_add_ps(res37, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "                for (int k = groupData[8]; k < groupData[9]; k++) {\n",
      "                    res30 = _mm256_sub_ps(res30, _mm256_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res31 = _mm256_sub_ps(res31, _mm256_load_ps(X + row_index[k] * M_ROW + i + 8));\n",
      "                    res32 = _mm256_sub_ps(res32, _mm256_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                    res33 = _mm256_sub_ps(res33, _mm256_load_ps(X + row_index[k] * M_ROW + i + 24));\n",
      "                    res34 = _mm256_sub_ps(res34, _mm256_load_ps(X + row_index[k] * M_ROW + i + 32));\n",
      "                    res35 = _mm256_sub_ps(res35, _mm256_load_ps(X + row_index[k] * M_ROW + i + 40));\n",
      "                    res36 = _mm256_sub_ps(res36, _mm256_load_ps(X + row_index[k] * M_ROW + i + 48));\n",
      "                    res37 = _mm256_sub_ps(res37, _mm256_load_ps(X + row_index[k] * M_ROW + i + 56));\n",
      "                }\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 0, res00);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 0, res10);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 0, res20);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 0, res30);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 8, res01);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 8, res11);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 8, res21);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 8, res31);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 16, res02);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 16, res12);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 16, res22);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 16, res32);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 24, res03);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 24, res13);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 24, res23);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 24, res33);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 32, res04);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 32, res14);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 32, res24);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 32, res34);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 40, res05);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 40, res15);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 40, res25);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 40, res35);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 48, res06);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 48, res16);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 48, res26);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 48, res36);\n",
      "            _mm256_store_ps(result + (j * 4 + 0) * M_ROW  + i + 56, res07);\n",
      "            _mm256_store_ps(result + (j * 4 + 1) * M_ROW  + i + 56, res17);\n",
      "            _mm256_store_ps(result + (j * 4 + 2) * M_ROW  + i + 56, res27);\n",
      "            _mm256_store_ps(result + (j * 4 + 3) * M_ROW  + i + 56, res37);\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin\n",
    "M_UNROLL = 64\n",
    "N_UNROLL = 4\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = True\n",
    "M_SIMD = int(M_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"        int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL):\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"            __m256 res\"+str(sn)+str(sm)+\" = _mm256_setzero_ps();\")    \n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        print(\"                __m256 pos\"+str(sn)+str(sm)+\" = _mm256_load_ps(X + row_index[k + \"+str(sn*2+0)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")   \n",
    "        print(\"                __m256 neg\"+str(sn)+str(sm)+\" = _mm256_load_ps(X + row_index[k + \"+str(sn*2+1)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "\n",
    "for sn in range(N_UNROLL):\n",
    "    print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++) {\")\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"                    res\"+str(sn)+str(sm)+\" = _mm256_add_ps(res\"+str(sn)+str(sm)+\", _mm256_load_ps(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")\n",
    "    print(\"                }\")\n",
    "    print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++) {\")\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"                    res\"+str(sn)+str(sm)+\" = _mm256_sub_ps(res\"+str(sn)+str(sm)+\", _mm256_load_ps(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")\n",
    "    print(\"                }\")\n",
    "    \n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "       print(\"            _mm256_store_ps(result + (j * \"+str(N_UNROLL)+\" + \"+str(sn)+\") * M_ROW  + i + \"+str(sm*SIMD_SIZE)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e6368-f3b4-425f-b11a-9fd71d068fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "void GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin_8xG4_AVX2_OpenMP(float* X, int32_t* metadata, int16_t* row_index, float* result, int M_ROW, int N_COL, int K) {\n",
    "#pragma omp parallel for\n",
    "    for (int j = 0; j < N_COL/4; j ++) {\n",
    "        /* Pointer to where a column starts and ends\n",
    "        int align_start  = metadata[j * 10 + 0];\n",
    "        int align_end    = metadata[j * 10 + 1];\n",
    "        int +remain_end0 = metadata[j * 10 + 2];\n",
    "        int -remain_end0 = metadata[j * 10 + 3];\n",
    "        int +remain_end1 = metadata[j * 10 + 4];\n",
    "        int -remain_end1 = metadata[j * 10 + 5];\n",
    "        ...\n",
    "        */\n",
    "        // Group # = j, metadata per group = 10\n",
    "        int * groupData = &metadata[j * 10];\n",
    "\n",
    "        for (int i = 0; i < M_ROW; i += 8) {\n",
    "            __m256 res0 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res1 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res2 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res3 = _mm256_set1_ps(0.0f);\n",
    "\n",
    "            for (int k = groupData[0]; k < groupData[1]; k += 8) {\n",
    "                __m256 pos0 = _mm256_load_ps(&X[row_index[k + 0] * M_ROW + i]);\n",
    "                __m256 neg0 = _mm256_load_ps(&X[row_index[k + 1] * M_ROW + i]);\n",
    "                __m256 pos1 = _mm256_load_ps(&X[row_index[k + 2] * M_ROW + i]);\n",
    "                __m256 neg1 = _mm256_load_ps(&X[row_index[k + 3] * M_ROW + i]);\n",
    "                __m256 pos2 = _mm256_load_ps(&X[row_index[k + 4] * M_ROW + i]);\n",
    "                __m256 neg2 = _mm256_load_ps(&X[row_index[k + 5] * M_ROW + i]);\n",
    "                __m256 pos3 = _mm256_load_ps(&X[row_index[k + 6] * M_ROW + i]);\n",
    "                __m256 neg3 = _mm256_load_ps(&X[row_index[k + 7] * M_ROW + i]);\n",
    "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
    "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
    "                res2 = _mm256_add_ps(res2, _mm256_sub_ps(pos2, neg2));\n",
    "                res3 = _mm256_add_ps(res3, _mm256_sub_ps(pos3, neg3));\n",
    "            }\n",
    "\n",
    "            __m256 pos0 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[1]; k < groupData[2]; k++) {\n",
    "                pos0 = _mm256_add_ps(pos0, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res0 = _mm256_add_ps(res0, pos0);\n",
    "            __m256 neg0 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[2]; k < groupData[3]; k++) {\n",
    "                neg0 = _mm256_add_ps(neg0, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res0 = _mm256_sub_ps(res0, neg0);\n",
    "\n",
    "            __m256 pos1 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[3]; k < groupData[4]; k++) {\n",
    "                pos1 = _mm256_add_ps(pos1, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res1 = _mm256_add_ps(res1, pos1);\n",
    "            __m256 neg1 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[4]; k < groupData[5]; k++) {\n",
    "                neg1 = _mm256_add_ps(neg1, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res1 = _mm256_sub_ps(res1, neg1);\n",
    "\n",
    "            __m256 pos2 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[5]; k < groupData[6]; k++) {\n",
    "                pos2 = _mm256_add_ps(pos2, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res2 = _mm256_add_ps(res2, pos2);\n",
    "            __m256 neg2 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[6]; k < groupData[7]; k++) {\n",
    "                neg2 = _mm256_add_ps(neg2, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res2 = _mm256_sub_ps(res2, neg2);\n",
    "\n",
    "            __m256 pos3 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[7]; k < groupData[8]; k++) {\n",
    "                pos3 = _mm256_add_ps(pos3, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res3 = _mm256_add_ps(res3, pos3);\n",
    "            __m256 neg3 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = groupData[8]; k < groupData[9]; k++) {\n",
    "                neg3 = _mm256_add_ps(neg3, _mm256_load_ps(&X[row_index[k] * M_ROW + i]));\n",
    "            }\n",
    "            res3 = _mm256_sub_ps(res3, neg3);\n",
    "\n",
    "            _mm256_store_ps(&result[(j * 4 + 0) * M_ROW + i], res0);\n",
    "            _mm256_store_ps(&result[(j * 4 + 1) * M_ROW + i], res1);\n",
    "            _mm256_store_ps(&result[(j * 4 + 2) * M_ROW + i], res2);\n",
    "            _mm256_store_ps(&result[(j * 4 + 3) * M_ROW + i], res3);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f9f2223-0d9e-4719-a4d9-88b1b4ab3969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_colMajor_TCSC_Uniform_32xG32_AVX2_OpenMP(float* X, int32_t NonZeroPerCol, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 32; j++) {\n",
      "        for (int i = 0; i < M_ROW; i +=32) {\n",
      "            __m256 res00 = _mm256_setzero_ps();\n",
      "            __m256 res01 = _mm256_setzero_ps();\n",
      "            __m256 res02 = _mm256_setzero_ps();\n",
      "            __m256 res03 = _mm256_setzero_ps();\n",
      "            __m256 res10 = _mm256_setzero_ps();\n",
      "            __m256 res11 = _mm256_setzero_ps();\n",
      "            __m256 res12 = _mm256_setzero_ps();\n",
      "            __m256 res13 = _mm256_setzero_ps();\n",
      "            __m256 res20 = _mm256_setzero_ps();\n",
      "            __m256 res21 = _mm256_setzero_ps();\n",
      "            __m256 res22 = _mm256_setzero_ps();\n",
      "            __m256 res23 = _mm256_setzero_ps();\n",
      "            __m256 res30 = _mm256_setzero_ps();\n",
      "            __m256 res31 = _mm256_setzero_ps();\n",
      "            __m256 res32 = _mm256_setzero_ps();\n",
      "            __m256 res33 = _mm256_setzero_ps();\n",
      "            __m256 res40 = _mm256_setzero_ps();\n",
      "            __m256 res41 = _mm256_setzero_ps();\n",
      "            __m256 res42 = _mm256_setzero_ps();\n",
      "            __m256 res43 = _mm256_setzero_ps();\n",
      "            __m256 res50 = _mm256_setzero_ps();\n",
      "            __m256 res51 = _mm256_setzero_ps();\n",
      "            __m256 res52 = _mm256_setzero_ps();\n",
      "            __m256 res53 = _mm256_setzero_ps();\n",
      "            __m256 res60 = _mm256_setzero_ps();\n",
      "            __m256 res61 = _mm256_setzero_ps();\n",
      "            __m256 res62 = _mm256_setzero_ps();\n",
      "            __m256 res63 = _mm256_setzero_ps();\n",
      "            __m256 res70 = _mm256_setzero_ps();\n",
      "            __m256 res71 = _mm256_setzero_ps();\n",
      "            __m256 res72 = _mm256_setzero_ps();\n",
      "            __m256 res73 = _mm256_setzero_ps();\n",
      "            __m256 res80 = _mm256_setzero_ps();\n",
      "            __m256 res81 = _mm256_setzero_ps();\n",
      "            __m256 res82 = _mm256_setzero_ps();\n",
      "            __m256 res83 = _mm256_setzero_ps();\n",
      "            __m256 res90 = _mm256_setzero_ps();\n",
      "            __m256 res91 = _mm256_setzero_ps();\n",
      "            __m256 res92 = _mm256_setzero_ps();\n",
      "            __m256 res93 = _mm256_setzero_ps();\n",
      "            __m256 res100 = _mm256_setzero_ps();\n",
      "            __m256 res101 = _mm256_setzero_ps();\n",
      "            __m256 res102 = _mm256_setzero_ps();\n",
      "            __m256 res103 = _mm256_setzero_ps();\n",
      "            __m256 res110 = _mm256_setzero_ps();\n",
      "            __m256 res111 = _mm256_setzero_ps();\n",
      "            __m256 res112 = _mm256_setzero_ps();\n",
      "            __m256 res113 = _mm256_setzero_ps();\n",
      "            __m256 res120 = _mm256_setzero_ps();\n",
      "            __m256 res121 = _mm256_setzero_ps();\n",
      "            __m256 res122 = _mm256_setzero_ps();\n",
      "            __m256 res123 = _mm256_setzero_ps();\n",
      "            __m256 res130 = _mm256_setzero_ps();\n",
      "            __m256 res131 = _mm256_setzero_ps();\n",
      "            __m256 res132 = _mm256_setzero_ps();\n",
      "            __m256 res133 = _mm256_setzero_ps();\n",
      "            __m256 res140 = _mm256_setzero_ps();\n",
      "            __m256 res141 = _mm256_setzero_ps();\n",
      "            __m256 res142 = _mm256_setzero_ps();\n",
      "            __m256 res143 = _mm256_setzero_ps();\n",
      "            __m256 res150 = _mm256_setzero_ps();\n",
      "            __m256 res151 = _mm256_setzero_ps();\n",
      "            __m256 res152 = _mm256_setzero_ps();\n",
      "            __m256 res153 = _mm256_setzero_ps();\n",
      "            __m256 res160 = _mm256_setzero_ps();\n",
      "            __m256 res161 = _mm256_setzero_ps();\n",
      "            __m256 res162 = _mm256_setzero_ps();\n",
      "            __m256 res163 = _mm256_setzero_ps();\n",
      "            __m256 res170 = _mm256_setzero_ps();\n",
      "            __m256 res171 = _mm256_setzero_ps();\n",
      "            __m256 res172 = _mm256_setzero_ps();\n",
      "            __m256 res173 = _mm256_setzero_ps();\n",
      "            __m256 res180 = _mm256_setzero_ps();\n",
      "            __m256 res181 = _mm256_setzero_ps();\n",
      "            __m256 res182 = _mm256_setzero_ps();\n",
      "            __m256 res183 = _mm256_setzero_ps();\n",
      "            __m256 res190 = _mm256_setzero_ps();\n",
      "            __m256 res191 = _mm256_setzero_ps();\n",
      "            __m256 res192 = _mm256_setzero_ps();\n",
      "            __m256 res193 = _mm256_setzero_ps();\n",
      "            __m256 res200 = _mm256_setzero_ps();\n",
      "            __m256 res201 = _mm256_setzero_ps();\n",
      "            __m256 res202 = _mm256_setzero_ps();\n",
      "            __m256 res203 = _mm256_setzero_ps();\n",
      "            __m256 res210 = _mm256_setzero_ps();\n",
      "            __m256 res211 = _mm256_setzero_ps();\n",
      "            __m256 res212 = _mm256_setzero_ps();\n",
      "            __m256 res213 = _mm256_setzero_ps();\n",
      "            __m256 res220 = _mm256_setzero_ps();\n",
      "            __m256 res221 = _mm256_setzero_ps();\n",
      "            __m256 res222 = _mm256_setzero_ps();\n",
      "            __m256 res223 = _mm256_setzero_ps();\n",
      "            __m256 res230 = _mm256_setzero_ps();\n",
      "            __m256 res231 = _mm256_setzero_ps();\n",
      "            __m256 res232 = _mm256_setzero_ps();\n",
      "            __m256 res233 = _mm256_setzero_ps();\n",
      "            __m256 res240 = _mm256_setzero_ps();\n",
      "            __m256 res241 = _mm256_setzero_ps();\n",
      "            __m256 res242 = _mm256_setzero_ps();\n",
      "            __m256 res243 = _mm256_setzero_ps();\n",
      "            __m256 res250 = _mm256_setzero_ps();\n",
      "            __m256 res251 = _mm256_setzero_ps();\n",
      "            __m256 res252 = _mm256_setzero_ps();\n",
      "            __m256 res253 = _mm256_setzero_ps();\n",
      "            __m256 res260 = _mm256_setzero_ps();\n",
      "            __m256 res261 = _mm256_setzero_ps();\n",
      "            __m256 res262 = _mm256_setzero_ps();\n",
      "            __m256 res263 = _mm256_setzero_ps();\n",
      "            __m256 res270 = _mm256_setzero_ps();\n",
      "            __m256 res271 = _mm256_setzero_ps();\n",
      "            __m256 res272 = _mm256_setzero_ps();\n",
      "            __m256 res273 = _mm256_setzero_ps();\n",
      "            __m256 res280 = _mm256_setzero_ps();\n",
      "            __m256 res281 = _mm256_setzero_ps();\n",
      "            __m256 res282 = _mm256_setzero_ps();\n",
      "            __m256 res283 = _mm256_setzero_ps();\n",
      "            __m256 res290 = _mm256_setzero_ps();\n",
      "            __m256 res291 = _mm256_setzero_ps();\n",
      "            __m256 res292 = _mm256_setzero_ps();\n",
      "            __m256 res293 = _mm256_setzero_ps();\n",
      "            __m256 res300 = _mm256_setzero_ps();\n",
      "            __m256 res301 = _mm256_setzero_ps();\n",
      "            __m256 res302 = _mm256_setzero_ps();\n",
      "            __m256 res303 = _mm256_setzero_ps();\n",
      "            __m256 res310 = _mm256_setzero_ps();\n",
      "            __m256 res311 = _mm256_setzero_ps();\n",
      "            __m256 res312 = _mm256_setzero_ps();\n",
      "            __m256 res313 = _mm256_setzero_ps();\n",
      "            for (int k = j * 32 * NonZeroPerCol; k < (j + 1) * 32 * NonZeroPerCol; k += 64) {\n",
      "                __m256 pos00 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 0);\n",
      "                __m256 neg00 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 0);\n",
      "                __m256 pos10 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 0);\n",
      "                __m256 neg10 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 0);\n",
      "                __m256 pos20 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 0);\n",
      "                __m256 neg20 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 0);\n",
      "                __m256 pos30 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 0);\n",
      "                __m256 neg30 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 0);\n",
      "                __m256 pos40 = _mm256_load_ps(X + row_index[k + 8] * M_ROW + i + 0);\n",
      "                __m256 neg40 = _mm256_load_ps(X + row_index[k + 9] * M_ROW + i + 0);\n",
      "                __m256 pos50 = _mm256_load_ps(X + row_index[k + 10] * M_ROW + i + 0);\n",
      "                __m256 neg50 = _mm256_load_ps(X + row_index[k + 11] * M_ROW + i + 0);\n",
      "                __m256 pos60 = _mm256_load_ps(X + row_index[k + 12] * M_ROW + i + 0);\n",
      "                __m256 neg60 = _mm256_load_ps(X + row_index[k + 13] * M_ROW + i + 0);\n",
      "                __m256 pos70 = _mm256_load_ps(X + row_index[k + 14] * M_ROW + i + 0);\n",
      "                __m256 neg70 = _mm256_load_ps(X + row_index[k + 15] * M_ROW + i + 0);\n",
      "                __m256 pos80 = _mm256_load_ps(X + row_index[k + 16] * M_ROW + i + 0);\n",
      "                __m256 neg80 = _mm256_load_ps(X + row_index[k + 17] * M_ROW + i + 0);\n",
      "                __m256 pos90 = _mm256_load_ps(X + row_index[k + 18] * M_ROW + i + 0);\n",
      "                __m256 neg90 = _mm256_load_ps(X + row_index[k + 19] * M_ROW + i + 0);\n",
      "                __m256 pos100 = _mm256_load_ps(X + row_index[k + 20] * M_ROW + i + 0);\n",
      "                __m256 neg100 = _mm256_load_ps(X + row_index[k + 21] * M_ROW + i + 0);\n",
      "                __m256 pos110 = _mm256_load_ps(X + row_index[k + 22] * M_ROW + i + 0);\n",
      "                __m256 neg110 = _mm256_load_ps(X + row_index[k + 23] * M_ROW + i + 0);\n",
      "                __m256 pos120 = _mm256_load_ps(X + row_index[k + 24] * M_ROW + i + 0);\n",
      "                __m256 neg120 = _mm256_load_ps(X + row_index[k + 25] * M_ROW + i + 0);\n",
      "                __m256 pos130 = _mm256_load_ps(X + row_index[k + 26] * M_ROW + i + 0);\n",
      "                __m256 neg130 = _mm256_load_ps(X + row_index[k + 27] * M_ROW + i + 0);\n",
      "                __m256 pos140 = _mm256_load_ps(X + row_index[k + 28] * M_ROW + i + 0);\n",
      "                __m256 neg140 = _mm256_load_ps(X + row_index[k + 29] * M_ROW + i + 0);\n",
      "                __m256 pos150 = _mm256_load_ps(X + row_index[k + 30] * M_ROW + i + 0);\n",
      "                __m256 neg150 = _mm256_load_ps(X + row_index[k + 31] * M_ROW + i + 0);\n",
      "                __m256 pos160 = _mm256_load_ps(X + row_index[k + 32] * M_ROW + i + 0);\n",
      "                __m256 neg160 = _mm256_load_ps(X + row_index[k + 33] * M_ROW + i + 0);\n",
      "                __m256 pos170 = _mm256_load_ps(X + row_index[k + 34] * M_ROW + i + 0);\n",
      "                __m256 neg170 = _mm256_load_ps(X + row_index[k + 35] * M_ROW + i + 0);\n",
      "                __m256 pos180 = _mm256_load_ps(X + row_index[k + 36] * M_ROW + i + 0);\n",
      "                __m256 neg180 = _mm256_load_ps(X + row_index[k + 37] * M_ROW + i + 0);\n",
      "                __m256 pos190 = _mm256_load_ps(X + row_index[k + 38] * M_ROW + i + 0);\n",
      "                __m256 neg190 = _mm256_load_ps(X + row_index[k + 39] * M_ROW + i + 0);\n",
      "                __m256 pos200 = _mm256_load_ps(X + row_index[k + 40] * M_ROW + i + 0);\n",
      "                __m256 neg200 = _mm256_load_ps(X + row_index[k + 41] * M_ROW + i + 0);\n",
      "                __m256 pos210 = _mm256_load_ps(X + row_index[k + 42] * M_ROW + i + 0);\n",
      "                __m256 neg210 = _mm256_load_ps(X + row_index[k + 43] * M_ROW + i + 0);\n",
      "                __m256 pos220 = _mm256_load_ps(X + row_index[k + 44] * M_ROW + i + 0);\n",
      "                __m256 neg220 = _mm256_load_ps(X + row_index[k + 45] * M_ROW + i + 0);\n",
      "                __m256 pos230 = _mm256_load_ps(X + row_index[k + 46] * M_ROW + i + 0);\n",
      "                __m256 neg230 = _mm256_load_ps(X + row_index[k + 47] * M_ROW + i + 0);\n",
      "                __m256 pos240 = _mm256_load_ps(X + row_index[k + 48] * M_ROW + i + 0);\n",
      "                __m256 neg240 = _mm256_load_ps(X + row_index[k + 49] * M_ROW + i + 0);\n",
      "                __m256 pos250 = _mm256_load_ps(X + row_index[k + 50] * M_ROW + i + 0);\n",
      "                __m256 neg250 = _mm256_load_ps(X + row_index[k + 51] * M_ROW + i + 0);\n",
      "                __m256 pos260 = _mm256_load_ps(X + row_index[k + 52] * M_ROW + i + 0);\n",
      "                __m256 neg260 = _mm256_load_ps(X + row_index[k + 53] * M_ROW + i + 0);\n",
      "                __m256 pos270 = _mm256_load_ps(X + row_index[k + 54] * M_ROW + i + 0);\n",
      "                __m256 neg270 = _mm256_load_ps(X + row_index[k + 55] * M_ROW + i + 0);\n",
      "                __m256 pos280 = _mm256_load_ps(X + row_index[k + 56] * M_ROW + i + 0);\n",
      "                __m256 neg280 = _mm256_load_ps(X + row_index[k + 57] * M_ROW + i + 0);\n",
      "                __m256 pos290 = _mm256_load_ps(X + row_index[k + 58] * M_ROW + i + 0);\n",
      "                __m256 neg290 = _mm256_load_ps(X + row_index[k + 59] * M_ROW + i + 0);\n",
      "                __m256 pos300 = _mm256_load_ps(X + row_index[k + 60] * M_ROW + i + 0);\n",
      "                __m256 neg300 = _mm256_load_ps(X + row_index[k + 61] * M_ROW + i + 0);\n",
      "                __m256 pos310 = _mm256_load_ps(X + row_index[k + 62] * M_ROW + i + 0);\n",
      "                __m256 neg310 = _mm256_load_ps(X + row_index[k + 63] * M_ROW + i + 0);\n",
      "                __m256 pos01 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 8);\n",
      "                __m256 neg01 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 8);\n",
      "                __m256 pos11 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 8);\n",
      "                __m256 neg11 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 8);\n",
      "                __m256 pos21 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 8);\n",
      "                __m256 neg21 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 8);\n",
      "                __m256 pos31 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 8);\n",
      "                __m256 neg31 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 8);\n",
      "                __m256 pos41 = _mm256_load_ps(X + row_index[k + 8] * M_ROW + i + 8);\n",
      "                __m256 neg41 = _mm256_load_ps(X + row_index[k + 9] * M_ROW + i + 8);\n",
      "                __m256 pos51 = _mm256_load_ps(X + row_index[k + 10] * M_ROW + i + 8);\n",
      "                __m256 neg51 = _mm256_load_ps(X + row_index[k + 11] * M_ROW + i + 8);\n",
      "                __m256 pos61 = _mm256_load_ps(X + row_index[k + 12] * M_ROW + i + 8);\n",
      "                __m256 neg61 = _mm256_load_ps(X + row_index[k + 13] * M_ROW + i + 8);\n",
      "                __m256 pos71 = _mm256_load_ps(X + row_index[k + 14] * M_ROW + i + 8);\n",
      "                __m256 neg71 = _mm256_load_ps(X + row_index[k + 15] * M_ROW + i + 8);\n",
      "                __m256 pos81 = _mm256_load_ps(X + row_index[k + 16] * M_ROW + i + 8);\n",
      "                __m256 neg81 = _mm256_load_ps(X + row_index[k + 17] * M_ROW + i + 8);\n",
      "                __m256 pos91 = _mm256_load_ps(X + row_index[k + 18] * M_ROW + i + 8);\n",
      "                __m256 neg91 = _mm256_load_ps(X + row_index[k + 19] * M_ROW + i + 8);\n",
      "                __m256 pos101 = _mm256_load_ps(X + row_index[k + 20] * M_ROW + i + 8);\n",
      "                __m256 neg101 = _mm256_load_ps(X + row_index[k + 21] * M_ROW + i + 8);\n",
      "                __m256 pos111 = _mm256_load_ps(X + row_index[k + 22] * M_ROW + i + 8);\n",
      "                __m256 neg111 = _mm256_load_ps(X + row_index[k + 23] * M_ROW + i + 8);\n",
      "                __m256 pos121 = _mm256_load_ps(X + row_index[k + 24] * M_ROW + i + 8);\n",
      "                __m256 neg121 = _mm256_load_ps(X + row_index[k + 25] * M_ROW + i + 8);\n",
      "                __m256 pos131 = _mm256_load_ps(X + row_index[k + 26] * M_ROW + i + 8);\n",
      "                __m256 neg131 = _mm256_load_ps(X + row_index[k + 27] * M_ROW + i + 8);\n",
      "                __m256 pos141 = _mm256_load_ps(X + row_index[k + 28] * M_ROW + i + 8);\n",
      "                __m256 neg141 = _mm256_load_ps(X + row_index[k + 29] * M_ROW + i + 8);\n",
      "                __m256 pos151 = _mm256_load_ps(X + row_index[k + 30] * M_ROW + i + 8);\n",
      "                __m256 neg151 = _mm256_load_ps(X + row_index[k + 31] * M_ROW + i + 8);\n",
      "                __m256 pos161 = _mm256_load_ps(X + row_index[k + 32] * M_ROW + i + 8);\n",
      "                __m256 neg161 = _mm256_load_ps(X + row_index[k + 33] * M_ROW + i + 8);\n",
      "                __m256 pos171 = _mm256_load_ps(X + row_index[k + 34] * M_ROW + i + 8);\n",
      "                __m256 neg171 = _mm256_load_ps(X + row_index[k + 35] * M_ROW + i + 8);\n",
      "                __m256 pos181 = _mm256_load_ps(X + row_index[k + 36] * M_ROW + i + 8);\n",
      "                __m256 neg181 = _mm256_load_ps(X + row_index[k + 37] * M_ROW + i + 8);\n",
      "                __m256 pos191 = _mm256_load_ps(X + row_index[k + 38] * M_ROW + i + 8);\n",
      "                __m256 neg191 = _mm256_load_ps(X + row_index[k + 39] * M_ROW + i + 8);\n",
      "                __m256 pos201 = _mm256_load_ps(X + row_index[k + 40] * M_ROW + i + 8);\n",
      "                __m256 neg201 = _mm256_load_ps(X + row_index[k + 41] * M_ROW + i + 8);\n",
      "                __m256 pos211 = _mm256_load_ps(X + row_index[k + 42] * M_ROW + i + 8);\n",
      "                __m256 neg211 = _mm256_load_ps(X + row_index[k + 43] * M_ROW + i + 8);\n",
      "                __m256 pos221 = _mm256_load_ps(X + row_index[k + 44] * M_ROW + i + 8);\n",
      "                __m256 neg221 = _mm256_load_ps(X + row_index[k + 45] * M_ROW + i + 8);\n",
      "                __m256 pos231 = _mm256_load_ps(X + row_index[k + 46] * M_ROW + i + 8);\n",
      "                __m256 neg231 = _mm256_load_ps(X + row_index[k + 47] * M_ROW + i + 8);\n",
      "                __m256 pos241 = _mm256_load_ps(X + row_index[k + 48] * M_ROW + i + 8);\n",
      "                __m256 neg241 = _mm256_load_ps(X + row_index[k + 49] * M_ROW + i + 8);\n",
      "                __m256 pos251 = _mm256_load_ps(X + row_index[k + 50] * M_ROW + i + 8);\n",
      "                __m256 neg251 = _mm256_load_ps(X + row_index[k + 51] * M_ROW + i + 8);\n",
      "                __m256 pos261 = _mm256_load_ps(X + row_index[k + 52] * M_ROW + i + 8);\n",
      "                __m256 neg261 = _mm256_load_ps(X + row_index[k + 53] * M_ROW + i + 8);\n",
      "                __m256 pos271 = _mm256_load_ps(X + row_index[k + 54] * M_ROW + i + 8);\n",
      "                __m256 neg271 = _mm256_load_ps(X + row_index[k + 55] * M_ROW + i + 8);\n",
      "                __m256 pos281 = _mm256_load_ps(X + row_index[k + 56] * M_ROW + i + 8);\n",
      "                __m256 neg281 = _mm256_load_ps(X + row_index[k + 57] * M_ROW + i + 8);\n",
      "                __m256 pos291 = _mm256_load_ps(X + row_index[k + 58] * M_ROW + i + 8);\n",
      "                __m256 neg291 = _mm256_load_ps(X + row_index[k + 59] * M_ROW + i + 8);\n",
      "                __m256 pos301 = _mm256_load_ps(X + row_index[k + 60] * M_ROW + i + 8);\n",
      "                __m256 neg301 = _mm256_load_ps(X + row_index[k + 61] * M_ROW + i + 8);\n",
      "                __m256 pos311 = _mm256_load_ps(X + row_index[k + 62] * M_ROW + i + 8);\n",
      "                __m256 neg311 = _mm256_load_ps(X + row_index[k + 63] * M_ROW + i + 8);\n",
      "                __m256 pos02 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 16);\n",
      "                __m256 neg02 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 16);\n",
      "                __m256 pos12 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 16);\n",
      "                __m256 neg12 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 16);\n",
      "                __m256 pos22 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 16);\n",
      "                __m256 neg22 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 16);\n",
      "                __m256 pos32 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 16);\n",
      "                __m256 neg32 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 16);\n",
      "                __m256 pos42 = _mm256_load_ps(X + row_index[k + 8] * M_ROW + i + 16);\n",
      "                __m256 neg42 = _mm256_load_ps(X + row_index[k + 9] * M_ROW + i + 16);\n",
      "                __m256 pos52 = _mm256_load_ps(X + row_index[k + 10] * M_ROW + i + 16);\n",
      "                __m256 neg52 = _mm256_load_ps(X + row_index[k + 11] * M_ROW + i + 16);\n",
      "                __m256 pos62 = _mm256_load_ps(X + row_index[k + 12] * M_ROW + i + 16);\n",
      "                __m256 neg62 = _mm256_load_ps(X + row_index[k + 13] * M_ROW + i + 16);\n",
      "                __m256 pos72 = _mm256_load_ps(X + row_index[k + 14] * M_ROW + i + 16);\n",
      "                __m256 neg72 = _mm256_load_ps(X + row_index[k + 15] * M_ROW + i + 16);\n",
      "                __m256 pos82 = _mm256_load_ps(X + row_index[k + 16] * M_ROW + i + 16);\n",
      "                __m256 neg82 = _mm256_load_ps(X + row_index[k + 17] * M_ROW + i + 16);\n",
      "                __m256 pos92 = _mm256_load_ps(X + row_index[k + 18] * M_ROW + i + 16);\n",
      "                __m256 neg92 = _mm256_load_ps(X + row_index[k + 19] * M_ROW + i + 16);\n",
      "                __m256 pos102 = _mm256_load_ps(X + row_index[k + 20] * M_ROW + i + 16);\n",
      "                __m256 neg102 = _mm256_load_ps(X + row_index[k + 21] * M_ROW + i + 16);\n",
      "                __m256 pos112 = _mm256_load_ps(X + row_index[k + 22] * M_ROW + i + 16);\n",
      "                __m256 neg112 = _mm256_load_ps(X + row_index[k + 23] * M_ROW + i + 16);\n",
      "                __m256 pos122 = _mm256_load_ps(X + row_index[k + 24] * M_ROW + i + 16);\n",
      "                __m256 neg122 = _mm256_load_ps(X + row_index[k + 25] * M_ROW + i + 16);\n",
      "                __m256 pos132 = _mm256_load_ps(X + row_index[k + 26] * M_ROW + i + 16);\n",
      "                __m256 neg132 = _mm256_load_ps(X + row_index[k + 27] * M_ROW + i + 16);\n",
      "                __m256 pos142 = _mm256_load_ps(X + row_index[k + 28] * M_ROW + i + 16);\n",
      "                __m256 neg142 = _mm256_load_ps(X + row_index[k + 29] * M_ROW + i + 16);\n",
      "                __m256 pos152 = _mm256_load_ps(X + row_index[k + 30] * M_ROW + i + 16);\n",
      "                __m256 neg152 = _mm256_load_ps(X + row_index[k + 31] * M_ROW + i + 16);\n",
      "                __m256 pos162 = _mm256_load_ps(X + row_index[k + 32] * M_ROW + i + 16);\n",
      "                __m256 neg162 = _mm256_load_ps(X + row_index[k + 33] * M_ROW + i + 16);\n",
      "                __m256 pos172 = _mm256_load_ps(X + row_index[k + 34] * M_ROW + i + 16);\n",
      "                __m256 neg172 = _mm256_load_ps(X + row_index[k + 35] * M_ROW + i + 16);\n",
      "                __m256 pos182 = _mm256_load_ps(X + row_index[k + 36] * M_ROW + i + 16);\n",
      "                __m256 neg182 = _mm256_load_ps(X + row_index[k + 37] * M_ROW + i + 16);\n",
      "                __m256 pos192 = _mm256_load_ps(X + row_index[k + 38] * M_ROW + i + 16);\n",
      "                __m256 neg192 = _mm256_load_ps(X + row_index[k + 39] * M_ROW + i + 16);\n",
      "                __m256 pos202 = _mm256_load_ps(X + row_index[k + 40] * M_ROW + i + 16);\n",
      "                __m256 neg202 = _mm256_load_ps(X + row_index[k + 41] * M_ROW + i + 16);\n",
      "                __m256 pos212 = _mm256_load_ps(X + row_index[k + 42] * M_ROW + i + 16);\n",
      "                __m256 neg212 = _mm256_load_ps(X + row_index[k + 43] * M_ROW + i + 16);\n",
      "                __m256 pos222 = _mm256_load_ps(X + row_index[k + 44] * M_ROW + i + 16);\n",
      "                __m256 neg222 = _mm256_load_ps(X + row_index[k + 45] * M_ROW + i + 16);\n",
      "                __m256 pos232 = _mm256_load_ps(X + row_index[k + 46] * M_ROW + i + 16);\n",
      "                __m256 neg232 = _mm256_load_ps(X + row_index[k + 47] * M_ROW + i + 16);\n",
      "                __m256 pos242 = _mm256_load_ps(X + row_index[k + 48] * M_ROW + i + 16);\n",
      "                __m256 neg242 = _mm256_load_ps(X + row_index[k + 49] * M_ROW + i + 16);\n",
      "                __m256 pos252 = _mm256_load_ps(X + row_index[k + 50] * M_ROW + i + 16);\n",
      "                __m256 neg252 = _mm256_load_ps(X + row_index[k + 51] * M_ROW + i + 16);\n",
      "                __m256 pos262 = _mm256_load_ps(X + row_index[k + 52] * M_ROW + i + 16);\n",
      "                __m256 neg262 = _mm256_load_ps(X + row_index[k + 53] * M_ROW + i + 16);\n",
      "                __m256 pos272 = _mm256_load_ps(X + row_index[k + 54] * M_ROW + i + 16);\n",
      "                __m256 neg272 = _mm256_load_ps(X + row_index[k + 55] * M_ROW + i + 16);\n",
      "                __m256 pos282 = _mm256_load_ps(X + row_index[k + 56] * M_ROW + i + 16);\n",
      "                __m256 neg282 = _mm256_load_ps(X + row_index[k + 57] * M_ROW + i + 16);\n",
      "                __m256 pos292 = _mm256_load_ps(X + row_index[k + 58] * M_ROW + i + 16);\n",
      "                __m256 neg292 = _mm256_load_ps(X + row_index[k + 59] * M_ROW + i + 16);\n",
      "                __m256 pos302 = _mm256_load_ps(X + row_index[k + 60] * M_ROW + i + 16);\n",
      "                __m256 neg302 = _mm256_load_ps(X + row_index[k + 61] * M_ROW + i + 16);\n",
      "                __m256 pos312 = _mm256_load_ps(X + row_index[k + 62] * M_ROW + i + 16);\n",
      "                __m256 neg312 = _mm256_load_ps(X + row_index[k + 63] * M_ROW + i + 16);\n",
      "                __m256 pos03 = _mm256_load_ps(X + row_index[k + 0] * M_ROW + i + 24);\n",
      "                __m256 neg03 = _mm256_load_ps(X + row_index[k + 1] * M_ROW + i + 24);\n",
      "                __m256 pos13 = _mm256_load_ps(X + row_index[k + 2] * M_ROW + i + 24);\n",
      "                __m256 neg13 = _mm256_load_ps(X + row_index[k + 3] * M_ROW + i + 24);\n",
      "                __m256 pos23 = _mm256_load_ps(X + row_index[k + 4] * M_ROW + i + 24);\n",
      "                __m256 neg23 = _mm256_load_ps(X + row_index[k + 5] * M_ROW + i + 24);\n",
      "                __m256 pos33 = _mm256_load_ps(X + row_index[k + 6] * M_ROW + i + 24);\n",
      "                __m256 neg33 = _mm256_load_ps(X + row_index[k + 7] * M_ROW + i + 24);\n",
      "                __m256 pos43 = _mm256_load_ps(X + row_index[k + 8] * M_ROW + i + 24);\n",
      "                __m256 neg43 = _mm256_load_ps(X + row_index[k + 9] * M_ROW + i + 24);\n",
      "                __m256 pos53 = _mm256_load_ps(X + row_index[k + 10] * M_ROW + i + 24);\n",
      "                __m256 neg53 = _mm256_load_ps(X + row_index[k + 11] * M_ROW + i + 24);\n",
      "                __m256 pos63 = _mm256_load_ps(X + row_index[k + 12] * M_ROW + i + 24);\n",
      "                __m256 neg63 = _mm256_load_ps(X + row_index[k + 13] * M_ROW + i + 24);\n",
      "                __m256 pos73 = _mm256_load_ps(X + row_index[k + 14] * M_ROW + i + 24);\n",
      "                __m256 neg73 = _mm256_load_ps(X + row_index[k + 15] * M_ROW + i + 24);\n",
      "                __m256 pos83 = _mm256_load_ps(X + row_index[k + 16] * M_ROW + i + 24);\n",
      "                __m256 neg83 = _mm256_load_ps(X + row_index[k + 17] * M_ROW + i + 24);\n",
      "                __m256 pos93 = _mm256_load_ps(X + row_index[k + 18] * M_ROW + i + 24);\n",
      "                __m256 neg93 = _mm256_load_ps(X + row_index[k + 19] * M_ROW + i + 24);\n",
      "                __m256 pos103 = _mm256_load_ps(X + row_index[k + 20] * M_ROW + i + 24);\n",
      "                __m256 neg103 = _mm256_load_ps(X + row_index[k + 21] * M_ROW + i + 24);\n",
      "                __m256 pos113 = _mm256_load_ps(X + row_index[k + 22] * M_ROW + i + 24);\n",
      "                __m256 neg113 = _mm256_load_ps(X + row_index[k + 23] * M_ROW + i + 24);\n",
      "                __m256 pos123 = _mm256_load_ps(X + row_index[k + 24] * M_ROW + i + 24);\n",
      "                __m256 neg123 = _mm256_load_ps(X + row_index[k + 25] * M_ROW + i + 24);\n",
      "                __m256 pos133 = _mm256_load_ps(X + row_index[k + 26] * M_ROW + i + 24);\n",
      "                __m256 neg133 = _mm256_load_ps(X + row_index[k + 27] * M_ROW + i + 24);\n",
      "                __m256 pos143 = _mm256_load_ps(X + row_index[k + 28] * M_ROW + i + 24);\n",
      "                __m256 neg143 = _mm256_load_ps(X + row_index[k + 29] * M_ROW + i + 24);\n",
      "                __m256 pos153 = _mm256_load_ps(X + row_index[k + 30] * M_ROW + i + 24);\n",
      "                __m256 neg153 = _mm256_load_ps(X + row_index[k + 31] * M_ROW + i + 24);\n",
      "                __m256 pos163 = _mm256_load_ps(X + row_index[k + 32] * M_ROW + i + 24);\n",
      "                __m256 neg163 = _mm256_load_ps(X + row_index[k + 33] * M_ROW + i + 24);\n",
      "                __m256 pos173 = _mm256_load_ps(X + row_index[k + 34] * M_ROW + i + 24);\n",
      "                __m256 neg173 = _mm256_load_ps(X + row_index[k + 35] * M_ROW + i + 24);\n",
      "                __m256 pos183 = _mm256_load_ps(X + row_index[k + 36] * M_ROW + i + 24);\n",
      "                __m256 neg183 = _mm256_load_ps(X + row_index[k + 37] * M_ROW + i + 24);\n",
      "                __m256 pos193 = _mm256_load_ps(X + row_index[k + 38] * M_ROW + i + 24);\n",
      "                __m256 neg193 = _mm256_load_ps(X + row_index[k + 39] * M_ROW + i + 24);\n",
      "                __m256 pos203 = _mm256_load_ps(X + row_index[k + 40] * M_ROW + i + 24);\n",
      "                __m256 neg203 = _mm256_load_ps(X + row_index[k + 41] * M_ROW + i + 24);\n",
      "                __m256 pos213 = _mm256_load_ps(X + row_index[k + 42] * M_ROW + i + 24);\n",
      "                __m256 neg213 = _mm256_load_ps(X + row_index[k + 43] * M_ROW + i + 24);\n",
      "                __m256 pos223 = _mm256_load_ps(X + row_index[k + 44] * M_ROW + i + 24);\n",
      "                __m256 neg223 = _mm256_load_ps(X + row_index[k + 45] * M_ROW + i + 24);\n",
      "                __m256 pos233 = _mm256_load_ps(X + row_index[k + 46] * M_ROW + i + 24);\n",
      "                __m256 neg233 = _mm256_load_ps(X + row_index[k + 47] * M_ROW + i + 24);\n",
      "                __m256 pos243 = _mm256_load_ps(X + row_index[k + 48] * M_ROW + i + 24);\n",
      "                __m256 neg243 = _mm256_load_ps(X + row_index[k + 49] * M_ROW + i + 24);\n",
      "                __m256 pos253 = _mm256_load_ps(X + row_index[k + 50] * M_ROW + i + 24);\n",
      "                __m256 neg253 = _mm256_load_ps(X + row_index[k + 51] * M_ROW + i + 24);\n",
      "                __m256 pos263 = _mm256_load_ps(X + row_index[k + 52] * M_ROW + i + 24);\n",
      "                __m256 neg263 = _mm256_load_ps(X + row_index[k + 53] * M_ROW + i + 24);\n",
      "                __m256 pos273 = _mm256_load_ps(X + row_index[k + 54] * M_ROW + i + 24);\n",
      "                __m256 neg273 = _mm256_load_ps(X + row_index[k + 55] * M_ROW + i + 24);\n",
      "                __m256 pos283 = _mm256_load_ps(X + row_index[k + 56] * M_ROW + i + 24);\n",
      "                __m256 neg283 = _mm256_load_ps(X + row_index[k + 57] * M_ROW + i + 24);\n",
      "                __m256 pos293 = _mm256_load_ps(X + row_index[k + 58] * M_ROW + i + 24);\n",
      "                __m256 neg293 = _mm256_load_ps(X + row_index[k + 59] * M_ROW + i + 24);\n",
      "                __m256 pos303 = _mm256_load_ps(X + row_index[k + 60] * M_ROW + i + 24);\n",
      "                __m256 neg303 = _mm256_load_ps(X + row_index[k + 61] * M_ROW + i + 24);\n",
      "                __m256 pos313 = _mm256_load_ps(X + row_index[k + 62] * M_ROW + i + 24);\n",
      "                __m256 neg313 = _mm256_load_ps(X + row_index[k + 63] * M_ROW + i + 24);\n",
      "                res00 = _mm256_add_ps(res00, _mm256_sub_ps(pos00, neg00));\n",
      "                res10 = _mm256_add_ps(res10, _mm256_sub_ps(pos10, neg10));\n",
      "                res20 = _mm256_add_ps(res20, _mm256_sub_ps(pos20, neg20));\n",
      "                res30 = _mm256_add_ps(res30, _mm256_sub_ps(pos30, neg30));\n",
      "                res40 = _mm256_add_ps(res40, _mm256_sub_ps(pos40, neg40));\n",
      "                res50 = _mm256_add_ps(res50, _mm256_sub_ps(pos50, neg50));\n",
      "                res60 = _mm256_add_ps(res60, _mm256_sub_ps(pos60, neg60));\n",
      "                res70 = _mm256_add_ps(res70, _mm256_sub_ps(pos70, neg70));\n",
      "                res80 = _mm256_add_ps(res80, _mm256_sub_ps(pos80, neg80));\n",
      "                res90 = _mm256_add_ps(res90, _mm256_sub_ps(pos90, neg90));\n",
      "                res100 = _mm256_add_ps(res100, _mm256_sub_ps(pos100, neg100));\n",
      "                res110 = _mm256_add_ps(res110, _mm256_sub_ps(pos110, neg110));\n",
      "                res120 = _mm256_add_ps(res120, _mm256_sub_ps(pos120, neg120));\n",
      "                res130 = _mm256_add_ps(res130, _mm256_sub_ps(pos130, neg130));\n",
      "                res140 = _mm256_add_ps(res140, _mm256_sub_ps(pos140, neg140));\n",
      "                res150 = _mm256_add_ps(res150, _mm256_sub_ps(pos150, neg150));\n",
      "                res160 = _mm256_add_ps(res160, _mm256_sub_ps(pos160, neg160));\n",
      "                res170 = _mm256_add_ps(res170, _mm256_sub_ps(pos170, neg170));\n",
      "                res180 = _mm256_add_ps(res180, _mm256_sub_ps(pos180, neg180));\n",
      "                res190 = _mm256_add_ps(res190, _mm256_sub_ps(pos190, neg190));\n",
      "                res200 = _mm256_add_ps(res200, _mm256_sub_ps(pos200, neg200));\n",
      "                res210 = _mm256_add_ps(res210, _mm256_sub_ps(pos210, neg210));\n",
      "                res220 = _mm256_add_ps(res220, _mm256_sub_ps(pos220, neg220));\n",
      "                res230 = _mm256_add_ps(res230, _mm256_sub_ps(pos230, neg230));\n",
      "                res240 = _mm256_add_ps(res240, _mm256_sub_ps(pos240, neg240));\n",
      "                res250 = _mm256_add_ps(res250, _mm256_sub_ps(pos250, neg250));\n",
      "                res260 = _mm256_add_ps(res260, _mm256_sub_ps(pos260, neg260));\n",
      "                res270 = _mm256_add_ps(res270, _mm256_sub_ps(pos270, neg270));\n",
      "                res280 = _mm256_add_ps(res280, _mm256_sub_ps(pos280, neg280));\n",
      "                res290 = _mm256_add_ps(res290, _mm256_sub_ps(pos290, neg290));\n",
      "                res300 = _mm256_add_ps(res300, _mm256_sub_ps(pos300, neg300));\n",
      "                res310 = _mm256_add_ps(res310, _mm256_sub_ps(pos310, neg310));\n",
      "                res01 = _mm256_add_ps(res01, _mm256_sub_ps(pos01, neg01));\n",
      "                res11 = _mm256_add_ps(res11, _mm256_sub_ps(pos11, neg11));\n",
      "                res21 = _mm256_add_ps(res21, _mm256_sub_ps(pos21, neg21));\n",
      "                res31 = _mm256_add_ps(res31, _mm256_sub_ps(pos31, neg31));\n",
      "                res41 = _mm256_add_ps(res41, _mm256_sub_ps(pos41, neg41));\n",
      "                res51 = _mm256_add_ps(res51, _mm256_sub_ps(pos51, neg51));\n",
      "                res61 = _mm256_add_ps(res61, _mm256_sub_ps(pos61, neg61));\n",
      "                res71 = _mm256_add_ps(res71, _mm256_sub_ps(pos71, neg71));\n",
      "                res81 = _mm256_add_ps(res81, _mm256_sub_ps(pos81, neg81));\n",
      "                res91 = _mm256_add_ps(res91, _mm256_sub_ps(pos91, neg91));\n",
      "                res101 = _mm256_add_ps(res101, _mm256_sub_ps(pos101, neg101));\n",
      "                res111 = _mm256_add_ps(res111, _mm256_sub_ps(pos111, neg111));\n",
      "                res121 = _mm256_add_ps(res121, _mm256_sub_ps(pos121, neg121));\n",
      "                res131 = _mm256_add_ps(res131, _mm256_sub_ps(pos131, neg131));\n",
      "                res141 = _mm256_add_ps(res141, _mm256_sub_ps(pos141, neg141));\n",
      "                res151 = _mm256_add_ps(res151, _mm256_sub_ps(pos151, neg151));\n",
      "                res161 = _mm256_add_ps(res161, _mm256_sub_ps(pos161, neg161));\n",
      "                res171 = _mm256_add_ps(res171, _mm256_sub_ps(pos171, neg171));\n",
      "                res181 = _mm256_add_ps(res181, _mm256_sub_ps(pos181, neg181));\n",
      "                res191 = _mm256_add_ps(res191, _mm256_sub_ps(pos191, neg191));\n",
      "                res201 = _mm256_add_ps(res201, _mm256_sub_ps(pos201, neg201));\n",
      "                res211 = _mm256_add_ps(res211, _mm256_sub_ps(pos211, neg211));\n",
      "                res221 = _mm256_add_ps(res221, _mm256_sub_ps(pos221, neg221));\n",
      "                res231 = _mm256_add_ps(res231, _mm256_sub_ps(pos231, neg231));\n",
      "                res241 = _mm256_add_ps(res241, _mm256_sub_ps(pos241, neg241));\n",
      "                res251 = _mm256_add_ps(res251, _mm256_sub_ps(pos251, neg251));\n",
      "                res261 = _mm256_add_ps(res261, _mm256_sub_ps(pos261, neg261));\n",
      "                res271 = _mm256_add_ps(res271, _mm256_sub_ps(pos271, neg271));\n",
      "                res281 = _mm256_add_ps(res281, _mm256_sub_ps(pos281, neg281));\n",
      "                res291 = _mm256_add_ps(res291, _mm256_sub_ps(pos291, neg291));\n",
      "                res301 = _mm256_add_ps(res301, _mm256_sub_ps(pos301, neg301));\n",
      "                res311 = _mm256_add_ps(res311, _mm256_sub_ps(pos311, neg311));\n",
      "                res02 = _mm256_add_ps(res02, _mm256_sub_ps(pos02, neg02));\n",
      "                res12 = _mm256_add_ps(res12, _mm256_sub_ps(pos12, neg12));\n",
      "                res22 = _mm256_add_ps(res22, _mm256_sub_ps(pos22, neg22));\n",
      "                res32 = _mm256_add_ps(res32, _mm256_sub_ps(pos32, neg32));\n",
      "                res42 = _mm256_add_ps(res42, _mm256_sub_ps(pos42, neg42));\n",
      "                res52 = _mm256_add_ps(res52, _mm256_sub_ps(pos52, neg52));\n",
      "                res62 = _mm256_add_ps(res62, _mm256_sub_ps(pos62, neg62));\n",
      "                res72 = _mm256_add_ps(res72, _mm256_sub_ps(pos72, neg72));\n",
      "                res82 = _mm256_add_ps(res82, _mm256_sub_ps(pos82, neg82));\n",
      "                res92 = _mm256_add_ps(res92, _mm256_sub_ps(pos92, neg92));\n",
      "                res102 = _mm256_add_ps(res102, _mm256_sub_ps(pos102, neg102));\n",
      "                res112 = _mm256_add_ps(res112, _mm256_sub_ps(pos112, neg112));\n",
      "                res122 = _mm256_add_ps(res122, _mm256_sub_ps(pos122, neg122));\n",
      "                res132 = _mm256_add_ps(res132, _mm256_sub_ps(pos132, neg132));\n",
      "                res142 = _mm256_add_ps(res142, _mm256_sub_ps(pos142, neg142));\n",
      "                res152 = _mm256_add_ps(res152, _mm256_sub_ps(pos152, neg152));\n",
      "                res162 = _mm256_add_ps(res162, _mm256_sub_ps(pos162, neg162));\n",
      "                res172 = _mm256_add_ps(res172, _mm256_sub_ps(pos172, neg172));\n",
      "                res182 = _mm256_add_ps(res182, _mm256_sub_ps(pos182, neg182));\n",
      "                res192 = _mm256_add_ps(res192, _mm256_sub_ps(pos192, neg192));\n",
      "                res202 = _mm256_add_ps(res202, _mm256_sub_ps(pos202, neg202));\n",
      "                res212 = _mm256_add_ps(res212, _mm256_sub_ps(pos212, neg212));\n",
      "                res222 = _mm256_add_ps(res222, _mm256_sub_ps(pos222, neg222));\n",
      "                res232 = _mm256_add_ps(res232, _mm256_sub_ps(pos232, neg232));\n",
      "                res242 = _mm256_add_ps(res242, _mm256_sub_ps(pos242, neg242));\n",
      "                res252 = _mm256_add_ps(res252, _mm256_sub_ps(pos252, neg252));\n",
      "                res262 = _mm256_add_ps(res262, _mm256_sub_ps(pos262, neg262));\n",
      "                res272 = _mm256_add_ps(res272, _mm256_sub_ps(pos272, neg272));\n",
      "                res282 = _mm256_add_ps(res282, _mm256_sub_ps(pos282, neg282));\n",
      "                res292 = _mm256_add_ps(res292, _mm256_sub_ps(pos292, neg292));\n",
      "                res302 = _mm256_add_ps(res302, _mm256_sub_ps(pos302, neg302));\n",
      "                res312 = _mm256_add_ps(res312, _mm256_sub_ps(pos312, neg312));\n",
      "                res03 = _mm256_add_ps(res03, _mm256_sub_ps(pos03, neg03));\n",
      "                res13 = _mm256_add_ps(res13, _mm256_sub_ps(pos13, neg13));\n",
      "                res23 = _mm256_add_ps(res23, _mm256_sub_ps(pos23, neg23));\n",
      "                res33 = _mm256_add_ps(res33, _mm256_sub_ps(pos33, neg33));\n",
      "                res43 = _mm256_add_ps(res43, _mm256_sub_ps(pos43, neg43));\n",
      "                res53 = _mm256_add_ps(res53, _mm256_sub_ps(pos53, neg53));\n",
      "                res63 = _mm256_add_ps(res63, _mm256_sub_ps(pos63, neg63));\n",
      "                res73 = _mm256_add_ps(res73, _mm256_sub_ps(pos73, neg73));\n",
      "                res83 = _mm256_add_ps(res83, _mm256_sub_ps(pos83, neg83));\n",
      "                res93 = _mm256_add_ps(res93, _mm256_sub_ps(pos93, neg93));\n",
      "                res103 = _mm256_add_ps(res103, _mm256_sub_ps(pos103, neg103));\n",
      "                res113 = _mm256_add_ps(res113, _mm256_sub_ps(pos113, neg113));\n",
      "                res123 = _mm256_add_ps(res123, _mm256_sub_ps(pos123, neg123));\n",
      "                res133 = _mm256_add_ps(res133, _mm256_sub_ps(pos133, neg133));\n",
      "                res143 = _mm256_add_ps(res143, _mm256_sub_ps(pos143, neg143));\n",
      "                res153 = _mm256_add_ps(res153, _mm256_sub_ps(pos153, neg153));\n",
      "                res163 = _mm256_add_ps(res163, _mm256_sub_ps(pos163, neg163));\n",
      "                res173 = _mm256_add_ps(res173, _mm256_sub_ps(pos173, neg173));\n",
      "                res183 = _mm256_add_ps(res183, _mm256_sub_ps(pos183, neg183));\n",
      "                res193 = _mm256_add_ps(res193, _mm256_sub_ps(pos193, neg193));\n",
      "                res203 = _mm256_add_ps(res203, _mm256_sub_ps(pos203, neg203));\n",
      "                res213 = _mm256_add_ps(res213, _mm256_sub_ps(pos213, neg213));\n",
      "                res223 = _mm256_add_ps(res223, _mm256_sub_ps(pos223, neg223));\n",
      "                res233 = _mm256_add_ps(res233, _mm256_sub_ps(pos233, neg233));\n",
      "                res243 = _mm256_add_ps(res243, _mm256_sub_ps(pos243, neg243));\n",
      "                res253 = _mm256_add_ps(res253, _mm256_sub_ps(pos253, neg253));\n",
      "                res263 = _mm256_add_ps(res263, _mm256_sub_ps(pos263, neg263));\n",
      "                res273 = _mm256_add_ps(res273, _mm256_sub_ps(pos273, neg273));\n",
      "                res283 = _mm256_add_ps(res283, _mm256_sub_ps(pos283, neg283));\n",
      "                res293 = _mm256_add_ps(res293, _mm256_sub_ps(pos293, neg293));\n",
      "                res303 = _mm256_add_ps(res303, _mm256_sub_ps(pos303, neg303));\n",
      "                res313 = _mm256_add_ps(res313, _mm256_sub_ps(pos313, neg313));\n",
      "            }\n",
      "            _mm256_store_ps(result + (j * 32 + 0) * M_ROW  + i + 0, res00);\n",
      "            _mm256_store_ps(result + (j * 32 + 1) * M_ROW  + i + 0, res10);\n",
      "            _mm256_store_ps(result + (j * 32 + 2) * M_ROW  + i + 0, res20);\n",
      "            _mm256_store_ps(result + (j * 32 + 3) * M_ROW  + i + 0, res30);\n",
      "            _mm256_store_ps(result + (j * 32 + 4) * M_ROW  + i + 0, res40);\n",
      "            _mm256_store_ps(result + (j * 32 + 5) * M_ROW  + i + 0, res50);\n",
      "            _mm256_store_ps(result + (j * 32 + 6) * M_ROW  + i + 0, res60);\n",
      "            _mm256_store_ps(result + (j * 32 + 7) * M_ROW  + i + 0, res70);\n",
      "            _mm256_store_ps(result + (j * 32 + 8) * M_ROW  + i + 0, res80);\n",
      "            _mm256_store_ps(result + (j * 32 + 9) * M_ROW  + i + 0, res90);\n",
      "            _mm256_store_ps(result + (j * 32 + 10) * M_ROW  + i + 0, res100);\n",
      "            _mm256_store_ps(result + (j * 32 + 11) * M_ROW  + i + 0, res110);\n",
      "            _mm256_store_ps(result + (j * 32 + 12) * M_ROW  + i + 0, res120);\n",
      "            _mm256_store_ps(result + (j * 32 + 13) * M_ROW  + i + 0, res130);\n",
      "            _mm256_store_ps(result + (j * 32 + 14) * M_ROW  + i + 0, res140);\n",
      "            _mm256_store_ps(result + (j * 32 + 15) * M_ROW  + i + 0, res150);\n",
      "            _mm256_store_ps(result + (j * 32 + 16) * M_ROW  + i + 0, res160);\n",
      "            _mm256_store_ps(result + (j * 32 + 17) * M_ROW  + i + 0, res170);\n",
      "            _mm256_store_ps(result + (j * 32 + 18) * M_ROW  + i + 0, res180);\n",
      "            _mm256_store_ps(result + (j * 32 + 19) * M_ROW  + i + 0, res190);\n",
      "            _mm256_store_ps(result + (j * 32 + 20) * M_ROW  + i + 0, res200);\n",
      "            _mm256_store_ps(result + (j * 32 + 21) * M_ROW  + i + 0, res210);\n",
      "            _mm256_store_ps(result + (j * 32 + 22) * M_ROW  + i + 0, res220);\n",
      "            _mm256_store_ps(result + (j * 32 + 23) * M_ROW  + i + 0, res230);\n",
      "            _mm256_store_ps(result + (j * 32 + 24) * M_ROW  + i + 0, res240);\n",
      "            _mm256_store_ps(result + (j * 32 + 25) * M_ROW  + i + 0, res250);\n",
      "            _mm256_store_ps(result + (j * 32 + 26) * M_ROW  + i + 0, res260);\n",
      "            _mm256_store_ps(result + (j * 32 + 27) * M_ROW  + i + 0, res270);\n",
      "            _mm256_store_ps(result + (j * 32 + 28) * M_ROW  + i + 0, res280);\n",
      "            _mm256_store_ps(result + (j * 32 + 29) * M_ROW  + i + 0, res290);\n",
      "            _mm256_store_ps(result + (j * 32 + 30) * M_ROW  + i + 0, res300);\n",
      "            _mm256_store_ps(result + (j * 32 + 31) * M_ROW  + i + 0, res310);\n",
      "            _mm256_store_ps(result + (j * 32 + 0) * M_ROW  + i + 8, res01);\n",
      "            _mm256_store_ps(result + (j * 32 + 1) * M_ROW  + i + 8, res11);\n",
      "            _mm256_store_ps(result + (j * 32 + 2) * M_ROW  + i + 8, res21);\n",
      "            _mm256_store_ps(result + (j * 32 + 3) * M_ROW  + i + 8, res31);\n",
      "            _mm256_store_ps(result + (j * 32 + 4) * M_ROW  + i + 8, res41);\n",
      "            _mm256_store_ps(result + (j * 32 + 5) * M_ROW  + i + 8, res51);\n",
      "            _mm256_store_ps(result + (j * 32 + 6) * M_ROW  + i + 8, res61);\n",
      "            _mm256_store_ps(result + (j * 32 + 7) * M_ROW  + i + 8, res71);\n",
      "            _mm256_store_ps(result + (j * 32 + 8) * M_ROW  + i + 8, res81);\n",
      "            _mm256_store_ps(result + (j * 32 + 9) * M_ROW  + i + 8, res91);\n",
      "            _mm256_store_ps(result + (j * 32 + 10) * M_ROW  + i + 8, res101);\n",
      "            _mm256_store_ps(result + (j * 32 + 11) * M_ROW  + i + 8, res111);\n",
      "            _mm256_store_ps(result + (j * 32 + 12) * M_ROW  + i + 8, res121);\n",
      "            _mm256_store_ps(result + (j * 32 + 13) * M_ROW  + i + 8, res131);\n",
      "            _mm256_store_ps(result + (j * 32 + 14) * M_ROW  + i + 8, res141);\n",
      "            _mm256_store_ps(result + (j * 32 + 15) * M_ROW  + i + 8, res151);\n",
      "            _mm256_store_ps(result + (j * 32 + 16) * M_ROW  + i + 8, res161);\n",
      "            _mm256_store_ps(result + (j * 32 + 17) * M_ROW  + i + 8, res171);\n",
      "            _mm256_store_ps(result + (j * 32 + 18) * M_ROW  + i + 8, res181);\n",
      "            _mm256_store_ps(result + (j * 32 + 19) * M_ROW  + i + 8, res191);\n",
      "            _mm256_store_ps(result + (j * 32 + 20) * M_ROW  + i + 8, res201);\n",
      "            _mm256_store_ps(result + (j * 32 + 21) * M_ROW  + i + 8, res211);\n",
      "            _mm256_store_ps(result + (j * 32 + 22) * M_ROW  + i + 8, res221);\n",
      "            _mm256_store_ps(result + (j * 32 + 23) * M_ROW  + i + 8, res231);\n",
      "            _mm256_store_ps(result + (j * 32 + 24) * M_ROW  + i + 8, res241);\n",
      "            _mm256_store_ps(result + (j * 32 + 25) * M_ROW  + i + 8, res251);\n",
      "            _mm256_store_ps(result + (j * 32 + 26) * M_ROW  + i + 8, res261);\n",
      "            _mm256_store_ps(result + (j * 32 + 27) * M_ROW  + i + 8, res271);\n",
      "            _mm256_store_ps(result + (j * 32 + 28) * M_ROW  + i + 8, res281);\n",
      "            _mm256_store_ps(result + (j * 32 + 29) * M_ROW  + i + 8, res291);\n",
      "            _mm256_store_ps(result + (j * 32 + 30) * M_ROW  + i + 8, res301);\n",
      "            _mm256_store_ps(result + (j * 32 + 31) * M_ROW  + i + 8, res311);\n",
      "            _mm256_store_ps(result + (j * 32 + 0) * M_ROW  + i + 16, res02);\n",
      "            _mm256_store_ps(result + (j * 32 + 1) * M_ROW  + i + 16, res12);\n",
      "            _mm256_store_ps(result + (j * 32 + 2) * M_ROW  + i + 16, res22);\n",
      "            _mm256_store_ps(result + (j * 32 + 3) * M_ROW  + i + 16, res32);\n",
      "            _mm256_store_ps(result + (j * 32 + 4) * M_ROW  + i + 16, res42);\n",
      "            _mm256_store_ps(result + (j * 32 + 5) * M_ROW  + i + 16, res52);\n",
      "            _mm256_store_ps(result + (j * 32 + 6) * M_ROW  + i + 16, res62);\n",
      "            _mm256_store_ps(result + (j * 32 + 7) * M_ROW  + i + 16, res72);\n",
      "            _mm256_store_ps(result + (j * 32 + 8) * M_ROW  + i + 16, res82);\n",
      "            _mm256_store_ps(result + (j * 32 + 9) * M_ROW  + i + 16, res92);\n",
      "            _mm256_store_ps(result + (j * 32 + 10) * M_ROW  + i + 16, res102);\n",
      "            _mm256_store_ps(result + (j * 32 + 11) * M_ROW  + i + 16, res112);\n",
      "            _mm256_store_ps(result + (j * 32 + 12) * M_ROW  + i + 16, res122);\n",
      "            _mm256_store_ps(result + (j * 32 + 13) * M_ROW  + i + 16, res132);\n",
      "            _mm256_store_ps(result + (j * 32 + 14) * M_ROW  + i + 16, res142);\n",
      "            _mm256_store_ps(result + (j * 32 + 15) * M_ROW  + i + 16, res152);\n",
      "            _mm256_store_ps(result + (j * 32 + 16) * M_ROW  + i + 16, res162);\n",
      "            _mm256_store_ps(result + (j * 32 + 17) * M_ROW  + i + 16, res172);\n",
      "            _mm256_store_ps(result + (j * 32 + 18) * M_ROW  + i + 16, res182);\n",
      "            _mm256_store_ps(result + (j * 32 + 19) * M_ROW  + i + 16, res192);\n",
      "            _mm256_store_ps(result + (j * 32 + 20) * M_ROW  + i + 16, res202);\n",
      "            _mm256_store_ps(result + (j * 32 + 21) * M_ROW  + i + 16, res212);\n",
      "            _mm256_store_ps(result + (j * 32 + 22) * M_ROW  + i + 16, res222);\n",
      "            _mm256_store_ps(result + (j * 32 + 23) * M_ROW  + i + 16, res232);\n",
      "            _mm256_store_ps(result + (j * 32 + 24) * M_ROW  + i + 16, res242);\n",
      "            _mm256_store_ps(result + (j * 32 + 25) * M_ROW  + i + 16, res252);\n",
      "            _mm256_store_ps(result + (j * 32 + 26) * M_ROW  + i + 16, res262);\n",
      "            _mm256_store_ps(result + (j * 32 + 27) * M_ROW  + i + 16, res272);\n",
      "            _mm256_store_ps(result + (j * 32 + 28) * M_ROW  + i + 16, res282);\n",
      "            _mm256_store_ps(result + (j * 32 + 29) * M_ROW  + i + 16, res292);\n",
      "            _mm256_store_ps(result + (j * 32 + 30) * M_ROW  + i + 16, res302);\n",
      "            _mm256_store_ps(result + (j * 32 + 31) * M_ROW  + i + 16, res312);\n",
      "            _mm256_store_ps(result + (j * 32 + 0) * M_ROW  + i + 24, res03);\n",
      "            _mm256_store_ps(result + (j * 32 + 1) * M_ROW  + i + 24, res13);\n",
      "            _mm256_store_ps(result + (j * 32 + 2) * M_ROW  + i + 24, res23);\n",
      "            _mm256_store_ps(result + (j * 32 + 3) * M_ROW  + i + 24, res33);\n",
      "            _mm256_store_ps(result + (j * 32 + 4) * M_ROW  + i + 24, res43);\n",
      "            _mm256_store_ps(result + (j * 32 + 5) * M_ROW  + i + 24, res53);\n",
      "            _mm256_store_ps(result + (j * 32 + 6) * M_ROW  + i + 24, res63);\n",
      "            _mm256_store_ps(result + (j * 32 + 7) * M_ROW  + i + 24, res73);\n",
      "            _mm256_store_ps(result + (j * 32 + 8) * M_ROW  + i + 24, res83);\n",
      "            _mm256_store_ps(result + (j * 32 + 9) * M_ROW  + i + 24, res93);\n",
      "            _mm256_store_ps(result + (j * 32 + 10) * M_ROW  + i + 24, res103);\n",
      "            _mm256_store_ps(result + (j * 32 + 11) * M_ROW  + i + 24, res113);\n",
      "            _mm256_store_ps(result + (j * 32 + 12) * M_ROW  + i + 24, res123);\n",
      "            _mm256_store_ps(result + (j * 32 + 13) * M_ROW  + i + 24, res133);\n",
      "            _mm256_store_ps(result + (j * 32 + 14) * M_ROW  + i + 24, res143);\n",
      "            _mm256_store_ps(result + (j * 32 + 15) * M_ROW  + i + 24, res153);\n",
      "            _mm256_store_ps(result + (j * 32 + 16) * M_ROW  + i + 24, res163);\n",
      "            _mm256_store_ps(result + (j * 32 + 17) * M_ROW  + i + 24, res173);\n",
      "            _mm256_store_ps(result + (j * 32 + 18) * M_ROW  + i + 24, res183);\n",
      "            _mm256_store_ps(result + (j * 32 + 19) * M_ROW  + i + 24, res193);\n",
      "            _mm256_store_ps(result + (j * 32 + 20) * M_ROW  + i + 24, res203);\n",
      "            _mm256_store_ps(result + (j * 32 + 21) * M_ROW  + i + 24, res213);\n",
      "            _mm256_store_ps(result + (j * 32 + 22) * M_ROW  + i + 24, res223);\n",
      "            _mm256_store_ps(result + (j * 32 + 23) * M_ROW  + i + 24, res233);\n",
      "            _mm256_store_ps(result + (j * 32 + 24) * M_ROW  + i + 24, res243);\n",
      "            _mm256_store_ps(result + (j * 32 + 25) * M_ROW  + i + 24, res253);\n",
      "            _mm256_store_ps(result + (j * 32 + 26) * M_ROW  + i + 24, res263);\n",
      "            _mm256_store_ps(result + (j * 32 + 27) * M_ROW  + i + 24, res273);\n",
      "            _mm256_store_ps(result + (j * 32 + 28) * M_ROW  + i + 24, res283);\n",
      "            _mm256_store_ps(result + (j * 32 + 29) * M_ROW  + i + 24, res293);\n",
      "            _mm256_store_ps(result + (j * 32 + 30) * M_ROW  + i + 24, res303);\n",
      "            _mm256_store_ps(result + (j * 32 + 31) * M_ROW  + i + 24, res313);\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate Uniform TCSC colMajor\n",
    "M_UNROLL = 32\n",
    "N_UNROLL = 32\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = True\n",
    "M_SIMD = int(M_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_colMajor_TCSC_Uniform_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\") \n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL):\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"            __m256 res\"+str(sn)+str(sm)+\" = _mm256_setzero_ps();\")    \n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        print(\"                __m256 pos\"+str(sn)+str(sm)+\" = _mm256_load_ps(X + row_index[k + \"+str(sn*2+0)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")   \n",
    "        print(\"                __m256 neg\"+str(sn)+str(sm)+\" = _mm256_load_ps(X + row_index[k + \"+str(sn*2+1)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "       print(\"            _mm256_store_ps(result + (j * \"+str(N_UNROLL)+\" + \"+str(sn)+\") * M_ROW  + i + \"+str(sm*SIMD_SIZE)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833bff6b-cdd6-4c6e-bd0b-4b07d2feab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "void GEMM_CPU_FP32_colMajor_TCSC_Uniform_8xG4_AVX2_OpenMP(float* X, int32_t NonZeroPerCol, int16_t* row_index, float* result, int M_ROW, int N_COL, int K) {\n",
    "#pragma omp parallel for\n",
    "    for (int j = 0; j < N_COL/4; j ++) {\n",
    "        /* Pointer to where a column starts and ends\n",
    "        int align_start  = metadata[j + 0];\n",
    "        int align_end    = metadata[j + 1];\n",
    "        */\n",
    "        // Group # = j, metadata per group = 2\n",
    "        for (int i = 0; i < M_ROW; i += 8) {\n",
    "            __m256 res0 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res1 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res2 = _mm256_set1_ps(0.0f);\n",
    "            __m256 res3 = _mm256_set1_ps(0.0f);\n",
    "            for (int k = j * 4 * NonZeroPerCol; k < (j * 4 + 4)*NonZeroPerCol; k += 8) {\n",
    "                __m256 pos0 = _mm256_load_ps(&X[row_index[k + 0] * M_ROW + i]);\n",
    "                __m256 neg0 = _mm256_load_ps(&X[row_index[k + 1] * M_ROW + i]);\n",
    "                __m256 pos1 = _mm256_load_ps(&X[row_index[k + 2] * M_ROW + i]);\n",
    "                __m256 neg1 = _mm256_load_ps(&X[row_index[k + 3] * M_ROW + i]);\n",
    "                __m256 pos2 = _mm256_load_ps(&X[row_index[k + 4] * M_ROW + i]);\n",
    "                __m256 neg2 = _mm256_load_ps(&X[row_index[k + 5] * M_ROW + i]);\n",
    "                __m256 pos3 = _mm256_load_ps(&X[row_index[k + 6] * M_ROW + i]);\n",
    "                __m256 neg3 = _mm256_load_ps(&X[row_index[k + 7] * M_ROW + i]);\n",
    "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
    "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
    "                res2 = _mm256_add_ps(res2, _mm256_sub_ps(pos2, neg2));\n",
    "                res3 = _mm256_add_ps(res3, _mm256_sub_ps(pos3, neg3));\n",
    "            }\n",
    "            _mm256_store_ps(&result[(j * 4 + 0) * M_ROW + i], res0);\n",
    "            _mm256_store_ps(&result[(j * 4 + 1) * M_ROW + i], res1);\n",
    "            _mm256_store_ps(&result[(j * 4 + 2) * M_ROW + i], res2);\n",
    "            _mm256_store_ps(&result[(j * 4 + 3) * M_ROW + i], res3);\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf8736-62b8-4534-bbe6-ad68edbf11a7",
   "metadata": {},
   "source": [
    "# AVX-512 Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5616e54d-13e7-4e88-9957-56de00d7edd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin_32xG32_AVX512_OpenMP(float* X, int32_t* metadata, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 32; j++) {\n",
      "        int* groupData = &metadata[j * 66]; \n",
      "        for (int i = 0; i < M_ROW; i +=32) {\n",
      "            __m512 res00 = _mm512_setzero_ps();\n",
      "            __m512 res01 = _mm512_setzero_ps();\n",
      "            __m512 res10 = _mm512_setzero_ps();\n",
      "            __m512 res11 = _mm512_setzero_ps();\n",
      "            __m512 res20 = _mm512_setzero_ps();\n",
      "            __m512 res21 = _mm512_setzero_ps();\n",
      "            __m512 res30 = _mm512_setzero_ps();\n",
      "            __m512 res31 = _mm512_setzero_ps();\n",
      "            __m512 res40 = _mm512_setzero_ps();\n",
      "            __m512 res41 = _mm512_setzero_ps();\n",
      "            __m512 res50 = _mm512_setzero_ps();\n",
      "            __m512 res51 = _mm512_setzero_ps();\n",
      "            __m512 res60 = _mm512_setzero_ps();\n",
      "            __m512 res61 = _mm512_setzero_ps();\n",
      "            __m512 res70 = _mm512_setzero_ps();\n",
      "            __m512 res71 = _mm512_setzero_ps();\n",
      "            __m512 res80 = _mm512_setzero_ps();\n",
      "            __m512 res81 = _mm512_setzero_ps();\n",
      "            __m512 res90 = _mm512_setzero_ps();\n",
      "            __m512 res91 = _mm512_setzero_ps();\n",
      "            __m512 res100 = _mm512_setzero_ps();\n",
      "            __m512 res101 = _mm512_setzero_ps();\n",
      "            __m512 res110 = _mm512_setzero_ps();\n",
      "            __m512 res111 = _mm512_setzero_ps();\n",
      "            __m512 res120 = _mm512_setzero_ps();\n",
      "            __m512 res121 = _mm512_setzero_ps();\n",
      "            __m512 res130 = _mm512_setzero_ps();\n",
      "            __m512 res131 = _mm512_setzero_ps();\n",
      "            __m512 res140 = _mm512_setzero_ps();\n",
      "            __m512 res141 = _mm512_setzero_ps();\n",
      "            __m512 res150 = _mm512_setzero_ps();\n",
      "            __m512 res151 = _mm512_setzero_ps();\n",
      "            __m512 res160 = _mm512_setzero_ps();\n",
      "            __m512 res161 = _mm512_setzero_ps();\n",
      "            __m512 res170 = _mm512_setzero_ps();\n",
      "            __m512 res171 = _mm512_setzero_ps();\n",
      "            __m512 res180 = _mm512_setzero_ps();\n",
      "            __m512 res181 = _mm512_setzero_ps();\n",
      "            __m512 res190 = _mm512_setzero_ps();\n",
      "            __m512 res191 = _mm512_setzero_ps();\n",
      "            __m512 res200 = _mm512_setzero_ps();\n",
      "            __m512 res201 = _mm512_setzero_ps();\n",
      "            __m512 res210 = _mm512_setzero_ps();\n",
      "            __m512 res211 = _mm512_setzero_ps();\n",
      "            __m512 res220 = _mm512_setzero_ps();\n",
      "            __m512 res221 = _mm512_setzero_ps();\n",
      "            __m512 res230 = _mm512_setzero_ps();\n",
      "            __m512 res231 = _mm512_setzero_ps();\n",
      "            __m512 res240 = _mm512_setzero_ps();\n",
      "            __m512 res241 = _mm512_setzero_ps();\n",
      "            __m512 res250 = _mm512_setzero_ps();\n",
      "            __m512 res251 = _mm512_setzero_ps();\n",
      "            __m512 res260 = _mm512_setzero_ps();\n",
      "            __m512 res261 = _mm512_setzero_ps();\n",
      "            __m512 res270 = _mm512_setzero_ps();\n",
      "            __m512 res271 = _mm512_setzero_ps();\n",
      "            __m512 res280 = _mm512_setzero_ps();\n",
      "            __m512 res281 = _mm512_setzero_ps();\n",
      "            __m512 res290 = _mm512_setzero_ps();\n",
      "            __m512 res291 = _mm512_setzero_ps();\n",
      "            __m512 res300 = _mm512_setzero_ps();\n",
      "            __m512 res301 = _mm512_setzero_ps();\n",
      "            __m512 res310 = _mm512_setzero_ps();\n",
      "            __m512 res311 = _mm512_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 64) {\n",
      "                __m512 pos00 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 0);\n",
      "                __m512 neg00 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 0);\n",
      "                __m512 pos10 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 0);\n",
      "                __m512 neg10 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 0);\n",
      "                __m512 pos20 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 0);\n",
      "                __m512 neg20 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 0);\n",
      "                __m512 pos30 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 0);\n",
      "                __m512 neg30 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 0);\n",
      "                __m512 pos40 = _mm512_load_ps(X + row_index[k + 8] * M_ROW + i + 0);\n",
      "                __m512 neg40 = _mm512_load_ps(X + row_index[k + 9] * M_ROW + i + 0);\n",
      "                __m512 pos50 = _mm512_load_ps(X + row_index[k + 10] * M_ROW + i + 0);\n",
      "                __m512 neg50 = _mm512_load_ps(X + row_index[k + 11] * M_ROW + i + 0);\n",
      "                __m512 pos60 = _mm512_load_ps(X + row_index[k + 12] * M_ROW + i + 0);\n",
      "                __m512 neg60 = _mm512_load_ps(X + row_index[k + 13] * M_ROW + i + 0);\n",
      "                __m512 pos70 = _mm512_load_ps(X + row_index[k + 14] * M_ROW + i + 0);\n",
      "                __m512 neg70 = _mm512_load_ps(X + row_index[k + 15] * M_ROW + i + 0);\n",
      "                __m512 pos80 = _mm512_load_ps(X + row_index[k + 16] * M_ROW + i + 0);\n",
      "                __m512 neg80 = _mm512_load_ps(X + row_index[k + 17] * M_ROW + i + 0);\n",
      "                __m512 pos90 = _mm512_load_ps(X + row_index[k + 18] * M_ROW + i + 0);\n",
      "                __m512 neg90 = _mm512_load_ps(X + row_index[k + 19] * M_ROW + i + 0);\n",
      "                __m512 pos100 = _mm512_load_ps(X + row_index[k + 20] * M_ROW + i + 0);\n",
      "                __m512 neg100 = _mm512_load_ps(X + row_index[k + 21] * M_ROW + i + 0);\n",
      "                __m512 pos110 = _mm512_load_ps(X + row_index[k + 22] * M_ROW + i + 0);\n",
      "                __m512 neg110 = _mm512_load_ps(X + row_index[k + 23] * M_ROW + i + 0);\n",
      "                __m512 pos120 = _mm512_load_ps(X + row_index[k + 24] * M_ROW + i + 0);\n",
      "                __m512 neg120 = _mm512_load_ps(X + row_index[k + 25] * M_ROW + i + 0);\n",
      "                __m512 pos130 = _mm512_load_ps(X + row_index[k + 26] * M_ROW + i + 0);\n",
      "                __m512 neg130 = _mm512_load_ps(X + row_index[k + 27] * M_ROW + i + 0);\n",
      "                __m512 pos140 = _mm512_load_ps(X + row_index[k + 28] * M_ROW + i + 0);\n",
      "                __m512 neg140 = _mm512_load_ps(X + row_index[k + 29] * M_ROW + i + 0);\n",
      "                __m512 pos150 = _mm512_load_ps(X + row_index[k + 30] * M_ROW + i + 0);\n",
      "                __m512 neg150 = _mm512_load_ps(X + row_index[k + 31] * M_ROW + i + 0);\n",
      "                __m512 pos160 = _mm512_load_ps(X + row_index[k + 32] * M_ROW + i + 0);\n",
      "                __m512 neg160 = _mm512_load_ps(X + row_index[k + 33] * M_ROW + i + 0);\n",
      "                __m512 pos170 = _mm512_load_ps(X + row_index[k + 34] * M_ROW + i + 0);\n",
      "                __m512 neg170 = _mm512_load_ps(X + row_index[k + 35] * M_ROW + i + 0);\n",
      "                __m512 pos180 = _mm512_load_ps(X + row_index[k + 36] * M_ROW + i + 0);\n",
      "                __m512 neg180 = _mm512_load_ps(X + row_index[k + 37] * M_ROW + i + 0);\n",
      "                __m512 pos190 = _mm512_load_ps(X + row_index[k + 38] * M_ROW + i + 0);\n",
      "                __m512 neg190 = _mm512_load_ps(X + row_index[k + 39] * M_ROW + i + 0);\n",
      "                __m512 pos200 = _mm512_load_ps(X + row_index[k + 40] * M_ROW + i + 0);\n",
      "                __m512 neg200 = _mm512_load_ps(X + row_index[k + 41] * M_ROW + i + 0);\n",
      "                __m512 pos210 = _mm512_load_ps(X + row_index[k + 42] * M_ROW + i + 0);\n",
      "                __m512 neg210 = _mm512_load_ps(X + row_index[k + 43] * M_ROW + i + 0);\n",
      "                __m512 pos220 = _mm512_load_ps(X + row_index[k + 44] * M_ROW + i + 0);\n",
      "                __m512 neg220 = _mm512_load_ps(X + row_index[k + 45] * M_ROW + i + 0);\n",
      "                __m512 pos230 = _mm512_load_ps(X + row_index[k + 46] * M_ROW + i + 0);\n",
      "                __m512 neg230 = _mm512_load_ps(X + row_index[k + 47] * M_ROW + i + 0);\n",
      "                __m512 pos240 = _mm512_load_ps(X + row_index[k + 48] * M_ROW + i + 0);\n",
      "                __m512 neg240 = _mm512_load_ps(X + row_index[k + 49] * M_ROW + i + 0);\n",
      "                __m512 pos250 = _mm512_load_ps(X + row_index[k + 50] * M_ROW + i + 0);\n",
      "                __m512 neg250 = _mm512_load_ps(X + row_index[k + 51] * M_ROW + i + 0);\n",
      "                __m512 pos260 = _mm512_load_ps(X + row_index[k + 52] * M_ROW + i + 0);\n",
      "                __m512 neg260 = _mm512_load_ps(X + row_index[k + 53] * M_ROW + i + 0);\n",
      "                __m512 pos270 = _mm512_load_ps(X + row_index[k + 54] * M_ROW + i + 0);\n",
      "                __m512 neg270 = _mm512_load_ps(X + row_index[k + 55] * M_ROW + i + 0);\n",
      "                __m512 pos280 = _mm512_load_ps(X + row_index[k + 56] * M_ROW + i + 0);\n",
      "                __m512 neg280 = _mm512_load_ps(X + row_index[k + 57] * M_ROW + i + 0);\n",
      "                __m512 pos290 = _mm512_load_ps(X + row_index[k + 58] * M_ROW + i + 0);\n",
      "                __m512 neg290 = _mm512_load_ps(X + row_index[k + 59] * M_ROW + i + 0);\n",
      "                __m512 pos300 = _mm512_load_ps(X + row_index[k + 60] * M_ROW + i + 0);\n",
      "                __m512 neg300 = _mm512_load_ps(X + row_index[k + 61] * M_ROW + i + 0);\n",
      "                __m512 pos310 = _mm512_load_ps(X + row_index[k + 62] * M_ROW + i + 0);\n",
      "                __m512 neg310 = _mm512_load_ps(X + row_index[k + 63] * M_ROW + i + 0);\n",
      "                __m512 pos01 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 16);\n",
      "                __m512 neg01 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 16);\n",
      "                __m512 pos11 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 16);\n",
      "                __m512 neg11 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 16);\n",
      "                __m512 pos21 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 16);\n",
      "                __m512 neg21 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 16);\n",
      "                __m512 pos31 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 16);\n",
      "                __m512 neg31 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 16);\n",
      "                __m512 pos41 = _mm512_load_ps(X + row_index[k + 8] * M_ROW + i + 16);\n",
      "                __m512 neg41 = _mm512_load_ps(X + row_index[k + 9] * M_ROW + i + 16);\n",
      "                __m512 pos51 = _mm512_load_ps(X + row_index[k + 10] * M_ROW + i + 16);\n",
      "                __m512 neg51 = _mm512_load_ps(X + row_index[k + 11] * M_ROW + i + 16);\n",
      "                __m512 pos61 = _mm512_load_ps(X + row_index[k + 12] * M_ROW + i + 16);\n",
      "                __m512 neg61 = _mm512_load_ps(X + row_index[k + 13] * M_ROW + i + 16);\n",
      "                __m512 pos71 = _mm512_load_ps(X + row_index[k + 14] * M_ROW + i + 16);\n",
      "                __m512 neg71 = _mm512_load_ps(X + row_index[k + 15] * M_ROW + i + 16);\n",
      "                __m512 pos81 = _mm512_load_ps(X + row_index[k + 16] * M_ROW + i + 16);\n",
      "                __m512 neg81 = _mm512_load_ps(X + row_index[k + 17] * M_ROW + i + 16);\n",
      "                __m512 pos91 = _mm512_load_ps(X + row_index[k + 18] * M_ROW + i + 16);\n",
      "                __m512 neg91 = _mm512_load_ps(X + row_index[k + 19] * M_ROW + i + 16);\n",
      "                __m512 pos101 = _mm512_load_ps(X + row_index[k + 20] * M_ROW + i + 16);\n",
      "                __m512 neg101 = _mm512_load_ps(X + row_index[k + 21] * M_ROW + i + 16);\n",
      "                __m512 pos111 = _mm512_load_ps(X + row_index[k + 22] * M_ROW + i + 16);\n",
      "                __m512 neg111 = _mm512_load_ps(X + row_index[k + 23] * M_ROW + i + 16);\n",
      "                __m512 pos121 = _mm512_load_ps(X + row_index[k + 24] * M_ROW + i + 16);\n",
      "                __m512 neg121 = _mm512_load_ps(X + row_index[k + 25] * M_ROW + i + 16);\n",
      "                __m512 pos131 = _mm512_load_ps(X + row_index[k + 26] * M_ROW + i + 16);\n",
      "                __m512 neg131 = _mm512_load_ps(X + row_index[k + 27] * M_ROW + i + 16);\n",
      "                __m512 pos141 = _mm512_load_ps(X + row_index[k + 28] * M_ROW + i + 16);\n",
      "                __m512 neg141 = _mm512_load_ps(X + row_index[k + 29] * M_ROW + i + 16);\n",
      "                __m512 pos151 = _mm512_load_ps(X + row_index[k + 30] * M_ROW + i + 16);\n",
      "                __m512 neg151 = _mm512_load_ps(X + row_index[k + 31] * M_ROW + i + 16);\n",
      "                __m512 pos161 = _mm512_load_ps(X + row_index[k + 32] * M_ROW + i + 16);\n",
      "                __m512 neg161 = _mm512_load_ps(X + row_index[k + 33] * M_ROW + i + 16);\n",
      "                __m512 pos171 = _mm512_load_ps(X + row_index[k + 34] * M_ROW + i + 16);\n",
      "                __m512 neg171 = _mm512_load_ps(X + row_index[k + 35] * M_ROW + i + 16);\n",
      "                __m512 pos181 = _mm512_load_ps(X + row_index[k + 36] * M_ROW + i + 16);\n",
      "                __m512 neg181 = _mm512_load_ps(X + row_index[k + 37] * M_ROW + i + 16);\n",
      "                __m512 pos191 = _mm512_load_ps(X + row_index[k + 38] * M_ROW + i + 16);\n",
      "                __m512 neg191 = _mm512_load_ps(X + row_index[k + 39] * M_ROW + i + 16);\n",
      "                __m512 pos201 = _mm512_load_ps(X + row_index[k + 40] * M_ROW + i + 16);\n",
      "                __m512 neg201 = _mm512_load_ps(X + row_index[k + 41] * M_ROW + i + 16);\n",
      "                __m512 pos211 = _mm512_load_ps(X + row_index[k + 42] * M_ROW + i + 16);\n",
      "                __m512 neg211 = _mm512_load_ps(X + row_index[k + 43] * M_ROW + i + 16);\n",
      "                __m512 pos221 = _mm512_load_ps(X + row_index[k + 44] * M_ROW + i + 16);\n",
      "                __m512 neg221 = _mm512_load_ps(X + row_index[k + 45] * M_ROW + i + 16);\n",
      "                __m512 pos231 = _mm512_load_ps(X + row_index[k + 46] * M_ROW + i + 16);\n",
      "                __m512 neg231 = _mm512_load_ps(X + row_index[k + 47] * M_ROW + i + 16);\n",
      "                __m512 pos241 = _mm512_load_ps(X + row_index[k + 48] * M_ROW + i + 16);\n",
      "                __m512 neg241 = _mm512_load_ps(X + row_index[k + 49] * M_ROW + i + 16);\n",
      "                __m512 pos251 = _mm512_load_ps(X + row_index[k + 50] * M_ROW + i + 16);\n",
      "                __m512 neg251 = _mm512_load_ps(X + row_index[k + 51] * M_ROW + i + 16);\n",
      "                __m512 pos261 = _mm512_load_ps(X + row_index[k + 52] * M_ROW + i + 16);\n",
      "                __m512 neg261 = _mm512_load_ps(X + row_index[k + 53] * M_ROW + i + 16);\n",
      "                __m512 pos271 = _mm512_load_ps(X + row_index[k + 54] * M_ROW + i + 16);\n",
      "                __m512 neg271 = _mm512_load_ps(X + row_index[k + 55] * M_ROW + i + 16);\n",
      "                __m512 pos281 = _mm512_load_ps(X + row_index[k + 56] * M_ROW + i + 16);\n",
      "                __m512 neg281 = _mm512_load_ps(X + row_index[k + 57] * M_ROW + i + 16);\n",
      "                __m512 pos291 = _mm512_load_ps(X + row_index[k + 58] * M_ROW + i + 16);\n",
      "                __m512 neg291 = _mm512_load_ps(X + row_index[k + 59] * M_ROW + i + 16);\n",
      "                __m512 pos301 = _mm512_load_ps(X + row_index[k + 60] * M_ROW + i + 16);\n",
      "                __m512 neg301 = _mm512_load_ps(X + row_index[k + 61] * M_ROW + i + 16);\n",
      "                __m512 pos311 = _mm512_load_ps(X + row_index[k + 62] * M_ROW + i + 16);\n",
      "                __m512 neg311 = _mm512_load_ps(X + row_index[k + 63] * M_ROW + i + 16);\n",
      "                res00 = _mm512_add_ps(res00, _mm512_sub_ps(pos00, neg00));\n",
      "                res10 = _mm512_add_ps(res10, _mm512_sub_ps(pos10, neg10));\n",
      "                res20 = _mm512_add_ps(res20, _mm512_sub_ps(pos20, neg20));\n",
      "                res30 = _mm512_add_ps(res30, _mm512_sub_ps(pos30, neg30));\n",
      "                res40 = _mm512_add_ps(res40, _mm512_sub_ps(pos40, neg40));\n",
      "                res50 = _mm512_add_ps(res50, _mm512_sub_ps(pos50, neg50));\n",
      "                res60 = _mm512_add_ps(res60, _mm512_sub_ps(pos60, neg60));\n",
      "                res70 = _mm512_add_ps(res70, _mm512_sub_ps(pos70, neg70));\n",
      "                res80 = _mm512_add_ps(res80, _mm512_sub_ps(pos80, neg80));\n",
      "                res90 = _mm512_add_ps(res90, _mm512_sub_ps(pos90, neg90));\n",
      "                res100 = _mm512_add_ps(res100, _mm512_sub_ps(pos100, neg100));\n",
      "                res110 = _mm512_add_ps(res110, _mm512_sub_ps(pos110, neg110));\n",
      "                res120 = _mm512_add_ps(res120, _mm512_sub_ps(pos120, neg120));\n",
      "                res130 = _mm512_add_ps(res130, _mm512_sub_ps(pos130, neg130));\n",
      "                res140 = _mm512_add_ps(res140, _mm512_sub_ps(pos140, neg140));\n",
      "                res150 = _mm512_add_ps(res150, _mm512_sub_ps(pos150, neg150));\n",
      "                res160 = _mm512_add_ps(res160, _mm512_sub_ps(pos160, neg160));\n",
      "                res170 = _mm512_add_ps(res170, _mm512_sub_ps(pos170, neg170));\n",
      "                res180 = _mm512_add_ps(res180, _mm512_sub_ps(pos180, neg180));\n",
      "                res190 = _mm512_add_ps(res190, _mm512_sub_ps(pos190, neg190));\n",
      "                res200 = _mm512_add_ps(res200, _mm512_sub_ps(pos200, neg200));\n",
      "                res210 = _mm512_add_ps(res210, _mm512_sub_ps(pos210, neg210));\n",
      "                res220 = _mm512_add_ps(res220, _mm512_sub_ps(pos220, neg220));\n",
      "                res230 = _mm512_add_ps(res230, _mm512_sub_ps(pos230, neg230));\n",
      "                res240 = _mm512_add_ps(res240, _mm512_sub_ps(pos240, neg240));\n",
      "                res250 = _mm512_add_ps(res250, _mm512_sub_ps(pos250, neg250));\n",
      "                res260 = _mm512_add_ps(res260, _mm512_sub_ps(pos260, neg260));\n",
      "                res270 = _mm512_add_ps(res270, _mm512_sub_ps(pos270, neg270));\n",
      "                res280 = _mm512_add_ps(res280, _mm512_sub_ps(pos280, neg280));\n",
      "                res290 = _mm512_add_ps(res290, _mm512_sub_ps(pos290, neg290));\n",
      "                res300 = _mm512_add_ps(res300, _mm512_sub_ps(pos300, neg300));\n",
      "                res310 = _mm512_add_ps(res310, _mm512_sub_ps(pos310, neg310));\n",
      "                res01 = _mm512_add_ps(res01, _mm512_sub_ps(pos01, neg01));\n",
      "                res11 = _mm512_add_ps(res11, _mm512_sub_ps(pos11, neg11));\n",
      "                res21 = _mm512_add_ps(res21, _mm512_sub_ps(pos21, neg21));\n",
      "                res31 = _mm512_add_ps(res31, _mm512_sub_ps(pos31, neg31));\n",
      "                res41 = _mm512_add_ps(res41, _mm512_sub_ps(pos41, neg41));\n",
      "                res51 = _mm512_add_ps(res51, _mm512_sub_ps(pos51, neg51));\n",
      "                res61 = _mm512_add_ps(res61, _mm512_sub_ps(pos61, neg61));\n",
      "                res71 = _mm512_add_ps(res71, _mm512_sub_ps(pos71, neg71));\n",
      "                res81 = _mm512_add_ps(res81, _mm512_sub_ps(pos81, neg81));\n",
      "                res91 = _mm512_add_ps(res91, _mm512_sub_ps(pos91, neg91));\n",
      "                res101 = _mm512_add_ps(res101, _mm512_sub_ps(pos101, neg101));\n",
      "                res111 = _mm512_add_ps(res111, _mm512_sub_ps(pos111, neg111));\n",
      "                res121 = _mm512_add_ps(res121, _mm512_sub_ps(pos121, neg121));\n",
      "                res131 = _mm512_add_ps(res131, _mm512_sub_ps(pos131, neg131));\n",
      "                res141 = _mm512_add_ps(res141, _mm512_sub_ps(pos141, neg141));\n",
      "                res151 = _mm512_add_ps(res151, _mm512_sub_ps(pos151, neg151));\n",
      "                res161 = _mm512_add_ps(res161, _mm512_sub_ps(pos161, neg161));\n",
      "                res171 = _mm512_add_ps(res171, _mm512_sub_ps(pos171, neg171));\n",
      "                res181 = _mm512_add_ps(res181, _mm512_sub_ps(pos181, neg181));\n",
      "                res191 = _mm512_add_ps(res191, _mm512_sub_ps(pos191, neg191));\n",
      "                res201 = _mm512_add_ps(res201, _mm512_sub_ps(pos201, neg201));\n",
      "                res211 = _mm512_add_ps(res211, _mm512_sub_ps(pos211, neg211));\n",
      "                res221 = _mm512_add_ps(res221, _mm512_sub_ps(pos221, neg221));\n",
      "                res231 = _mm512_add_ps(res231, _mm512_sub_ps(pos231, neg231));\n",
      "                res241 = _mm512_add_ps(res241, _mm512_sub_ps(pos241, neg241));\n",
      "                res251 = _mm512_add_ps(res251, _mm512_sub_ps(pos251, neg251));\n",
      "                res261 = _mm512_add_ps(res261, _mm512_sub_ps(pos261, neg261));\n",
      "                res271 = _mm512_add_ps(res271, _mm512_sub_ps(pos271, neg271));\n",
      "                res281 = _mm512_add_ps(res281, _mm512_sub_ps(pos281, neg281));\n",
      "                res291 = _mm512_add_ps(res291, _mm512_sub_ps(pos291, neg291));\n",
      "                res301 = _mm512_add_ps(res301, _mm512_sub_ps(pos301, neg301));\n",
      "                res311 = _mm512_add_ps(res311, _mm512_sub_ps(pos311, neg311));\n",
      "            }\n",
      "                for (int k = groupData[1]; k < groupData[2]; k++) {\n",
      "                    res00 = _mm512_add_ps(res00, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res01 = _mm512_add_ps(res01, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[2]; k < groupData[3]; k++) {\n",
      "                    res00 = _mm512_sub_ps(res00, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res01 = _mm512_sub_ps(res01, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[3]; k < groupData[4]; k++) {\n",
      "                    res10 = _mm512_add_ps(res10, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res11 = _mm512_add_ps(res11, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[4]; k < groupData[5]; k++) {\n",
      "                    res10 = _mm512_sub_ps(res10, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res11 = _mm512_sub_ps(res11, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[5]; k < groupData[6]; k++) {\n",
      "                    res20 = _mm512_add_ps(res20, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res21 = _mm512_add_ps(res21, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[6]; k < groupData[7]; k++) {\n",
      "                    res20 = _mm512_sub_ps(res20, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res21 = _mm512_sub_ps(res21, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[7]; k < groupData[8]; k++) {\n",
      "                    res30 = _mm512_add_ps(res30, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res31 = _mm512_add_ps(res31, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[8]; k < groupData[9]; k++) {\n",
      "                    res30 = _mm512_sub_ps(res30, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res31 = _mm512_sub_ps(res31, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[9]; k < groupData[10]; k++) {\n",
      "                    res40 = _mm512_add_ps(res40, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res41 = _mm512_add_ps(res41, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[10]; k < groupData[11]; k++) {\n",
      "                    res40 = _mm512_sub_ps(res40, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res41 = _mm512_sub_ps(res41, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[11]; k < groupData[12]; k++) {\n",
      "                    res50 = _mm512_add_ps(res50, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res51 = _mm512_add_ps(res51, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[12]; k < groupData[13]; k++) {\n",
      "                    res50 = _mm512_sub_ps(res50, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res51 = _mm512_sub_ps(res51, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[13]; k < groupData[14]; k++) {\n",
      "                    res60 = _mm512_add_ps(res60, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res61 = _mm512_add_ps(res61, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[14]; k < groupData[15]; k++) {\n",
      "                    res60 = _mm512_sub_ps(res60, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res61 = _mm512_sub_ps(res61, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[15]; k < groupData[16]; k++) {\n",
      "                    res70 = _mm512_add_ps(res70, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res71 = _mm512_add_ps(res71, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[16]; k < groupData[17]; k++) {\n",
      "                    res70 = _mm512_sub_ps(res70, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res71 = _mm512_sub_ps(res71, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[17]; k < groupData[18]; k++) {\n",
      "                    res80 = _mm512_add_ps(res80, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res81 = _mm512_add_ps(res81, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[18]; k < groupData[19]; k++) {\n",
      "                    res80 = _mm512_sub_ps(res80, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res81 = _mm512_sub_ps(res81, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[19]; k < groupData[20]; k++) {\n",
      "                    res90 = _mm512_add_ps(res90, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res91 = _mm512_add_ps(res91, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[20]; k < groupData[21]; k++) {\n",
      "                    res90 = _mm512_sub_ps(res90, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res91 = _mm512_sub_ps(res91, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[21]; k < groupData[22]; k++) {\n",
      "                    res100 = _mm512_add_ps(res100, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res101 = _mm512_add_ps(res101, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[22]; k < groupData[23]; k++) {\n",
      "                    res100 = _mm512_sub_ps(res100, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res101 = _mm512_sub_ps(res101, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[23]; k < groupData[24]; k++) {\n",
      "                    res110 = _mm512_add_ps(res110, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res111 = _mm512_add_ps(res111, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[24]; k < groupData[25]; k++) {\n",
      "                    res110 = _mm512_sub_ps(res110, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res111 = _mm512_sub_ps(res111, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[25]; k < groupData[26]; k++) {\n",
      "                    res120 = _mm512_add_ps(res120, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res121 = _mm512_add_ps(res121, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[26]; k < groupData[27]; k++) {\n",
      "                    res120 = _mm512_sub_ps(res120, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res121 = _mm512_sub_ps(res121, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[27]; k < groupData[28]; k++) {\n",
      "                    res130 = _mm512_add_ps(res130, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res131 = _mm512_add_ps(res131, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[28]; k < groupData[29]; k++) {\n",
      "                    res130 = _mm512_sub_ps(res130, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res131 = _mm512_sub_ps(res131, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[29]; k < groupData[30]; k++) {\n",
      "                    res140 = _mm512_add_ps(res140, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res141 = _mm512_add_ps(res141, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[30]; k < groupData[31]; k++) {\n",
      "                    res140 = _mm512_sub_ps(res140, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res141 = _mm512_sub_ps(res141, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[31]; k < groupData[32]; k++) {\n",
      "                    res150 = _mm512_add_ps(res150, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res151 = _mm512_add_ps(res151, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[32]; k < groupData[33]; k++) {\n",
      "                    res150 = _mm512_sub_ps(res150, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res151 = _mm512_sub_ps(res151, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[33]; k < groupData[34]; k++) {\n",
      "                    res160 = _mm512_add_ps(res160, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res161 = _mm512_add_ps(res161, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[34]; k < groupData[35]; k++) {\n",
      "                    res160 = _mm512_sub_ps(res160, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res161 = _mm512_sub_ps(res161, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[35]; k < groupData[36]; k++) {\n",
      "                    res170 = _mm512_add_ps(res170, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res171 = _mm512_add_ps(res171, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[36]; k < groupData[37]; k++) {\n",
      "                    res170 = _mm512_sub_ps(res170, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res171 = _mm512_sub_ps(res171, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[37]; k < groupData[38]; k++) {\n",
      "                    res180 = _mm512_add_ps(res180, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res181 = _mm512_add_ps(res181, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[38]; k < groupData[39]; k++) {\n",
      "                    res180 = _mm512_sub_ps(res180, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res181 = _mm512_sub_ps(res181, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[39]; k < groupData[40]; k++) {\n",
      "                    res190 = _mm512_add_ps(res190, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res191 = _mm512_add_ps(res191, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[40]; k < groupData[41]; k++) {\n",
      "                    res190 = _mm512_sub_ps(res190, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res191 = _mm512_sub_ps(res191, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[41]; k < groupData[42]; k++) {\n",
      "                    res200 = _mm512_add_ps(res200, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res201 = _mm512_add_ps(res201, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[42]; k < groupData[43]; k++) {\n",
      "                    res200 = _mm512_sub_ps(res200, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res201 = _mm512_sub_ps(res201, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[43]; k < groupData[44]; k++) {\n",
      "                    res210 = _mm512_add_ps(res210, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res211 = _mm512_add_ps(res211, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[44]; k < groupData[45]; k++) {\n",
      "                    res210 = _mm512_sub_ps(res210, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res211 = _mm512_sub_ps(res211, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[45]; k < groupData[46]; k++) {\n",
      "                    res220 = _mm512_add_ps(res220, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res221 = _mm512_add_ps(res221, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[46]; k < groupData[47]; k++) {\n",
      "                    res220 = _mm512_sub_ps(res220, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res221 = _mm512_sub_ps(res221, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[47]; k < groupData[48]; k++) {\n",
      "                    res230 = _mm512_add_ps(res230, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res231 = _mm512_add_ps(res231, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[48]; k < groupData[49]; k++) {\n",
      "                    res230 = _mm512_sub_ps(res230, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res231 = _mm512_sub_ps(res231, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[49]; k < groupData[50]; k++) {\n",
      "                    res240 = _mm512_add_ps(res240, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res241 = _mm512_add_ps(res241, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[50]; k < groupData[51]; k++) {\n",
      "                    res240 = _mm512_sub_ps(res240, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res241 = _mm512_sub_ps(res241, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[51]; k < groupData[52]; k++) {\n",
      "                    res250 = _mm512_add_ps(res250, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res251 = _mm512_add_ps(res251, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[52]; k < groupData[53]; k++) {\n",
      "                    res250 = _mm512_sub_ps(res250, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res251 = _mm512_sub_ps(res251, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[53]; k < groupData[54]; k++) {\n",
      "                    res260 = _mm512_add_ps(res260, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res261 = _mm512_add_ps(res261, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[54]; k < groupData[55]; k++) {\n",
      "                    res260 = _mm512_sub_ps(res260, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res261 = _mm512_sub_ps(res261, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[55]; k < groupData[56]; k++) {\n",
      "                    res270 = _mm512_add_ps(res270, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res271 = _mm512_add_ps(res271, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[56]; k < groupData[57]; k++) {\n",
      "                    res270 = _mm512_sub_ps(res270, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res271 = _mm512_sub_ps(res271, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[57]; k < groupData[58]; k++) {\n",
      "                    res280 = _mm512_add_ps(res280, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res281 = _mm512_add_ps(res281, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[58]; k < groupData[59]; k++) {\n",
      "                    res280 = _mm512_sub_ps(res280, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res281 = _mm512_sub_ps(res281, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[59]; k < groupData[60]; k++) {\n",
      "                    res290 = _mm512_add_ps(res290, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res291 = _mm512_add_ps(res291, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[60]; k < groupData[61]; k++) {\n",
      "                    res290 = _mm512_sub_ps(res290, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res291 = _mm512_sub_ps(res291, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[61]; k < groupData[62]; k++) {\n",
      "                    res300 = _mm512_add_ps(res300, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res301 = _mm512_add_ps(res301, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[62]; k < groupData[63]; k++) {\n",
      "                    res300 = _mm512_sub_ps(res300, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res301 = _mm512_sub_ps(res301, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[63]; k < groupData[64]; k++) {\n",
      "                    res310 = _mm512_add_ps(res310, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res311 = _mm512_add_ps(res311, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "                for (int k = groupData[64]; k < groupData[65]; k++) {\n",
      "                    res310 = _mm512_sub_ps(res310, _mm512_load_ps(X + row_index[k] * M_ROW + i + 0));\n",
      "                    res311 = _mm512_sub_ps(res311, _mm512_load_ps(X + row_index[k] * M_ROW + i + 16));\n",
      "                }\n",
      "            _mm512_store_ps(result + (j * 32 + 0) * M_ROW  + i + 0, res00);\n",
      "            _mm512_store_ps(result + (j * 32 + 1) * M_ROW  + i + 0, res10);\n",
      "            _mm512_store_ps(result + (j * 32 + 2) * M_ROW  + i + 0, res20);\n",
      "            _mm512_store_ps(result + (j * 32 + 3) * M_ROW  + i + 0, res30);\n",
      "            _mm512_store_ps(result + (j * 32 + 4) * M_ROW  + i + 0, res40);\n",
      "            _mm512_store_ps(result + (j * 32 + 5) * M_ROW  + i + 0, res50);\n",
      "            _mm512_store_ps(result + (j * 32 + 6) * M_ROW  + i + 0, res60);\n",
      "            _mm512_store_ps(result + (j * 32 + 7) * M_ROW  + i + 0, res70);\n",
      "            _mm512_store_ps(result + (j * 32 + 8) * M_ROW  + i + 0, res80);\n",
      "            _mm512_store_ps(result + (j * 32 + 9) * M_ROW  + i + 0, res90);\n",
      "            _mm512_store_ps(result + (j * 32 + 10) * M_ROW  + i + 0, res100);\n",
      "            _mm512_store_ps(result + (j * 32 + 11) * M_ROW  + i + 0, res110);\n",
      "            _mm512_store_ps(result + (j * 32 + 12) * M_ROW  + i + 0, res120);\n",
      "            _mm512_store_ps(result + (j * 32 + 13) * M_ROW  + i + 0, res130);\n",
      "            _mm512_store_ps(result + (j * 32 + 14) * M_ROW  + i + 0, res140);\n",
      "            _mm512_store_ps(result + (j * 32 + 15) * M_ROW  + i + 0, res150);\n",
      "            _mm512_store_ps(result + (j * 32 + 16) * M_ROW  + i + 0, res160);\n",
      "            _mm512_store_ps(result + (j * 32 + 17) * M_ROW  + i + 0, res170);\n",
      "            _mm512_store_ps(result + (j * 32 + 18) * M_ROW  + i + 0, res180);\n",
      "            _mm512_store_ps(result + (j * 32 + 19) * M_ROW  + i + 0, res190);\n",
      "            _mm512_store_ps(result + (j * 32 + 20) * M_ROW  + i + 0, res200);\n",
      "            _mm512_store_ps(result + (j * 32 + 21) * M_ROW  + i + 0, res210);\n",
      "            _mm512_store_ps(result + (j * 32 + 22) * M_ROW  + i + 0, res220);\n",
      "            _mm512_store_ps(result + (j * 32 + 23) * M_ROW  + i + 0, res230);\n",
      "            _mm512_store_ps(result + (j * 32 + 24) * M_ROW  + i + 0, res240);\n",
      "            _mm512_store_ps(result + (j * 32 + 25) * M_ROW  + i + 0, res250);\n",
      "            _mm512_store_ps(result + (j * 32 + 26) * M_ROW  + i + 0, res260);\n",
      "            _mm512_store_ps(result + (j * 32 + 27) * M_ROW  + i + 0, res270);\n",
      "            _mm512_store_ps(result + (j * 32 + 28) * M_ROW  + i + 0, res280);\n",
      "            _mm512_store_ps(result + (j * 32 + 29) * M_ROW  + i + 0, res290);\n",
      "            _mm512_store_ps(result + (j * 32 + 30) * M_ROW  + i + 0, res300);\n",
      "            _mm512_store_ps(result + (j * 32 + 31) * M_ROW  + i + 0, res310);\n",
      "            _mm512_store_ps(result + (j * 32 + 0) * M_ROW  + i + 16, res01);\n",
      "            _mm512_store_ps(result + (j * 32 + 1) * M_ROW  + i + 16, res11);\n",
      "            _mm512_store_ps(result + (j * 32 + 2) * M_ROW  + i + 16, res21);\n",
      "            _mm512_store_ps(result + (j * 32 + 3) * M_ROW  + i + 16, res31);\n",
      "            _mm512_store_ps(result + (j * 32 + 4) * M_ROW  + i + 16, res41);\n",
      "            _mm512_store_ps(result + (j * 32 + 5) * M_ROW  + i + 16, res51);\n",
      "            _mm512_store_ps(result + (j * 32 + 6) * M_ROW  + i + 16, res61);\n",
      "            _mm512_store_ps(result + (j * 32 + 7) * M_ROW  + i + 16, res71);\n",
      "            _mm512_store_ps(result + (j * 32 + 8) * M_ROW  + i + 16, res81);\n",
      "            _mm512_store_ps(result + (j * 32 + 9) * M_ROW  + i + 16, res91);\n",
      "            _mm512_store_ps(result + (j * 32 + 10) * M_ROW  + i + 16, res101);\n",
      "            _mm512_store_ps(result + (j * 32 + 11) * M_ROW  + i + 16, res111);\n",
      "            _mm512_store_ps(result + (j * 32 + 12) * M_ROW  + i + 16, res121);\n",
      "            _mm512_store_ps(result + (j * 32 + 13) * M_ROW  + i + 16, res131);\n",
      "            _mm512_store_ps(result + (j * 32 + 14) * M_ROW  + i + 16, res141);\n",
      "            _mm512_store_ps(result + (j * 32 + 15) * M_ROW  + i + 16, res151);\n",
      "            _mm512_store_ps(result + (j * 32 + 16) * M_ROW  + i + 16, res161);\n",
      "            _mm512_store_ps(result + (j * 32 + 17) * M_ROW  + i + 16, res171);\n",
      "            _mm512_store_ps(result + (j * 32 + 18) * M_ROW  + i + 16, res181);\n",
      "            _mm512_store_ps(result + (j * 32 + 19) * M_ROW  + i + 16, res191);\n",
      "            _mm512_store_ps(result + (j * 32 + 20) * M_ROW  + i + 16, res201);\n",
      "            _mm512_store_ps(result + (j * 32 + 21) * M_ROW  + i + 16, res211);\n",
      "            _mm512_store_ps(result + (j * 32 + 22) * M_ROW  + i + 16, res221);\n",
      "            _mm512_store_ps(result + (j * 32 + 23) * M_ROW  + i + 16, res231);\n",
      "            _mm512_store_ps(result + (j * 32 + 24) * M_ROW  + i + 16, res241);\n",
      "            _mm512_store_ps(result + (j * 32 + 25) * M_ROW  + i + 16, res251);\n",
      "            _mm512_store_ps(result + (j * 32 + 26) * M_ROW  + i + 16, res261);\n",
      "            _mm512_store_ps(result + (j * 32 + 27) * M_ROW  + i + 16, res271);\n",
      "            _mm512_store_ps(result + (j * 32 + 28) * M_ROW  + i + 16, res281);\n",
      "            _mm512_store_ps(result + (j * 32 + 29) * M_ROW  + i + 16, res291);\n",
      "            _mm512_store_ps(result + (j * 32 + 30) * M_ROW  + i + 16, res301);\n",
      "            _mm512_store_ps(result + (j * 32 + 31) * M_ROW  + i + 16, res311);\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin - AVX-512\n",
    "M_UNROLL = 32\n",
    "N_UNROLL = 32\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "UNROLL_REMAIN = True\n",
    "M_SIMD = int(M_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_colMajor_TCSC_Merged_GroupMin_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"        int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL):\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"            __m512 res\"+str(sn)+str(sm)+\" = _mm512_setzero_ps();\")    \n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        print(\"                __m512 pos\"+str(sn)+str(sm)+\" = _mm512_load_ps(X + row_index[k + \"+str(sn*2+0)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")   \n",
    "        print(\"                __m512 neg\"+str(sn)+str(sm)+\" = _mm512_load_ps(X + row_index[k + \"+str(sn*2+1)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "\n",
    "for sn in range(N_UNROLL):\n",
    "    print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++) {\")\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"                    res\"+str(sn)+str(sm)+\" = _mm512_add_ps(res\"+str(sn)+str(sm)+\", _mm512_load_ps(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")\n",
    "    print(\"                }\")\n",
    "    print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++) {\")\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"                    res\"+str(sn)+str(sm)+\" = _mm512_sub_ps(res\"+str(sn)+str(sm)+\", _mm512_load_ps(X + row_index[k] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\"));\")\n",
    "    print(\"                }\")\n",
    "    \n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "       print(\"            _mm512_store_ps(result + (j * \"+str(N_UNROLL)+\" + \"+str(sn)+\") * M_ROW  + i + \"+str(sm*SIMD_SIZE)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98a649f-fc04-42fb-a411-a8dc04346a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_colMajor_TCSC_Uniform_64xG4_AVX512_OpenMP(float* X, int32_t NonZeroPerCol, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 4; j++) {\n",
      "        for (int i = 0; i < M_ROW; i +=64) {\n",
      "            __m512 res00 = _mm512_setzero_ps();\n",
      "            __m512 res01 = _mm512_setzero_ps();\n",
      "            __m512 res02 = _mm512_setzero_ps();\n",
      "            __m512 res03 = _mm512_setzero_ps();\n",
      "            __m512 res10 = _mm512_setzero_ps();\n",
      "            __m512 res11 = _mm512_setzero_ps();\n",
      "            __m512 res12 = _mm512_setzero_ps();\n",
      "            __m512 res13 = _mm512_setzero_ps();\n",
      "            __m512 res20 = _mm512_setzero_ps();\n",
      "            __m512 res21 = _mm512_setzero_ps();\n",
      "            __m512 res22 = _mm512_setzero_ps();\n",
      "            __m512 res23 = _mm512_setzero_ps();\n",
      "            __m512 res30 = _mm512_setzero_ps();\n",
      "            __m512 res31 = _mm512_setzero_ps();\n",
      "            __m512 res32 = _mm512_setzero_ps();\n",
      "            __m512 res33 = _mm512_setzero_ps();\n",
      "            for (int k = j * 4 * NonZeroPerCol; k < (j + 1) * 4 * NonZeroPerCol; k += 8) {\n",
      "                __m512 pos00 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 0);\n",
      "                __m512 neg00 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 0);\n",
      "                __m512 pos10 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 0);\n",
      "                __m512 neg10 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 0);\n",
      "                __m512 pos20 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 0);\n",
      "                __m512 neg20 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 0);\n",
      "                __m512 pos30 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 0);\n",
      "                __m512 neg30 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 0);\n",
      "                __m512 pos01 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 16);\n",
      "                __m512 neg01 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 16);\n",
      "                __m512 pos11 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 16);\n",
      "                __m512 neg11 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 16);\n",
      "                __m512 pos21 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 16);\n",
      "                __m512 neg21 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 16);\n",
      "                __m512 pos31 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 16);\n",
      "                __m512 neg31 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 16);\n",
      "                __m512 pos02 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 32);\n",
      "                __m512 neg02 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 32);\n",
      "                __m512 pos12 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 32);\n",
      "                __m512 neg12 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 32);\n",
      "                __m512 pos22 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 32);\n",
      "                __m512 neg22 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 32);\n",
      "                __m512 pos32 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 32);\n",
      "                __m512 neg32 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 32);\n",
      "                __m512 pos03 = _mm512_load_ps(X + row_index[k + 0] * M_ROW + i + 48);\n",
      "                __m512 neg03 = _mm512_load_ps(X + row_index[k + 1] * M_ROW + i + 48);\n",
      "                __m512 pos13 = _mm512_load_ps(X + row_index[k + 2] * M_ROW + i + 48);\n",
      "                __m512 neg13 = _mm512_load_ps(X + row_index[k + 3] * M_ROW + i + 48);\n",
      "                __m512 pos23 = _mm512_load_ps(X + row_index[k + 4] * M_ROW + i + 48);\n",
      "                __m512 neg23 = _mm512_load_ps(X + row_index[k + 5] * M_ROW + i + 48);\n",
      "                __m512 pos33 = _mm512_load_ps(X + row_index[k + 6] * M_ROW + i + 48);\n",
      "                __m512 neg33 = _mm512_load_ps(X + row_index[k + 7] * M_ROW + i + 48);\n",
      "                res00 = _mm512_add_ps(res00, _mm512_sub_ps(pos00, neg00));\n",
      "                res10 = _mm512_add_ps(res10, _mm512_sub_ps(pos10, neg10));\n",
      "                res20 = _mm512_add_ps(res20, _mm512_sub_ps(pos20, neg20));\n",
      "                res30 = _mm512_add_ps(res30, _mm512_sub_ps(pos30, neg30));\n",
      "                res01 = _mm512_add_ps(res01, _mm512_sub_ps(pos01, neg01));\n",
      "                res11 = _mm512_add_ps(res11, _mm512_sub_ps(pos11, neg11));\n",
      "                res21 = _mm512_add_ps(res21, _mm512_sub_ps(pos21, neg21));\n",
      "                res31 = _mm512_add_ps(res31, _mm512_sub_ps(pos31, neg31));\n",
      "                res02 = _mm512_add_ps(res02, _mm512_sub_ps(pos02, neg02));\n",
      "                res12 = _mm512_add_ps(res12, _mm512_sub_ps(pos12, neg12));\n",
      "                res22 = _mm512_add_ps(res22, _mm512_sub_ps(pos22, neg22));\n",
      "                res32 = _mm512_add_ps(res32, _mm512_sub_ps(pos32, neg32));\n",
      "                res03 = _mm512_add_ps(res03, _mm512_sub_ps(pos03, neg03));\n",
      "                res13 = _mm512_add_ps(res13, _mm512_sub_ps(pos13, neg13));\n",
      "                res23 = _mm512_add_ps(res23, _mm512_sub_ps(pos23, neg23));\n",
      "                res33 = _mm512_add_ps(res33, _mm512_sub_ps(pos33, neg33));\n",
      "            }\n",
      "            _mm512_store_ps(result + (j * 4 + 0) * M_ROW  + i + 0, res00);\n",
      "            _mm512_store_ps(result + (j * 4 + 1) * M_ROW  + i + 0, res10);\n",
      "            _mm512_store_ps(result + (j * 4 + 2) * M_ROW  + i + 0, res20);\n",
      "            _mm512_store_ps(result + (j * 4 + 3) * M_ROW  + i + 0, res30);\n",
      "            _mm512_store_ps(result + (j * 4 + 0) * M_ROW  + i + 16, res01);\n",
      "            _mm512_store_ps(result + (j * 4 + 1) * M_ROW  + i + 16, res11);\n",
      "            _mm512_store_ps(result + (j * 4 + 2) * M_ROW  + i + 16, res21);\n",
      "            _mm512_store_ps(result + (j * 4 + 3) * M_ROW  + i + 16, res31);\n",
      "            _mm512_store_ps(result + (j * 4 + 0) * M_ROW  + i + 32, res02);\n",
      "            _mm512_store_ps(result + (j * 4 + 1) * M_ROW  + i + 32, res12);\n",
      "            _mm512_store_ps(result + (j * 4 + 2) * M_ROW  + i + 32, res22);\n",
      "            _mm512_store_ps(result + (j * 4 + 3) * M_ROW  + i + 32, res32);\n",
      "            _mm512_store_ps(result + (j * 4 + 0) * M_ROW  + i + 48, res03);\n",
      "            _mm512_store_ps(result + (j * 4 + 1) * M_ROW  + i + 48, res13);\n",
      "            _mm512_store_ps(result + (j * 4 + 2) * M_ROW  + i + 48, res23);\n",
      "            _mm512_store_ps(result + (j * 4 + 3) * M_ROW  + i + 48, res33);\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate Uniform TCSC colMajor - AVX-512\n",
    "M_UNROLL = 64\n",
    "N_UNROLL = 4\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "UNROLL_REMAIN = True\n",
    "M_SIMD = int(M_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_colMajor_TCSC_Uniform_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int16_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\") \n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "for sn in range(N_UNROLL):\n",
    "    for sm in range(M_SIMD):\n",
    "        print(\"            __m512 res\"+str(sn)+str(sm)+\" = _mm512_setzero_ps();\")    \n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        print(\"                __m512 pos\"+str(sn)+str(sm)+\" = _mm512_load_ps(X + row_index[k + \"+str(sn*2+0)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")   \n",
    "        print(\"                __m512 neg\"+str(sn)+str(sm)+\" = _mm512_load_ps(X + row_index[k + \"+str(sn*2+1)+\"] * M_ROW + i + \"+str(sm*SIMD_SIZE)+\");\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "for sm in range(M_SIMD):\n",
    "    for sn in range(N_UNROLL):    \n",
    "       print(\"            _mm512_store_ps(result + (j * \"+str(N_UNROLL)+\" + \"+str(sn)+\") * M_ROW  + i + \"+str(sm*SIMD_SIZE)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba211984-d27a-47a0-a88b-36d7c8041a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_2xG32_AVX512_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int M_ROW, int N_COL, int K){\n",
      "    #pragma omp parallel for\n",
      "    for (int j = 0; j < N_COL / 32; j++) {\n",
      "        for (int i = 0; i < M_ROW; i +=2) {\n",
      "            float* Xbase = X + i * K;\n",
      "            int* groupData = &metadata[j * 66]; \n",
      "            __m512 res00 = _mm512_setzero_ps();\n",
      "            __m512 res01 = _mm512_setzero_ps();\n",
      "            __m512 res10 = _mm512_setzero_ps();\n",
      "            __m512 res11 = _mm512_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 64) {\n",
      "                __m512i indices_p0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 0));\n",
      "                __m512i indices_p1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 16));\n",
      "                __m512i indices_n0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 32));\n",
      "                __m512i indices_n1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 48));\n",
      "                __m512 pos00 = _mm512_i32gather_ps(Xbase + K * 0, indices_p0, 4);\n",
      "                __m512 pos10 = _mm512_i32gather_ps(Xbase + K * 0, indices_p1, 4);\n",
      "                __m512 pos01 = _mm512_i32gather_ps(Xbase + K * 1, indices_p0, 4);\n",
      "                __m512 pos11 = _mm512_i32gather_ps(Xbase + K * 1, indices_p1, 4);\n",
      "                __m512 neg00 = _mm512_i32gather_ps(Xbase + K * 0, indices_n0, 4);\n",
      "                __m512 neg10 = _mm512_i32gather_ps(Xbase + K * 0, indices_n1, 4);\n",
      "                __m512 neg01 = _mm512_i32gather_ps(Xbase + K * 1, indices_n0, 4);\n",
      "                __m512 neg11 = _mm512_i32gather_ps(Xbase + K * 1, indices_n1, 4);\n",
      "                res00 = _mm512_add_ps(res00, _mm512_sub_ps(pos00, neg00));\n",
      "                res10 = _mm512_add_ps(res10, _mm512_sub_ps(pos10, neg10));\n",
      "                res01 = _mm512_add_ps(res01, _mm512_sub_ps(pos01, neg01));\n",
      "                res11 = _mm512_add_ps(res11, _mm512_sub_ps(pos11, neg11));\n",
      "            }\n",
      "            float* Ybase = result + i * N_COL + j * 32;\n",
      "            _mm512_store_ps(Ybase + N_COL * 0 + 0, res00);\n",
      "            _mm512_store_ps(Ybase + N_COL * 0 + 16, res10);\n",
      "            _mm512_store_ps(Ybase + N_COL * 1 + 0, res01);\n",
      "            _mm512_store_ps(Ybase + N_COL * 1 + 16, res11);\n",
      "            for (int g = 0; g < 32; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++) {\n",
      "                    Ybase[N_COL * 0 + g] += Xbase[K * 0 + row_index[k]];\n",
      "                    Ybase[N_COL * 1 + g] += Xbase[K * 1 + row_index[k]];\n",
      "                }\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++) {\n",
      "                    Ybase[N_COL * 0 + g] -= Xbase[K * 0 + row_index[k]];\n",
      "                    Ybase[N_COL * 1 + g] -= Xbase[K * 1 + row_index[k]];\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin - AVX-512\n",
    "M_UNROLL = 2\n",
    "N_UNROLL = 32\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMM_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_\"+str(M_UNROLL)+\"xG\"+str(N_UNROLL)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int M_ROW, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"    #pragma omp parallel for\")\n",
    "print(\"    for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"        for (int i = 0; i < M_ROW; i +=\"+str(M_UNROLL)+\") {\")\n",
    "print(\"            float* Xbase = X + i * K;\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"            __m512 res\"+str(sn)+str(sm)+\" = _mm512_setzero_ps();\")\n",
    "    \n",
    "\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m512i indices_p\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512i indices_n\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE + SIMD_SIZE*N_SIMD)+\"));\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        print(\"                __m512 pos\"+str(sn)+str(sm)+\" = _mm512_i32gather_ps(Xbase + K * \"+str(sm)+\", indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        print(\"                __m512 neg\"+str(sn)+str(sm)+\" = _mm512_i32gather_ps(Xbase + K * \"+str(sm)+\", indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "        idx = str(sn)+str(sm)\n",
    "        print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + i * N_COL + j * \"+str(N_UNROLL)+\";\")\n",
    "for sm in range(M_UNROLL):\n",
    "    for sn in range(N_SIMD):    \n",
    "       print(\"            _mm512_store_ps(Ybase + N_COL * \"+str(sm)+\" + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+str(sm)+\");\") \n",
    "\n",
    "\n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL):\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++) {\")\n",
    "        for sm in range(M_UNROLL):\n",
    "            print(\"                    Ybase[N_COL * \"+str(sm)+\" + \"+str(sn)+\"] += Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "        print(\"                }\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++) {\")\n",
    "        for sm in range(M_UNROLL):\n",
    "            print(\"                    Ybase[N_COL * \"+str(sm)+\" + \"+str(sn)+\"] -= Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "        print(\"                }\")\n",
    "else:\n",
    "    print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "    print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++) {\")\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"                    Ybase[N_COL * \"+str(sm)+\" + g] += Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "    print(\"                }\")\n",
    "    print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++) {\")\n",
    "    for sm in range(M_UNROLL):\n",
    "        print(\"                    Ybase[N_COL * \"+str(sm)+\" + g] -= Xbase[K * \"+str(sm)+\" + row_index[k]];\")\n",
    "    print(\"                }\")\n",
    "    print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"    }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "150413e9-7dcd-4f42-8312-bfd1bfdf89ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G128_AVX512_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            int* groupData = &metadata[j * 258]; \n",
      "            __m512 res0 = _mm512_setzero_ps();\n",
      "            __m512 res1 = _mm512_setzero_ps();\n",
      "            __m512 res2 = _mm512_setzero_ps();\n",
      "            __m512 res3 = _mm512_setzero_ps();\n",
      "            __m512 res4 = _mm512_setzero_ps();\n",
      "            __m512 res5 = _mm512_setzero_ps();\n",
      "            __m512 res6 = _mm512_setzero_ps();\n",
      "            __m512 res7 = _mm512_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 256) {\n",
      "                __m512i indices_p0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 0));\n",
      "                __m512i indices_p1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 16));\n",
      "                __m512i indices_p2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 32));\n",
      "                __m512i indices_p3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 48));\n",
      "                __m512i indices_p4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 64));\n",
      "                __m512i indices_p5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 80));\n",
      "                __m512i indices_p6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 96));\n",
      "                __m512i indices_p7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 112));\n",
      "                __m512i indices_n0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 128));\n",
      "                __m512i indices_n1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 144));\n",
      "                __m512i indices_n2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 160));\n",
      "                __m512i indices_n3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 176));\n",
      "                __m512i indices_n4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 192));\n",
      "                __m512i indices_n5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 208));\n",
      "                __m512i indices_n6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 224));\n",
      "                __m512i indices_n7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 240));\n",
      "                __m512 pos0 = _mm512_i32gather_ps(indices_p0, X, 4);\n",
      "                __m512 pos1 = _mm512_i32gather_ps(indices_p1, X, 4);\n",
      "                __m512 pos2 = _mm512_i32gather_ps(indices_p2, X, 4);\n",
      "                __m512 pos3 = _mm512_i32gather_ps(indices_p3, X, 4);\n",
      "                __m512 pos4 = _mm512_i32gather_ps(indices_p4, X, 4);\n",
      "                __m512 pos5 = _mm512_i32gather_ps(indices_p5, X, 4);\n",
      "                __m512 pos6 = _mm512_i32gather_ps(indices_p6, X, 4);\n",
      "                __m512 pos7 = _mm512_i32gather_ps(indices_p7, X, 4);\n",
      "                __m512 neg0 = _mm512_i32gather_ps(indices_n0, X, 4);\n",
      "                __m512 neg1 = _mm512_i32gather_ps(indices_n1, X, 4);\n",
      "                __m512 neg2 = _mm512_i32gather_ps(indices_n2, X, 4);\n",
      "                __m512 neg3 = _mm512_i32gather_ps(indices_n3, X, 4);\n",
      "                __m512 neg4 = _mm512_i32gather_ps(indices_n4, X, 4);\n",
      "                __m512 neg5 = _mm512_i32gather_ps(indices_n5, X, 4);\n",
      "                __m512 neg6 = _mm512_i32gather_ps(indices_n6, X, 4);\n",
      "                __m512 neg7 = _mm512_i32gather_ps(indices_n7, X, 4);\n",
      "                res0 = _mm512_add_ps(res0, _mm512_sub_ps(pos0, neg0));\n",
      "                res1 = _mm512_add_ps(res1, _mm512_sub_ps(pos1, neg1));\n",
      "                res2 = _mm512_add_ps(res2, _mm512_sub_ps(pos2, neg2));\n",
      "                res3 = _mm512_add_ps(res3, _mm512_sub_ps(pos3, neg3));\n",
      "                res4 = _mm512_add_ps(res4, _mm512_sub_ps(pos4, neg4));\n",
      "                res5 = _mm512_add_ps(res5, _mm512_sub_ps(pos5, neg5));\n",
      "                res6 = _mm512_add_ps(res6, _mm512_sub_ps(pos6, neg6));\n",
      "                res7 = _mm512_add_ps(res7, _mm512_sub_ps(pos7, neg7));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm512_store_ps(Ybase + 0, res0);\n",
      "            _mm512_store_ps(Ybase + 16, res1);\n",
      "            _mm512_store_ps(Ybase + 32, res2);\n",
      "            _mm512_store_ps(Ybase + 48, res3);\n",
      "            _mm512_store_ps(Ybase + 64, res4);\n",
      "            _mm512_store_ps(Ybase + 80, res5);\n",
      "            _mm512_store_ps(Ybase + 96, res6);\n",
      "            _mm512_store_ps(Ybase + 112, res7);\n",
      "            for (int g = 0; g < 128; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\n",
      "                    Ybase[g] += X[row_index[k]];\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\n",
      "                    Ybase[g] -= X[row_index[k]];\n",
      "            }\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin - AVX-512\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G\"+str(N_UNROLL)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m512 res\"+str(sn)+\" = _mm512_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m512i indices_p\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512i indices_n\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE + SIMD_SIZE * N_SIMD)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512 pos\"+str(sn)+\" = _mm512_i32gather_ps(indices_p\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\") \n",
    "for sn in range(N_SIMD):  \n",
    "    print(\"                __m512 neg\"+str(sn)+\" = _mm512_i32gather_ps(indices_n\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm512_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL): \n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] -= X[row_index[k]];\")\n",
    "else:\n",
    "        print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "        print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\")\n",
    "        print(\"                    Ybase[g] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\")\n",
    "        print(\"                    Ybase[g] -= X[row_index[k]];\")\n",
    "        print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05518737-bac2-44e9-ad62-8e45acfdde8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G128_AVX512_OpenMP(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            __m512 res0 = _mm512_setzero_ps();\n",
      "            __m512 res1 = _mm512_setzero_ps();\n",
      "            __m512 res2 = _mm512_setzero_ps();\n",
      "            __m512 res3 = _mm512_setzero_ps();\n",
      "            __m512 res4 = _mm512_setzero_ps();\n",
      "            __m512 res5 = _mm512_setzero_ps();\n",
      "            __m512 res6 = _mm512_setzero_ps();\n",
      "            __m512 res7 = _mm512_setzero_ps();\n",
      "            for (int k = j * 128 * NonZeroPerCol; k < (j + 1) * 128 * NonZeroPerCol; k += 256) {\n",
      "                __m512i indices_p0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 0));\n",
      "                __m512i indices_p1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 16));\n",
      "                __m512i indices_p2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 32));\n",
      "                __m512i indices_p3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 48));\n",
      "                __m512i indices_p4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 64));\n",
      "                __m512i indices_p5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 80));\n",
      "                __m512i indices_p6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 96));\n",
      "                __m512i indices_p7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 112));\n",
      "                __m512i indices_n0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 128));\n",
      "                __m512i indices_n1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 144));\n",
      "                __m512i indices_n2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 160));\n",
      "                __m512i indices_n3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 176));\n",
      "                __m512i indices_n4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 192));\n",
      "                __m512i indices_n5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 208));\n",
      "                __m512i indices_n6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 224));\n",
      "                __m512i indices_n7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 240));\n",
      "                __m512 pos0 = _mm512_i32gather_ps(indices_p0, X, 4);\n",
      "                __m512 pos1 = _mm512_i32gather_ps(indices_p1, X, 4);\n",
      "                __m512 pos2 = _mm512_i32gather_ps(indices_p2, X, 4);\n",
      "                __m512 pos3 = _mm512_i32gather_ps(indices_p3, X, 4);\n",
      "                __m512 pos4 = _mm512_i32gather_ps(indices_p4, X, 4);\n",
      "                __m512 pos5 = _mm512_i32gather_ps(indices_p5, X, 4);\n",
      "                __m512 pos6 = _mm512_i32gather_ps(indices_p6, X, 4);\n",
      "                __m512 pos7 = _mm512_i32gather_ps(indices_p7, X, 4);\n",
      "                __m512 neg0 = _mm512_i32gather_ps(indices_n0, X, 4);\n",
      "                __m512 neg1 = _mm512_i32gather_ps(indices_n1, X, 4);\n",
      "                __m512 neg2 = _mm512_i32gather_ps(indices_n2, X, 4);\n",
      "                __m512 neg3 = _mm512_i32gather_ps(indices_n3, X, 4);\n",
      "                __m512 neg4 = _mm512_i32gather_ps(indices_n4, X, 4);\n",
      "                __m512 neg5 = _mm512_i32gather_ps(indices_n5, X, 4);\n",
      "                __m512 neg6 = _mm512_i32gather_ps(indices_n6, X, 4);\n",
      "                __m512 neg7 = _mm512_i32gather_ps(indices_n7, X, 4);\n",
      "                res0 = _mm512_add_ps(res0, _mm512_sub_ps(pos0, neg0));\n",
      "                res1 = _mm512_add_ps(res1, _mm512_sub_ps(pos1, neg1));\n",
      "                res2 = _mm512_add_ps(res2, _mm512_sub_ps(pos2, neg2));\n",
      "                res3 = _mm512_add_ps(res3, _mm512_sub_ps(pos3, neg3));\n",
      "                res4 = _mm512_add_ps(res4, _mm512_sub_ps(pos4, neg4));\n",
      "                res5 = _mm512_add_ps(res5, _mm512_sub_ps(pos5, neg5));\n",
      "                res6 = _mm512_add_ps(res6, _mm512_sub_ps(pos6, neg6));\n",
      "                res7 = _mm512_add_ps(res7, _mm512_sub_ps(pos7, neg7));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm512_store_ps(Ybase + 0, res0);\n",
      "            _mm512_store_ps(Ybase + 16, res1);\n",
      "            _mm512_store_ps(Ybase + 32, res2);\n",
      "            _mm512_store_ps(Ybase + 48, res3);\n",
      "            _mm512_store_ps(Ybase + 64, res4);\n",
      "            _mm512_store_ps(Ybase + 80, res5);\n",
      "            _mm512_store_ps(Ybase + 96, res6);\n",
      "            _mm512_store_ps(Ybase + 112, res7);\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Uniform - AVX-512\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G\"+str(N_UNROLL)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m512 res\"+str(sn)+\" = _mm512_setzero_ps();\")\n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m512i indices_p\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE)+\"));\") \n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512i indices_n\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE + SIMD_SIZE * N_SIMD)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512 pos\"+str(sn)+\" = _mm512_i32gather_ps(indices_p\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\") \n",
    "for sn in range(N_SIMD):  \n",
    "    print(\"                __m512 neg\"+str(sn)+\" = _mm512_i32gather_ps(indices_n\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm512_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8dc6c-b0a3-4fca-aec7-968b64e2d80f",
   "metadata": {},
   "source": [
    "# GEMV Generator Contineous with SIMD_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975753ad-806f-4246-b42f-1d3a91ca3336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G128_CS8_AVX2_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            int* groupData = &metadata[j * 258]; \n",
      "            __m256 res0 = _mm256_setzero_ps();\n",
      "            __m256 res1 = _mm256_setzero_ps();\n",
      "            __m256 res2 = _mm256_setzero_ps();\n",
      "            __m256 res3 = _mm256_setzero_ps();\n",
      "            __m256 res4 = _mm256_setzero_ps();\n",
      "            __m256 res5 = _mm256_setzero_ps();\n",
      "            __m256 res6 = _mm256_setzero_ps();\n",
      "            __m256 res7 = _mm256_setzero_ps();\n",
      "            __m256 res8 = _mm256_setzero_ps();\n",
      "            __m256 res9 = _mm256_setzero_ps();\n",
      "            __m256 res10 = _mm256_setzero_ps();\n",
      "            __m256 res11 = _mm256_setzero_ps();\n",
      "            __m256 res12 = _mm256_setzero_ps();\n",
      "            __m256 res13 = _mm256_setzero_ps();\n",
      "            __m256 res14 = _mm256_setzero_ps();\n",
      "            __m256 res15 = _mm256_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 256) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256i indices_p2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 32));\n",
      "                __m256i indices_n2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 40));\n",
      "                __m256i indices_p3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 48));\n",
      "                __m256i indices_n3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 56));\n",
      "                __m256i indices_p4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 64));\n",
      "                __m256i indices_n4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 72));\n",
      "                __m256i indices_p5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 80));\n",
      "                __m256i indices_n5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 88));\n",
      "                __m256i indices_p6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 96));\n",
      "                __m256i indices_n6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 104));\n",
      "                __m256i indices_p7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 112));\n",
      "                __m256i indices_n7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 120));\n",
      "                __m256i indices_p8 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 128));\n",
      "                __m256i indices_n8 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 136));\n",
      "                __m256i indices_p9 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 144));\n",
      "                __m256i indices_n9 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 152));\n",
      "                __m256i indices_p10 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 160));\n",
      "                __m256i indices_n10 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 168));\n",
      "                __m256i indices_p11 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 176));\n",
      "                __m256i indices_n11 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 184));\n",
      "                __m256i indices_p12 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 192));\n",
      "                __m256i indices_n12 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 200));\n",
      "                __m256i indices_p13 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 208));\n",
      "                __m256i indices_n13 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 216));\n",
      "                __m256i indices_p14 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 224));\n",
      "                __m256i indices_n14 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 232));\n",
      "                __m256i indices_p15 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 240));\n",
      "                __m256i indices_n15 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 248));\n",
      "                __m256 pos0 = _mm256_i32gather_ps(X, indices_p0, 4);\n",
      "                __m256 neg0 = _mm256_i32gather_ps(X, indices_n0, 4);\n",
      "                __m256 pos1 = _mm256_i32gather_ps(X, indices_p1, 4);\n",
      "                __m256 neg1 = _mm256_i32gather_ps(X, indices_n1, 4);\n",
      "                __m256 pos2 = _mm256_i32gather_ps(X, indices_p2, 4);\n",
      "                __m256 neg2 = _mm256_i32gather_ps(X, indices_n2, 4);\n",
      "                __m256 pos3 = _mm256_i32gather_ps(X, indices_p3, 4);\n",
      "                __m256 neg3 = _mm256_i32gather_ps(X, indices_n3, 4);\n",
      "                __m256 pos4 = _mm256_i32gather_ps(X, indices_p4, 4);\n",
      "                __m256 neg4 = _mm256_i32gather_ps(X, indices_n4, 4);\n",
      "                __m256 pos5 = _mm256_i32gather_ps(X, indices_p5, 4);\n",
      "                __m256 neg5 = _mm256_i32gather_ps(X, indices_n5, 4);\n",
      "                __m256 pos6 = _mm256_i32gather_ps(X, indices_p6, 4);\n",
      "                __m256 neg6 = _mm256_i32gather_ps(X, indices_n6, 4);\n",
      "                __m256 pos7 = _mm256_i32gather_ps(X, indices_p7, 4);\n",
      "                __m256 neg7 = _mm256_i32gather_ps(X, indices_n7, 4);\n",
      "                __m256 pos8 = _mm256_i32gather_ps(X, indices_p8, 4);\n",
      "                __m256 neg8 = _mm256_i32gather_ps(X, indices_n8, 4);\n",
      "                __m256 pos9 = _mm256_i32gather_ps(X, indices_p9, 4);\n",
      "                __m256 neg9 = _mm256_i32gather_ps(X, indices_n9, 4);\n",
      "                __m256 pos10 = _mm256_i32gather_ps(X, indices_p10, 4);\n",
      "                __m256 neg10 = _mm256_i32gather_ps(X, indices_n10, 4);\n",
      "                __m256 pos11 = _mm256_i32gather_ps(X, indices_p11, 4);\n",
      "                __m256 neg11 = _mm256_i32gather_ps(X, indices_n11, 4);\n",
      "                __m256 pos12 = _mm256_i32gather_ps(X, indices_p12, 4);\n",
      "                __m256 neg12 = _mm256_i32gather_ps(X, indices_n12, 4);\n",
      "                __m256 pos13 = _mm256_i32gather_ps(X, indices_p13, 4);\n",
      "                __m256 neg13 = _mm256_i32gather_ps(X, indices_n13, 4);\n",
      "                __m256 pos14 = _mm256_i32gather_ps(X, indices_p14, 4);\n",
      "                __m256 neg14 = _mm256_i32gather_ps(X, indices_n14, 4);\n",
      "                __m256 pos15 = _mm256_i32gather_ps(X, indices_p15, 4);\n",
      "                __m256 neg15 = _mm256_i32gather_ps(X, indices_n15, 4);\n",
      "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
      "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
      "                res2 = _mm256_add_ps(res2, _mm256_sub_ps(pos2, neg2));\n",
      "                res3 = _mm256_add_ps(res3, _mm256_sub_ps(pos3, neg3));\n",
      "                res4 = _mm256_add_ps(res4, _mm256_sub_ps(pos4, neg4));\n",
      "                res5 = _mm256_add_ps(res5, _mm256_sub_ps(pos5, neg5));\n",
      "                res6 = _mm256_add_ps(res6, _mm256_sub_ps(pos6, neg6));\n",
      "                res7 = _mm256_add_ps(res7, _mm256_sub_ps(pos7, neg7));\n",
      "                res8 = _mm256_add_ps(res8, _mm256_sub_ps(pos8, neg8));\n",
      "                res9 = _mm256_add_ps(res9, _mm256_sub_ps(pos9, neg9));\n",
      "                res10 = _mm256_add_ps(res10, _mm256_sub_ps(pos10, neg10));\n",
      "                res11 = _mm256_add_ps(res11, _mm256_sub_ps(pos11, neg11));\n",
      "                res12 = _mm256_add_ps(res12, _mm256_sub_ps(pos12, neg12));\n",
      "                res13 = _mm256_add_ps(res13, _mm256_sub_ps(pos13, neg13));\n",
      "                res14 = _mm256_add_ps(res14, _mm256_sub_ps(pos14, neg14));\n",
      "                res15 = _mm256_add_ps(res15, _mm256_sub_ps(pos15, neg15));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm256_store_ps(Ybase + 0, res0);\n",
      "            _mm256_store_ps(Ybase + 8, res1);\n",
      "            _mm256_store_ps(Ybase + 16, res2);\n",
      "            _mm256_store_ps(Ybase + 24, res3);\n",
      "            _mm256_store_ps(Ybase + 32, res4);\n",
      "            _mm256_store_ps(Ybase + 40, res5);\n",
      "            _mm256_store_ps(Ybase + 48, res6);\n",
      "            _mm256_store_ps(Ybase + 56, res7);\n",
      "            _mm256_store_ps(Ybase + 64, res8);\n",
      "            _mm256_store_ps(Ybase + 72, res9);\n",
      "            _mm256_store_ps(Ybase + 80, res10);\n",
      "            _mm256_store_ps(Ybase + 88, res11);\n",
      "            _mm256_store_ps(Ybase + 96, res12);\n",
      "            _mm256_store_ps(Ybase + 104, res13);\n",
      "            _mm256_store_ps(Ybase + 112, res14);\n",
      "            _mm256_store_ps(Ybase + 120, res15);\n",
      "            for (int g = 0; g < 128; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\n",
      "                    Ybase[g] += X[row_index[k]];\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\n",
      "                    Ybase[g] -= X[row_index[k]];\n",
      "            }\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G\"+str(N_UNROLL)+\"_CS\"+str(SIMD_SIZE)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m256 res\"+str(sn)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2)+\"));\") \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2 + SIMD_SIZE)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256 pos\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\") \n",
    "    print(\"                __m256 neg\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm256_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL): \n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] -= X[row_index[k]];\")\n",
    "else:\n",
    "        #print(\"            #pragma omp simd\")\n",
    "        print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "        #print(\"                #pragma omp simd\")\n",
    "        print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\")\n",
    "        print(\"                    Ybase[g] += X[row_index[k]];\")\n",
    "        #print(\"                #pragma omp simd\")\n",
    "        print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\")\n",
    "        print(\"                    Ybase[g] -= X[row_index[k]];\")\n",
    "        print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e76605-e28a-4eba-84a4-fc854f237709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G128_CS8_AVX2_OpenMP(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            __m256 res0 = _mm256_setzero_ps();\n",
      "            __m256 res1 = _mm256_setzero_ps();\n",
      "            __m256 res2 = _mm256_setzero_ps();\n",
      "            __m256 res3 = _mm256_setzero_ps();\n",
      "            __m256 res4 = _mm256_setzero_ps();\n",
      "            __m256 res5 = _mm256_setzero_ps();\n",
      "            __m256 res6 = _mm256_setzero_ps();\n",
      "            __m256 res7 = _mm256_setzero_ps();\n",
      "            __m256 res8 = _mm256_setzero_ps();\n",
      "            __m256 res9 = _mm256_setzero_ps();\n",
      "            __m256 res10 = _mm256_setzero_ps();\n",
      "            __m256 res11 = _mm256_setzero_ps();\n",
      "            __m256 res12 = _mm256_setzero_ps();\n",
      "            __m256 res13 = _mm256_setzero_ps();\n",
      "            __m256 res14 = _mm256_setzero_ps();\n",
      "            __m256 res15 = _mm256_setzero_ps();\n",
      "            for (int k = j * 128 * NonZeroPerCol; k < (j + 1) * 128 * NonZeroPerCol; k += 256) {\n",
      "                __m256i indices_p0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 0));\n",
      "                __m256i indices_n0 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 8));\n",
      "                __m256i indices_p1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 16));\n",
      "                __m256i indices_n1 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 24));\n",
      "                __m256i indices_p2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 32));\n",
      "                __m256i indices_n2 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 40));\n",
      "                __m256i indices_p3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 48));\n",
      "                __m256i indices_n3 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 56));\n",
      "                __m256i indices_p4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 64));\n",
      "                __m256i indices_n4 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 72));\n",
      "                __m256i indices_p5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 80));\n",
      "                __m256i indices_n5 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 88));\n",
      "                __m256i indices_p6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 96));\n",
      "                __m256i indices_n6 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 104));\n",
      "                __m256i indices_p7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 112));\n",
      "                __m256i indices_n7 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 120));\n",
      "                __m256i indices_p8 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 128));\n",
      "                __m256i indices_n8 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 136));\n",
      "                __m256i indices_p9 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 144));\n",
      "                __m256i indices_n9 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 152));\n",
      "                __m256i indices_p10 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 160));\n",
      "                __m256i indices_n10 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 168));\n",
      "                __m256i indices_p11 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 176));\n",
      "                __m256i indices_n11 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 184));\n",
      "                __m256i indices_p12 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 192));\n",
      "                __m256i indices_n12 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 200));\n",
      "                __m256i indices_p13 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 208));\n",
      "                __m256i indices_n13 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 216));\n",
      "                __m256i indices_p14 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 224));\n",
      "                __m256i indices_n14 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 232));\n",
      "                __m256i indices_p15 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 240));\n",
      "                __m256i indices_n15 = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + 248));\n",
      "                __m256 pos0 = _mm256_i32gather_ps(X, indices_p0, 4);\n",
      "                __m256 neg0 = _mm256_i32gather_ps(X, indices_n0, 4);\n",
      "                __m256 pos1 = _mm256_i32gather_ps(X, indices_p1, 4);\n",
      "                __m256 neg1 = _mm256_i32gather_ps(X, indices_n1, 4);\n",
      "                __m256 pos2 = _mm256_i32gather_ps(X, indices_p2, 4);\n",
      "                __m256 neg2 = _mm256_i32gather_ps(X, indices_n2, 4);\n",
      "                __m256 pos3 = _mm256_i32gather_ps(X, indices_p3, 4);\n",
      "                __m256 neg3 = _mm256_i32gather_ps(X, indices_n3, 4);\n",
      "                __m256 pos4 = _mm256_i32gather_ps(X, indices_p4, 4);\n",
      "                __m256 neg4 = _mm256_i32gather_ps(X, indices_n4, 4);\n",
      "                __m256 pos5 = _mm256_i32gather_ps(X, indices_p5, 4);\n",
      "                __m256 neg5 = _mm256_i32gather_ps(X, indices_n5, 4);\n",
      "                __m256 pos6 = _mm256_i32gather_ps(X, indices_p6, 4);\n",
      "                __m256 neg6 = _mm256_i32gather_ps(X, indices_n6, 4);\n",
      "                __m256 pos7 = _mm256_i32gather_ps(X, indices_p7, 4);\n",
      "                __m256 neg7 = _mm256_i32gather_ps(X, indices_n7, 4);\n",
      "                __m256 pos8 = _mm256_i32gather_ps(X, indices_p8, 4);\n",
      "                __m256 neg8 = _mm256_i32gather_ps(X, indices_n8, 4);\n",
      "                __m256 pos9 = _mm256_i32gather_ps(X, indices_p9, 4);\n",
      "                __m256 neg9 = _mm256_i32gather_ps(X, indices_n9, 4);\n",
      "                __m256 pos10 = _mm256_i32gather_ps(X, indices_p10, 4);\n",
      "                __m256 neg10 = _mm256_i32gather_ps(X, indices_n10, 4);\n",
      "                __m256 pos11 = _mm256_i32gather_ps(X, indices_p11, 4);\n",
      "                __m256 neg11 = _mm256_i32gather_ps(X, indices_n11, 4);\n",
      "                __m256 pos12 = _mm256_i32gather_ps(X, indices_p12, 4);\n",
      "                __m256 neg12 = _mm256_i32gather_ps(X, indices_n12, 4);\n",
      "                __m256 pos13 = _mm256_i32gather_ps(X, indices_p13, 4);\n",
      "                __m256 neg13 = _mm256_i32gather_ps(X, indices_n13, 4);\n",
      "                __m256 pos14 = _mm256_i32gather_ps(X, indices_p14, 4);\n",
      "                __m256 neg14 = _mm256_i32gather_ps(X, indices_n14, 4);\n",
      "                __m256 pos15 = _mm256_i32gather_ps(X, indices_p15, 4);\n",
      "                __m256 neg15 = _mm256_i32gather_ps(X, indices_n15, 4);\n",
      "                res0 = _mm256_add_ps(res0, _mm256_sub_ps(pos0, neg0));\n",
      "                res1 = _mm256_add_ps(res1, _mm256_sub_ps(pos1, neg1));\n",
      "                res2 = _mm256_add_ps(res2, _mm256_sub_ps(pos2, neg2));\n",
      "                res3 = _mm256_add_ps(res3, _mm256_sub_ps(pos3, neg3));\n",
      "                res4 = _mm256_add_ps(res4, _mm256_sub_ps(pos4, neg4));\n",
      "                res5 = _mm256_add_ps(res5, _mm256_sub_ps(pos5, neg5));\n",
      "                res6 = _mm256_add_ps(res6, _mm256_sub_ps(pos6, neg6));\n",
      "                res7 = _mm256_add_ps(res7, _mm256_sub_ps(pos7, neg7));\n",
      "                res8 = _mm256_add_ps(res8, _mm256_sub_ps(pos8, neg8));\n",
      "                res9 = _mm256_add_ps(res9, _mm256_sub_ps(pos9, neg9));\n",
      "                res10 = _mm256_add_ps(res10, _mm256_sub_ps(pos10, neg10));\n",
      "                res11 = _mm256_add_ps(res11, _mm256_sub_ps(pos11, neg11));\n",
      "                res12 = _mm256_add_ps(res12, _mm256_sub_ps(pos12, neg12));\n",
      "                res13 = _mm256_add_ps(res13, _mm256_sub_ps(pos13, neg13));\n",
      "                res14 = _mm256_add_ps(res14, _mm256_sub_ps(pos14, neg14));\n",
      "                res15 = _mm256_add_ps(res15, _mm256_sub_ps(pos15, neg15));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm256_store_ps(Ybase + 0, res0);\n",
      "            _mm256_store_ps(Ybase + 8, res1);\n",
      "            _mm256_store_ps(Ybase + 16, res2);\n",
      "            _mm256_store_ps(Ybase + 24, res3);\n",
      "            _mm256_store_ps(Ybase + 32, res4);\n",
      "            _mm256_store_ps(Ybase + 40, res5);\n",
      "            _mm256_store_ps(Ybase + 48, res6);\n",
      "            _mm256_store_ps(Ybase + 56, res7);\n",
      "            _mm256_store_ps(Ybase + 64, res8);\n",
      "            _mm256_store_ps(Ybase + 72, res9);\n",
      "            _mm256_store_ps(Ybase + 80, res10);\n",
      "            _mm256_store_ps(Ybase + 88, res11);\n",
      "            _mm256_store_ps(Ybase + 96, res12);\n",
      "            _mm256_store_ps(Ybase + 104, res13);\n",
      "            _mm256_store_ps(Ybase + 112, res14);\n",
      "            _mm256_store_ps(Ybase + 120, res15);\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Uniform\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 8\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G\"+str(N_UNROLL)+\"_CS\"+str(SIMD_SIZE)+\"_AVX2_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m256 res\"+str(sn)+\" = _mm256_setzero_ps();\")\n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m256i indices_p\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2)+\"));\") \n",
    "    print(\"                __m256i indices_n\"+str(sn)+\" = _mm256_load_si256(reinterpret_cast<const __m256i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2 + SIMD_SIZE)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m256 pos\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_p\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\") \n",
    "    print(\"                __m256 neg\"+str(sn)+\" = _mm256_i32gather_ps(X, indices_n\"+str(sn)+\", \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm256_add_ps(res\"+idx+\", _mm256_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm256_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2dd7a12-5ca4-4e8f-9266-ad502865a735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G128_CS16_AVX512_OpenMP(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            int* groupData = &metadata[j * 258]; \n",
      "            __m512 res0 = _mm512_setzero_ps();\n",
      "            __m512 res1 = _mm512_setzero_ps();\n",
      "            __m512 res2 = _mm512_setzero_ps();\n",
      "            __m512 res3 = _mm512_setzero_ps();\n",
      "            __m512 res4 = _mm512_setzero_ps();\n",
      "            __m512 res5 = _mm512_setzero_ps();\n",
      "            __m512 res6 = _mm512_setzero_ps();\n",
      "            __m512 res7 = _mm512_setzero_ps();\n",
      "            for (int k = groupData[0]; k < groupData[1]; k += 256) {\n",
      "                __m512i indices_p0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 0));\n",
      "                __m512i indices_n0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 16));\n",
      "                __m512i indices_p1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 32));\n",
      "                __m512i indices_n1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 48));\n",
      "                __m512i indices_p2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 64));\n",
      "                __m512i indices_n2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 80));\n",
      "                __m512i indices_p3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 96));\n",
      "                __m512i indices_n3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 112));\n",
      "                __m512i indices_p4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 128));\n",
      "                __m512i indices_n4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 144));\n",
      "                __m512i indices_p5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 160));\n",
      "                __m512i indices_n5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 176));\n",
      "                __m512i indices_p6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 192));\n",
      "                __m512i indices_n6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 208));\n",
      "                __m512i indices_p7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 224));\n",
      "                __m512i indices_n7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 240));\n",
      "                __m512 pos0 = _mm512_i32gather_ps(indices_p0, X, 4);\n",
      "                __m512 neg0 = _mm512_i32gather_ps(indices_n0, X, 4);\n",
      "                __m512 pos1 = _mm512_i32gather_ps(indices_p1, X, 4);\n",
      "                __m512 neg1 = _mm512_i32gather_ps(indices_n1, X, 4);\n",
      "                __m512 pos2 = _mm512_i32gather_ps(indices_p2, X, 4);\n",
      "                __m512 neg2 = _mm512_i32gather_ps(indices_n2, X, 4);\n",
      "                __m512 pos3 = _mm512_i32gather_ps(indices_p3, X, 4);\n",
      "                __m512 neg3 = _mm512_i32gather_ps(indices_n3, X, 4);\n",
      "                __m512 pos4 = _mm512_i32gather_ps(indices_p4, X, 4);\n",
      "                __m512 neg4 = _mm512_i32gather_ps(indices_n4, X, 4);\n",
      "                __m512 pos5 = _mm512_i32gather_ps(indices_p5, X, 4);\n",
      "                __m512 neg5 = _mm512_i32gather_ps(indices_n5, X, 4);\n",
      "                __m512 pos6 = _mm512_i32gather_ps(indices_p6, X, 4);\n",
      "                __m512 neg6 = _mm512_i32gather_ps(indices_n6, X, 4);\n",
      "                __m512 pos7 = _mm512_i32gather_ps(indices_p7, X, 4);\n",
      "                __m512 neg7 = _mm512_i32gather_ps(indices_n7, X, 4);\n",
      "                res0 = _mm512_add_ps(res0, _mm512_sub_ps(pos0, neg0));\n",
      "                res1 = _mm512_add_ps(res1, _mm512_sub_ps(pos1, neg1));\n",
      "                res2 = _mm512_add_ps(res2, _mm512_sub_ps(pos2, neg2));\n",
      "                res3 = _mm512_add_ps(res3, _mm512_sub_ps(pos3, neg3));\n",
      "                res4 = _mm512_add_ps(res4, _mm512_sub_ps(pos4, neg4));\n",
      "                res5 = _mm512_add_ps(res5, _mm512_sub_ps(pos5, neg5));\n",
      "                res6 = _mm512_add_ps(res6, _mm512_sub_ps(pos6, neg6));\n",
      "                res7 = _mm512_add_ps(res7, _mm512_sub_ps(pos7, neg7));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm512_store_ps(Ybase + 0, res0);\n",
      "            _mm512_store_ps(Ybase + 16, res1);\n",
      "            _mm512_store_ps(Ybase + 32, res2);\n",
      "            _mm512_store_ps(Ybase + 48, res3);\n",
      "            _mm512_store_ps(Ybase + 64, res4);\n",
      "            _mm512_store_ps(Ybase + 80, res5);\n",
      "            _mm512_store_ps(Ybase + 96, res6);\n",
      "            _mm512_store_ps(Ybase + 112, res7);\n",
      "            for (int g = 0; g < 128; g++) {\n",
      "                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\n",
      "                    Ybase[g] += X[row_index[k]];\n",
      "                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\n",
      "                    Ybase[g] -= X[row_index[k]];\n",
      "            }\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin - AVX-512\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "UNROLL_REMAIN = False\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Merged_GroupMin_G\"+str(N_UNROLL)+\"_CS\"+str(SIMD_SIZE)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t* metadata, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "print(\"            int* groupData = &metadata[j * \"+str(2 + 2 * N_UNROLL)+\"]; \")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m512 res\"+str(sn)+\" = _mm512_setzero_ps();\")\n",
    "print(\"            for (int k = groupData[0]; k < groupData[1]; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m512i indices_p\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2)+\"));\") \n",
    "    print(\"                __m512i indices_n\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2 + SIMD_SIZE)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512 pos\"+str(sn)+\" = _mm512_i32gather_ps(indices_p\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\") \n",
    "    print(\"                __m512 neg\"+str(sn)+\" = _mm512_i32gather_ps(indices_n\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm512_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "if(UNROLL_REMAIN):\n",
    "    for sn in range(N_UNROLL): \n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+1)+\"]; k < groupData[\"+str(2 * sn+2)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] += X[row_index[k]];\")\n",
    "        print(\"                for (int k = groupData[\"+str(2*sn+2)+\"]; k < groupData[\"+str(2 * sn+3)+\"]; k++)\")\n",
    "        print(\"                    Ybase[\"+str(sn)+\"] -= X[row_index[k]];\")\n",
    "else:\n",
    "        print(\"            for (int g = 0; g < \"+str(N_UNROLL)+\"; g++) {\")\n",
    "        #print(\"                #pragma omp simd\")\n",
    "        print(\"                for (int k = groupData[2 * g + 1]; k < groupData[2 * g + 2]; k++)\")\n",
    "        print(\"                    Ybase[g] += X[row_index[k]];\")\n",
    "        #print(\"                #pragma omp simd\")\n",
    "        print(\"                for (int k = groupData[2 * g + 2]; k < groupData[2 * g + 3]; k++)\")\n",
    "        print(\"                    Ybase[g] -= X[row_index[k]];\")\n",
    "        print(\"            }\")\n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ae030f-d526-4a7e-af0a-df99a361c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G128_CS16_AVX512_OpenMP(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\n",
      "        #pragma omp parallel for\n",
      "        for (int j = 0; j < N_COL / 128; j++) {\n",
      "            __m512 res0 = _mm512_setzero_ps();\n",
      "            __m512 res1 = _mm512_setzero_ps();\n",
      "            __m512 res2 = _mm512_setzero_ps();\n",
      "            __m512 res3 = _mm512_setzero_ps();\n",
      "            __m512 res4 = _mm512_setzero_ps();\n",
      "            __m512 res5 = _mm512_setzero_ps();\n",
      "            __m512 res6 = _mm512_setzero_ps();\n",
      "            __m512 res7 = _mm512_setzero_ps();\n",
      "            for (int k = j * 128 * NonZeroPerCol; k < (j + 1) * 128 * NonZeroPerCol; k += 256) {\n",
      "                __m512i indices_p0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 0));\n",
      "                __m512i indices_n0 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 16));\n",
      "                __m512i indices_p1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 32));\n",
      "                __m512i indices_n1 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 48));\n",
      "                __m512i indices_p2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 64));\n",
      "                __m512i indices_n2 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 80));\n",
      "                __m512i indices_p3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 96));\n",
      "                __m512i indices_n3 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 112));\n",
      "                __m512i indices_p4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 128));\n",
      "                __m512i indices_n4 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 144));\n",
      "                __m512i indices_p5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 160));\n",
      "                __m512i indices_n5 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 176));\n",
      "                __m512i indices_p6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 192));\n",
      "                __m512i indices_n6 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 208));\n",
      "                __m512i indices_p7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 224));\n",
      "                __m512i indices_n7 = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + 240));\n",
      "                __m512 pos0 = _mm512_i32gather_ps(indices_p0, X, 4);\n",
      "                __m512 neg0 = _mm512_i32gather_ps(indices_n0, X, 4);\n",
      "                __m512 pos1 = _mm512_i32gather_ps(indices_p1, X, 4);\n",
      "                __m512 neg1 = _mm512_i32gather_ps(indices_n1, X, 4);\n",
      "                __m512 pos2 = _mm512_i32gather_ps(indices_p2, X, 4);\n",
      "                __m512 neg2 = _mm512_i32gather_ps(indices_n2, X, 4);\n",
      "                __m512 pos3 = _mm512_i32gather_ps(indices_p3, X, 4);\n",
      "                __m512 neg3 = _mm512_i32gather_ps(indices_n3, X, 4);\n",
      "                __m512 pos4 = _mm512_i32gather_ps(indices_p4, X, 4);\n",
      "                __m512 neg4 = _mm512_i32gather_ps(indices_n4, X, 4);\n",
      "                __m512 pos5 = _mm512_i32gather_ps(indices_p5, X, 4);\n",
      "                __m512 neg5 = _mm512_i32gather_ps(indices_n5, X, 4);\n",
      "                __m512 pos6 = _mm512_i32gather_ps(indices_p6, X, 4);\n",
      "                __m512 neg6 = _mm512_i32gather_ps(indices_n6, X, 4);\n",
      "                __m512 pos7 = _mm512_i32gather_ps(indices_p7, X, 4);\n",
      "                __m512 neg7 = _mm512_i32gather_ps(indices_n7, X, 4);\n",
      "                res0 = _mm512_add_ps(res0, _mm512_sub_ps(pos0, neg0));\n",
      "                res1 = _mm512_add_ps(res1, _mm512_sub_ps(pos1, neg1));\n",
      "                res2 = _mm512_add_ps(res2, _mm512_sub_ps(pos2, neg2));\n",
      "                res3 = _mm512_add_ps(res3, _mm512_sub_ps(pos3, neg3));\n",
      "                res4 = _mm512_add_ps(res4, _mm512_sub_ps(pos4, neg4));\n",
      "                res5 = _mm512_add_ps(res5, _mm512_sub_ps(pos5, neg5));\n",
      "                res6 = _mm512_add_ps(res6, _mm512_sub_ps(pos6, neg6));\n",
      "                res7 = _mm512_add_ps(res7, _mm512_sub_ps(pos7, neg7));\n",
      "            }\n",
      "            float* Ybase = result + j * 128;\n",
      "            _mm512_store_ps(Ybase + 0, res0);\n",
      "            _mm512_store_ps(Ybase + 16, res1);\n",
      "            _mm512_store_ps(Ybase + 32, res2);\n",
      "            _mm512_store_ps(Ybase + 48, res3);\n",
      "            _mm512_store_ps(Ybase + 64, res4);\n",
      "            _mm512_store_ps(Ybase + 80, res5);\n",
      "            _mm512_store_ps(Ybase + 96, res6);\n",
      "            _mm512_store_ps(Ybase + 112, res7);\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate GEMV_CPU_FP32_rowMajor_TCSC_Uniform - AVX-512\n",
    "N_UNROLL = 128\n",
    "X_DATA_BYTES = 4\n",
    "SIMD_SIZE = 16\n",
    "N_SIMD = int(N_UNROLL/SIMD_SIZE)\n",
    "function_name = \"void GEMV_CPU_FP32_rowMajor_TCSC_Uniform_G\"+str(N_UNROLL)+\"_CS\"+str(SIMD_SIZE)+\"_AVX512_OpenMP\"\n",
    "function_name +=\"(float* X, int32_t NonZeroPerCol, int32_t* row_index, float* result, int N_COL, int K){\"\n",
    "print(function_name)\n",
    "print(\"        #pragma omp parallel for\")\n",
    "print(\"        for (int j = 0; j < N_COL / \"+str(N_UNROLL)+\"; j++) {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"            __m512 res\"+str(sn)+\" = _mm512_setzero_ps();\")\n",
    "print(\"            for (int k = j * \"+str(N_UNROLL)+\" * NonZeroPerCol; k < (j + 1) * \"+str(N_UNROLL)+\" * NonZeroPerCol; k += \"+str(2 * N_UNROLL)+\") {\")\n",
    "for sn in range(N_SIMD):\n",
    "    print(\"                __m512i indices_p\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2)+\"));\") \n",
    "    print(\"                __m512i indices_n\"+str(sn)+\" = _mm512_load_si512(reinterpret_cast<const __m512i*>(row_index + k + \"+str(sn * SIMD_SIZE * 2+ SIMD_SIZE)+\"));\")\n",
    "for sn in range(N_SIMD): \n",
    "    print(\"                __m512 pos\"+str(sn)+\" = _mm512_i32gather_ps(indices_p\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\")  \n",
    "    print(\"                __m512 neg\"+str(sn)+\" = _mm512_i32gather_ps(indices_n\"+str(sn)+\", X, \"+str(X_DATA_BYTES)+\");\")\n",
    "for sn in range(N_SIMD):    \n",
    "    idx = str(sn)\n",
    "    print(\"                res\"+idx+\" = _mm512_add_ps(res\"+idx+\", _mm512_sub_ps(pos\"+idx+\", neg\"+idx+\"));\")\n",
    "print(\"            }\")\n",
    "print(\"            float* Ybase = result + j * \"+str(N_UNROLL)+\";\")\n",
    "for sn in range(N_SIMD):    \n",
    "     print(\"            _mm512_store_ps(Ybase + \"+str(SIMD_SIZE*sn)+\", res\"+str(sn)+\");\") \n",
    "print(\"        }\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098811f4-7b77-4aff-98b1-3be3ce905b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
